# Comparing `tmp/k1lib-1.3.5.4-py3-none-any.whl.zip` & `tmp/k1lib-1.3.6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,19 +1,19 @@
-Zip file size: 2521304 bytes, number of entries: 82
+Zip file size: 2525883 bytes, number of entries: 82
 -rw-rw-r--  2.0 unx     1435 b- defN 23-Feb-08 00:13 k1lib/__init__.py
 -rw-rw-r--  2.0 unx    53793 b- defN 23-Apr-02 08:25 k1lib/_baseClasses.py
 -rw-rw-r--  2.0 unx    12952 b- defN 23-Apr-24 20:20 k1lib/_basics.py
 -rw-rw-r--  2.0 unx     4234 b- defN 22-Dec-23 14:19 k1lib/_context.py
 -rw-rw-r--  2.0 unx     2866 b- defN 22-Jul-20 04:30 k1lib/_higher.py
 -rw-rw-r--  2.0 unx      948 b- defN 22-Sep-21 23:54 k1lib/_k1a.py
 -rw-rw-r--  2.0 unx    11646 b- defN 23-Jan-14 15:37 k1lib/_learner.py
 -rw-rw-r--  2.0 unx    19050 b- defN 23-Apr-17 06:59 k1lib/_monkey.py
 -rw-rw-r--  2.0 unx     3571 b- defN 21-Nov-04 18:35 k1lib/_perlin.py
 -rw-rw-r--  2.0 unx    13377 b- defN 21-Dec-29 02:58 k1lib/eqn.py
--rw-rw-r--  2.0 unx     5688 b- defN 23-Apr-28 23:07 k1lib/fmt.py
+-rw-rw-r--  2.0 unx     5688 b- defN 23-Apr-28 23:08 k1lib/fmt.py
 -rw-rw-r--  2.0 unx     6398 b- defN 22-Sep-29 08:23 k1lib/graphEqn.py
 -rw-rw-r--  2.0 unx     2555 b- defN 23-Apr-28 15:36 k1lib/imports.py
 -rw-rw-r--  2.0 unx     3107 b- defN 22-Oct-26 20:43 k1lib/knn.py
 -rw-rw-r--  2.0 unx     3564 b- defN 23-Jan-25 02:48 k1lib/p5.py
 -rw-rw-r--  2.0 unx     8077 b- defN 22-May-06 21:09 k1lib/schedule.py
 -rw-rw-r--  2.0 unx    17767 b- defN 22-Sep-29 07:48 k1lib/selector.py
 -rw-rw-r--  2.0 unx    16231 b- defN 23-Apr-28 23:07 k1lib/viz.py
@@ -46,39 +46,39 @@
 -rw-rw-r--  2.0 unx     2319 b- defN 22-May-15 08:59 k1lib/callbacks/profilers/io.py
 -rw-rw-r--  2.0 unx     4419 b- defN 22-May-15 09:00 k1lib/callbacks/profilers/memory.py
 -rw-rw-r--  2.0 unx     4215 b- defN 22-May-15 09:03 k1lib/callbacks/profilers/time.py
 -rw-rw-r--  2.0 unx      925 b- defN 22-Nov-16 09:22 k1lib/cli/__init__.py
 -rw-rw-r--  2.0 unx     8308 b- defN 22-Nov-27 07:16 k1lib/cli/bio.py
 -rw-rw-r--  2.0 unx     4033 b- defN 23-Jan-25 02:02 k1lib/cli/cif.py
 -rw-rw-r--  2.0 unx    18610 b- defN 23-Apr-26 17:44 k1lib/cli/conv.py
--rw-rw-r--  2.0 unx    24068 b- defN 23-Apr-26 17:32 k1lib/cli/filt.py
+-rw-rw-r--  2.0 unx    24096 b- defN 23-Apr-29 07:15 k1lib/cli/filt.py
 -rw-rw-r--  2.0 unx     6672 b- defN 23-Jan-25 02:02 k1lib/cli/gb.py
 -rw-rw-r--  2.0 unx     6348 b- defN 23-Apr-05 15:10 k1lib/cli/grep.py
--rw-rw-r--  2.0 unx    17990 b- defN 23-Apr-28 15:44 k1lib/cli/init.py
+-rw-rw-r--  2.0 unx    18312 b- defN 23-May-02 14:44 k1lib/cli/init.py
 -rw-rw-r--  2.0 unx    20950 b- defN 23-Apr-05 14:54 k1lib/cli/inp.py
 -rw-rw-r--  2.0 unx      623 b- defN 22-Jun-22 10:43 k1lib/cli/kcsv.py
 -rw-rw-r--  2.0 unx     4819 b- defN 22-Aug-11 20:44 k1lib/cli/kxml.py
 -rw-rw-r--  2.0 unx     1915 b- defN 21-Nov-12 16:48 k1lib/cli/mgi.py
--rw-rw-r--  2.0 unx    34374 b- defN 23-Apr-28 19:19 k1lib/cli/modifier.py
+-rw-rw-r--  2.0 unx    40213 b- defN 23-May-02 17:55 k1lib/cli/modifier.py
 -rw-rw-r--  2.0 unx      694 b- defN 22-Nov-27 07:17 k1lib/cli/mol.py
 -rw-rw-r--  2.0 unx     3551 b- defN 23-Feb-02 17:12 k1lib/cli/nb.py
 -rw-rw-r--  2.0 unx     3530 b- defN 22-Aug-16 15:08 k1lib/cli/optimizations.py
 -rw-rw-r--  2.0 unx    11559 b- defN 23-Apr-25 00:01 k1lib/cli/output.py
 -rw-rw-r--  2.0 unx     2394 b- defN 23-Jan-25 02:03 k1lib/cli/sam.py
--rw-rw-r--  2.0 unx    41816 b- defN 23-Apr-26 16:05 k1lib/cli/structural.py
+-rw-rw-r--  2.0 unx    49588 b- defN 23-May-02 16:53 k1lib/cli/structural.py
 -rw-rw-r--  2.0 unx    10399 b- defN 22-Aug-05 01:15 k1lib/cli/trace.py
 -rw-rw-r--  2.0 unx    23319 b- defN 22-Sep-29 07:14 k1lib/cli/typehint.py
 -rw-rw-r--  2.0 unx    20345 b- defN 23-Apr-26 17:09 k1lib/cli/utils.py
 -rw-rw-r--  2.0 unx       20 b- defN 23-Jan-19 22:00 k1lib/k1ui/__init__.py
 -rw-rw-r--  2.0 unx    61803 b- defN 23-Feb-10 12:10 k1lib/k1ui/main.py
 -rw-rw-r--  2.0 unx       20 b- defN 22-Sep-16 01:12 k1lib/serve/__init__.py
 -rw-rw-r--  2.0 unx    10093 b- defN 23-Mar-19 11:14 k1lib/serve/main.py
 -rw-rw-r--  2.0 unx      642 b- defN 23-Feb-13 19:00 k1lib/serve/suffix.py
--rw-rw-r--  2.0 unx  2453826 b- defN 23-Jan-19 22:50 k1lib-1.3.5.4.data/data/k1lib/k1ui/256.model.state_dict.pth
--rw-rw-r--  2.0 unx   304735 b- defN 23-Jan-17 19:16 k1lib-1.3.5.4.data/data/k1lib/k1ui/mouseKey.pth
--rw-rw-r--  2.0 unx    20544 b- defN 23-Mar-19 11:14 k1lib-1.3.5.4.data/data/k1lib/serve/main.html
--rw-rw-r--  2.0 unx     1049 b- defN 23-Apr-28 23:07 k1lib-1.3.5.4.dist-info/LICENSE
--rw-rw-r--  2.0 unx     2913 b- defN 23-Apr-28 23:07 k1lib-1.3.5.4.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-28 23:07 k1lib-1.3.5.4.dist-info/WHEEL
--rw-rw-r--  2.0 unx        6 b- defN 23-Apr-28 23:07 k1lib-1.3.5.4.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     6543 b- defN 23-Apr-28 23:07 k1lib-1.3.5.4.dist-info/RECORD
-82 files, 3447840 bytes uncompressed, 2511210 bytes compressed:  27.2%
+-rw-rw-r--  2.0 unx  2453826 b- defN 23-Jan-19 22:50 k1lib-1.3.6.data/data/k1lib/k1ui/256.model.state_dict.pth
+-rw-rw-r--  2.0 unx   304735 b- defN 23-Jan-17 19:16 k1lib-1.3.6.data/data/k1lib/k1ui/mouseKey.pth
+-rw-rw-r--  2.0 unx    20544 b- defN 23-Mar-19 11:14 k1lib-1.3.6.data/data/k1lib/serve/main.html
+-rw-rw-r--  2.0 unx     1049 b- defN 23-May-02 17:55 k1lib-1.3.6.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     2911 b- defN 23-May-02 17:55 k1lib-1.3.6.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-May-02 17:55 k1lib-1.3.6.dist-info/WHEEL
+-rw-rw-r--  2.0 unx        6 b- defN 23-May-02 17:55 k1lib-1.3.6.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     6527 b- defN 23-May-02 17:55 k1lib-1.3.6.dist-info/RECORD
+82 files, 3461783 bytes uncompressed, 2515821 bytes compressed:  27.3%
```

## zipnote {}

```diff
@@ -216,32 +216,32 @@
 
 Filename: k1lib/serve/main.py
 Comment: 
 
 Filename: k1lib/serve/suffix.py
 Comment: 
 
-Filename: k1lib-1.3.5.4.data/data/k1lib/k1ui/256.model.state_dict.pth
+Filename: k1lib-1.3.6.data/data/k1lib/k1ui/256.model.state_dict.pth
 Comment: 
 
-Filename: k1lib-1.3.5.4.data/data/k1lib/k1ui/mouseKey.pth
+Filename: k1lib-1.3.6.data/data/k1lib/k1ui/mouseKey.pth
 Comment: 
 
-Filename: k1lib-1.3.5.4.data/data/k1lib/serve/main.html
+Filename: k1lib-1.3.6.data/data/k1lib/serve/main.html
 Comment: 
 
-Filename: k1lib-1.3.5.4.dist-info/LICENSE
+Filename: k1lib-1.3.6.dist-info/LICENSE
 Comment: 
 
-Filename: k1lib-1.3.5.4.dist-info/METADATA
+Filename: k1lib-1.3.6.dist-info/METADATA
 Comment: 
 
-Filename: k1lib-1.3.5.4.dist-info/WHEEL
+Filename: k1lib-1.3.6.dist-info/WHEEL
 Comment: 
 
-Filename: k1lib-1.3.5.4.dist-info/top_level.txt
+Filename: k1lib-1.3.6.dist-info/top_level.txt
 Comment: 
 
-Filename: k1lib-1.3.5.4.dist-info/RECORD
+Filename: k1lib-1.3.6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## k1lib/cli/filt.py

```diff
@@ -479,20 +479,20 @@
 class breakIf(BaseCli):
     def __init__(self, f):
         """Breaks the input iterator if a condition is met.
 Example::
 
     # returns [0, 1, 2, 3, 4, 5]
     [*range(10), 2, 3] | breakIf(lambda x: x > 5) | deref()"""
-        fs = [f]; super().__init__(fs); self.f = fs[0]
+        fs = [f]; super().__init__(fs); self.f = fs[0]; self._fC = fastF(self.f)
     def _typehint(self, inp):
         if isinstance(inp, tListIterSet): return tIter(inp.child)
         return tIter(tAny())
     def __ror__(self, it:Iterator[T]) -> Iterator[T]:
-        f = self.f
+        f = self._fC
         for line in it:
             if f(line): break
             yield line
 class mask(BaseCli):
     def __init__(self, mask:Iterator[bool]):
         """Masks the input stream.
 Example::
```

## k1lib/cli/init.py

```diff
@@ -307,14 +307,17 @@
 def patchNumpy():
     """Patches numpy arrays and data types, so that piping like
 this work::
 
     a = np.random.randn(3)
     a | shape() # returns (3,)"""
     try:
+        if np._k1_patched: return
+    except: pass
+    try:
         import forbiddenfruit, inspect; #forbiddenfruit.reverse(np.ndarray, "__or__") # old version
         oldOr = np.ndarray.__or__
         def _newNpOr(self, v):
             if isinstance(v, BaseCli): return NotImplemented
             try: return oldOr(self, v)
             except: warnings.warn(traceback.format_exc())
         forbiddenfruit.curse(np.ndarray, "__or__", _newNpOr)
@@ -322,26 +325,30 @@
         for _type in [x for x in a if inspect.isclass(x) and issubclass(x, np.number) and not issubclass(x, np.integer)]:
             _oldOr = _type.__or__
             def _typeNewOr(self, v):
                 if isinstance(v, BaseCli): return NotImplemented
                 try: return _oldOr(self, v)
                 except: warnings.warn(traceback.format_exc())
             forbiddenfruit.curse(_type, "__or__", _typeNewOr)
+        np._k1_patched = True
     except Exception as e: warnings.warn(f"Tried to patch __or__ operator of built-in type `np.ndarray` but can't because: {e}")
 dict_keys = type({"a": 3}.keys());   oldDKOr = dict_keys.__or__
 dict_items = type({"a": 3}.items()); oldDIOr = dict_items.__or__
 oldSetOr = set.__or__
 def patchDict():
     """Patches dictionaries's items and keys, so that piping
 works::
 
     d = {"a": 3, "b": 4}
     d.keys() | deref() # returns ["a", "b"]
     d.items() | deref() # returns [["a", 3], ["b", 4]]"""
     try:
+        if np._k1_dict_patched: return
+    except: pass
+    try:
         import forbiddenfruit, traceback
         def _newDOr(self, v):
             """Why is this so weird? For some reason, if you patch dict_keys, you will
             also patch dict_items. So, if you were to have 2 functions, one for each,
             then they will override each other. The way forward is to have 1 single
             function detect whether it's dict_keys or dict_items, and call the correct
             original function. So why are there 2 curses? Well cause I'm lazy to check
@@ -358,29 +365,37 @@
                     return oldSetOr(self, v)
             except:
                 print(self, type(self), v, type(v))
                 warnings.warn(traceback.format_exc())
                 return NotImplemented
         forbiddenfruit.curse(dict_keys, "__or__", _newDOr)
         forbiddenfruit.curse(dict_items, "__or__", _newDOr)
+        np._k1_dict_patched = True
     except Exception as e: warnings.warn(f"Tried to patch __or__ operator of built-in type `dict_keys` and `dict_items` but can't because: {e}")
 def patchPandas():
     """Patches panda's :class:`pandas.core.series.Series` and
 :class:`pandas.core.frame.DataFrame` so that piping works::
 
     pd.read_csv("a.csv")["col3"] | shape()"""
     try:
-        import forbiddenfruit, pandas as pd
+        import pandas as pd
+    except: return
+    try:
+        if pd._k1_patched: return
+    except: pass
+    try:
+        import forbiddenfruit
         oldPdSOr = pd.core.series.Series.__or__
         def _newPdSOr(self, v):
             if isinstance(v, BaseCli): return NotImplemented
             try: return oldPdSOr(self, v)
             except: warnings.warn(traceback.format_exc())
         forbiddenfruit.curse(pd.core.series.Series, "__or__", _newPdSOr)
         
         oldPdDFOr = pd.core.frame.DataFrame
         def _newPdDFOr(self, v):
             if isinstance(v, BaseCli): return NotImplemented
             try: return oldPdDFOr(self, v)
             except: warnings.warn(traceback.format_exc())
         forbiddenfruit.curse(pd.core.frame.DataFrame, "__or__", _newPdDFOr)
+        pd._k1_patched = True
     except Exception as e: warnings.warn(f"Tried to patch __or__ operator of built-in type `pd.core.series.Series` but can't because: {e}")
```

## k1lib/cli/modifier.py

```diff
@@ -142,17 +142,18 @@
 arguments out. Just for convenience really. Example::
 
     # returns [10, 12, 14, 16, 18]
     [range(5), range(10, 15)] | transpose() | ~apply(lambda x, y: x+y) | deref()"""
         return apply(lambda x: self.f(*x, **self.kwargs), self.column, self.cache)
 map_ = apply
 def executeFunc(common, line):
-    import dill
+    import dill, time
     f, kwargs = dill.loads(common)
-    return f(dill.loads(line), **kwargs)
+    res = f(dill.loads(line), **kwargs)
+    time.sleep(0.1); return res # suggestion by https://stackoverflow.com/questions/36359528/broken-pipe-error-with-multiprocessing-queue
 def terminateGraceful(): signal.signal(signal.SIGINT, signal.SIG_IGN)
 class applyMp(BaseCli):
     _pools = set()
     _torchNumThreads = None
     def __init__(self, f:Callable[[T], T], prefetch:int=None, timeout:float=8, utilization:float=0.8, bs:int=1, newPoolEvery:int=0, **kwargs):
         """Like :class:`apply`, but execute a function over the input iterator
 in multiple processes. Example::
@@ -310,16 +311,18 @@
         return
         if hasattr(self, "p"):
             self.p.terminate();
             if self.p in applyMp._pools: applyMp._pools.remove(self.p)
 # apparently, this doesn't do anything, at least in jupyter environment
 atexit.register(lambda: applyMp.clearPools())
 parallel = applyMp
+def specificNode(obj, nodeId:str):
+    return obj.options(scheduling_strategy=ray.util.scheduling_strategies.NodeAffinitySchedulingStrategy(node_id=nodeId, soft=False))
 class applyCl(BaseCli):
-    def __init__(self, f, prefetch=None, timeout=8, bs=1, **kwargs):
+    def __init__(self, f, prefetch=None, timeout=8, bs=1, rss:Union[dict, str]={}, pre:bool=False, orPatch=True, **kwargs):
         """Like :class:`apply`, but execute a function over the input iterator
 in multiple processes on multiple nodes inside of a cluster (hence "cl"). So, just a more
 powerful version of :class:`applyMp`, assuming you have a cluster to run it on.
 Example::
 
     # returns [3, 2]
     ["abc", "de"] | applyCl(len) | deref()
@@ -346,35 +349,125 @@
     k1lib.settings.startup.init_ray = False
     from k1lib.imports import *
 
 As with :class:`applyMp`, there are pitfalls and weird quirks to multiprocessing,
 on 1 or multiple nodes, so check out the docs over there to be aware of them,
 as those translates well to here.
 
+.. admonition:: Advanced use case
+
+    Not really advanced, but just a bit difficult to understand/follow. Let's say
+    that you want to scan through the home directory of all nodes, grab all files,
+    read them, and get the number of bytes they have. You can do something like this::
+    
+        a = None | applyCl.aS(lambda: None | cmd("ls ~") | filt(os.path.isfile) | deref()) | deref()
+        b = a | ungroup(single=True, begin=True) | deref()
+        c = b | applyCl(cat(text=False) | shape(0), pre=True) | deref()
+        d = c | groupBy(0, True) | apply(item().all() | toSum(), 1) | deref()
+    
+    Noted, this is relatively complex. Let's see what A, B, C and D looks like::
+    
+        # A
+        [['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', ['Miniconda3-latest-Linux-x86_64.sh', 'mintupgrade-2023-04-01T232950.log']],
+         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', ['5a', 'abc.jpg', 'a.txt']]]
+        # B
+        [['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 'Miniconda3-latest-Linux-x86_64.sh'],
+         ['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 'mintupgrade-2023-04-01T232950.log'],
+         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', '5a'],
+         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 'abc.jpg'],
+         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 'a.txt']]
+        # C
+        [['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 74403966],
+         ['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 1065252],
+         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 2601],
+         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 16341],
+         ['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 10177]]
+        # D
+        [['1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068', 92185432],
+         ['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', 75469218]]
+
+    The steps we're concerned with is A and C. In step A, we're running 2 processes, 1 for each
+    node, to get all the file names in the home directory. In step C, we're running 5 processes
+    total, 2 on the first node and 3 on the second node. For each process, it's going to read as
+    bytes and count up those bytes. Finally in step D, the results are grouped together and the
+    sizes summed.
+
+    So yeah, it's pretty nice that we did all of that in a relatively short amount of code.
+    The data is distributed too (reading multiple files from multiple nodes), so we're truly
+    not bottlenecked by anything.
+
 :param prefetch: if not specified, schedules all jobs at the same time. If
     specified, schedules jobs so that there'll only be a specified amount of
     jobs, and will only schedule more if results are actually being used.
 :param timeout: seconds to wait for job before raising an error
 :param bs: if specified, groups ``bs`` number of transforms into 1 job to be more
     efficient.
+:param rss: resources required for the task. Can be {"CPU": 2} or "CPU" as a shortcut
+:param pre: "preserve", same convention as :meth:`applyCl.aS`. If True, then allow passing
+    through node ids as the first column to shedule jobs on those specific nodes only
+:param orPatch: whether to automatically patch __or__ function so that cli tools can
+    work with numpy arrays on that remote worker
 :param kwargs: extra arguments to be passed to the function. ``args`` not
     included as there're a couple of options you can pass for this cli."""
-        self.ogF = lambda e: f(e, **kwargs); self.f = ray.remote(self.ogF)
+        super().__init__(fs=[f]); _fC = fastF(f); self.pre = pre
+        if isinstance(rss, str): rss = {rss: 1}
+        def ogF(e):
+            if orPatch:
+                import k1lib; k1lib.cli.init.patchNumpy()
+                k1lib.cli.init.patchDict(); k1lib.cli.init.patchPandas()
+            return _fC(e, **kwargs)
+        self.ogF = ogF; self.f = ray.remote(resources=rss)(ogF)
         self.prefetch = prefetch or int(1e9)
         self.timeout = timeout; self.bs = bs
+        def preprocessF(f, e): # return future (if pre=False), or [nodeId, future] (if pre=True)
+            if pre: nodeId, e = e; return [nodeId, specificNode(f, nodeId).remote(e)]
+            else: return f.remote(e)
+        def resolveF(e):
+            if pre: return [e[0], ray.get(e[1], timeout=timeout)]
+            else: return ray.get(e, timeout=timeout)
+        self.preprocessF = preprocessF; self.resolveF = resolveF
     def __ror__(self, it):
-        f = self.f.remote; timeout = self.timeout; bs = self.bs; ogF = self.ogF
+        f = self.f; timeout = self.timeout; bs = self.bs; ogF = self.ogF; preprocessF = self.preprocessF; resolveF = self.resolveF
         if bs > 1: return it | cli.batched(bs, True) | applyCl(lambda x: x | apply(ogF) | cli.aS(list), self.prefetch, timeout) | cli.joinStreams()
         def gen(it):
             futures = deque(); it = iter(it)
-            for i, e in zip(range(self.prefetch), it): futures.append(f(e))
-            for e in it:
-                yield ray.get(futures.popleft(), timeout=timeout); futures.append(f(e))
-            for e in futures: yield ray.get(e, timeout=timeout)
+            for i, e in zip(range(self.prefetch), it): futures.append(preprocessF(f, e))
+            for e in it: yield resolveF(futures.popleft()); futures.append(preprocessF(f, e))
+            for e in futures: yield resolveF(e)
         return gen(it)
+    @staticmethod
+    def nodeIds() -> iter:
+        """Returns an iterator of all node ids in the current cluster.
+Example::
+
+    applyCl.nodeIds() # returns something like ['7bb387b2920694abe9f7d2a2ed939b6d31843faf91d174d0221e871d', '1051dafd2b0dac13561c46fe052f561400592f0723df2cd746a41068']
+
+If you want to get nodes' metadata, then just use ray's builtin function ``ray.nodes()``"""
+        return ray.nodes() | cli.filt(lambda x: x["Alive"]) | apply(lambda x: x["NodeID"])
+    @staticmethod
+    def aS(f, timeout:float=8):
+        """Executes function f once for all node ids that are piped in.
+Example::
+
+    # returns [['1051da...', ['Desktop', 'Downloads']], ['7bb387...', ['Pictures', 'Music']]]
+    applyCl.nodeIds() | applyCl.aS(lambda: None | cmd("ls ~") | deref()) | deref()
+    # also returns [['1051da...', ['Desktop', 'Downloads']], ['7bb387...', ['Pictures', 'Music']]]
+    None | applyCl.aS(lambda: None | cmd("ls ~") | deref()) | deref()
+
+If you want to execute f for all nodes, you can pass in None instead.
+
+As a reminder, this kinda follows the same logic as the popular cli :class:`aS`, where
+f is executed once, hence the name "apply Single". Here, the meaning of "single" is
+different. It just means execute once for each node ids.
+
+:param f: main function to execute in each node. Not supposed to accept any arguments
+:param timeout: seconds to wait for job before raising an error"""
+        f = fastF(f); g = lambda nodeId: specificNode(ray.remote(f), nodeId).remote()
+        final = cli.iden() & (apply(g) | aS(list) | apply(ray.get, timeout=timeout)) | cli.transpose()
+        return aS(lambda it: (applyCl.nodeIds() if it is None else it) | final)
 thEmptySentinel = object()
 class applyTh(BaseCli):
     def __init__(self, f, prefetch:int=None, timeout:float=5, bs:int=1):
         """Kinda like the same as :class:`applyMp`, but executes ``f`` on multiple
 threads, instead of on multiple processes. Advantages:
 
 - Relatively low overhead for thread creation
```

## k1lib/cli/structural.py

```diff
@@ -3,23 +3,23 @@
 This is for functions that sort of changes the table
 structure in a dramatic way. They're the core transformations
 """
 from typing import List, Union, Iterator, Callable, Any, Tuple, Dict
 from collections import defaultdict, Counter, deque
 from k1lib.cli.init import patchDefaultDelim, BaseCli, oneToMany, T, Table, fastF, yieldT
 import k1lib.cli as cli; from k1lib.cli.typehint import *
-import itertools, numpy as np, k1lib; import matplotlib.pyplot as plt
+import itertools, numpy as np, k1lib, math; import matplotlib.pyplot as plt
 try: import torch; hasTorch = True
 except: torch = k1lib.Object().withAutoDeclare(lambda: type("RandomClass", (object, ), {})); hasTorch = True
 __all__ = ["transpose", "reshape", "insert", "splitW", "splitC",
            "joinStreams", "flatten", "joinStreamsRandom", "activeSamples",
            "table", "batched", "window", "groupBy", "ungroup",
            "insertColumn", "insertIdColumn",
            "expandE", "unsqueeze",
-           "count", "permute", "accumulate", "AA_", "peek", "peekF",
+           "count", "hist", "permute", "accumulate", "AA_", "peek", "peekF",
            "repeat", "repeatF", "repeatFrom", "oneHot", "indexTable"]
 settings = k1lib.settings.cli
 class transpose(BaseCli):
     def __init__(self, dim1:int=0, dim2:int=1, fill=None):
         """Join multiple columns and loop through all rows. Aka transpose.
 Example::
 
@@ -468,21 +468,22 @@
 
 :param n: size of the window
 :param newList: whether to create a new list out of every window or
     not. If False (default), less robust but faster. If True, more
     robust but slower
 :param pad: whether to pad the output stream on the end, so that it
     has the same number of elements as the input stream or not"""
-        self.n = n; self.listF = (lambda x: list(x)) if newList else (lambda x: iter(x)); self.pad = pad
+        self.n = n; self.listF = (lambda x: list(x)) if newList else (lambda x: iter(x))
+        self.pad = pad; self.padBool = pad is not nothing # why do this? Cause in applyMp, "nothing" takes on multiple identities
     def __ror__(self, it):
         n = self.n; pad = self.pad; q = deque([], n); listF = self.listF
         for e in it:
             q.append(e)
             if len(q) == n: yield listF(q); q.popleft()
-        if pad is not nothing:
+        if self.padBool:
             for i in range(n-1):
                 q.append(pad)
                 yield listF(q); q.popleft()
 class groupBy(BaseCli):
     def __init__(self, column:int, separate:bool=False, removeCol:bool=None):
         """Groups table by some column.
 Example::
@@ -496,35 +497,48 @@
 
 This returns::
 
     [[[6.7, 1]],
      [[3.4, 2], [4.5, 2]],
      [[2.3, 5], [5.6, 5]]]
 
-Should have O(n log(n)) time complexity. What if ``separate`` is True?
+Should have O(n log(n)) time complexity. What if ``separate`` is True::
 
     a | groupBy(1, True) | deref()
 
 This returns::
 
     [[1, [[6.7]]],
      [2, [[3.4], [4.5]]],
      [5, [[2.3], [5.6]]]]
 
-What if ``removeCol`` is False?
+What if ``removeCol`` is False::
 
     a | groupBy(1, True, False) | deref()
 
 This returns::
 
     [[1, [[6.7, 1]]],
      [2, [[3.4, 2], [4.5, 2]]],
      [5, [[2.3, 5], [5.6, 5]]]]
 
-See also: :class:`~k1lib.cli.grep.grep`
+There's another perspective and way to think about this operation. A lot of
+libraries (like pandas) expect the uncompressed, "flat" version (the variable
+``a`` in the examples above). But throughout my time using cli, the grouped
+version (separate=True) is usually much more useful and amenable to
+transformations. It also occupies less memory too, as the columns with duplicated
+elements are deleted.
+
+So, you can sort of think :class:`groupBy` is converting pandas dataframes
+into a more easily digestible form. But because the prevalence of those libraries,
+after doing all the transformations you want, sometimes it's necessary to flatten
+it again, which :class:`ungroup` does.
+
+If you want to group text lines by some pattern im them, :class:`~k1lib.cli.grep.grep`
+might be better for you.
 
 :param column: which column to group by
 :param separate: whether to separate out the column to sort of form a dict or not. See example
 :param removeCol: whether to remove the grouped-by column. Defaults to True if
     ``separate=True``, and False if ``separate=False``"""
         self.column = column; self.separate = separate
         if removeCol is None: removeCol = separate # if separate, then remove cols, else don't do it
@@ -546,30 +560,55 @@
                     a = [e]; v = a[0][c]
         except StopIteration:
             if len(a) > 0:
                 if removeCol: a = a | ~cli.cut(c)
                 if separate: yield [v, a]
                 else: yield a
 class ungroup(BaseCli):
-    def __init__(self, insertCol:bool=True):
+    def __init__(self, insertCol:bool=True, single=False, begin=False):
         """Ungroups things that were grouped using a specific mode of
 :class:`groupBy`. Particularly useful to transform some complex data
 structure into a flat dataframe so that you can plug into pandas. Example::
 
     a = [[2.3, 5], [3.4, 2], [4.5, 2], [5.6, 5], [6.7, 1]]
     # returns [[6.7, 1], [3.4, 2], [4.5, 2], [2.3, 5], [5.6, 5]]
     a | groupBy(1, True) | ungroup() | deref()
     # returns [[6.7], [3.4], [4.5], [2.3], [5.6]]
     a | groupBy(1, True) | ungroup(False) | deref()
 
-:param insertCol: whether to insert the column into the table or not"""
-        self.insertCol = insertCol
+Just as a reminder, this is the output of :class:`groupBy` after executing ``a | groupBy(1, True)``::
+
+    [[1, [[6.7]]],
+     [2, [[3.4], [4.5]]],
+     [5, [[2.3], [5.6]]]]
+
+A lot of times, your data is a little bit different, like this perhaps::
+
+    [[1, [6.7]],
+     [2, [3.4, 4.5]],
+     [5, [2.3, 5.6]]]
+
+A way to fix this would be to add ``apply(wrapList().all(), 1)`` before :class:`ungroup`.
+But because this is so common, I've added in the parameter ``single`` for that. Just set
+it to True::
+
+    # returns [[6.7, 1], [3.4, 2], [4.5, 2], [2.3, 5], [5.6, 5]]
+    [[1, [6.7]],
+     [2, [3.4, 4.5]],
+     [5, [2.3, 5.6]]] | ungroup(single=True)
+
+:param insertCol: whether to insert the column into the table or not
+:param single: whether the table in each group has a single column or not
+:param begin: whether to insert the column at the beginning or at the end.
+    Only works if ``insertCol`` is True"""
+        self.insertCol = insertCol; self.single = single; self.begin = begin
     def __ror__(self, it):
-        if self.insertCol: return it | ~cli.apply(lambda x, arr: arr | cli.insert(x, False).all()) | cli.joinStreams()
-        else: return it | cli.cut(1) | cli.joinStreams()
+        preprocess = cli.apply(cli.wrapList().all(), 1) if self.single else cli.iden(); begin = self.begin
+        if self.insertCol: return it | preprocess | ~cli.apply(lambda x, arr: arr | cli.insert(x, begin).all()) | cli.joinStreams()
+        else: return it | preprocess | cli.cut(1) | cli.joinStreams()
 class insertColumn(BaseCli):
     def __init__(self, column:List[T], begin=True, fill=""):
         """Inserts a column at beginning or end.
 Example::
 
     # returns [['a', 1, 2], ['b', 3, 4]]
     [[1, 2], [3, 4]] | insertColumn(["a", "b"]) | deref()
@@ -675,14 +714,130 @@
             for _count in counts:
                 if _count is None: continue
                 for v, k, *_ in _count:
                     values[k] += v
             s = values.values() | cli.toSum()
             for k, v in values.items(): yield [v, k, f"{round(100*v/s)}%"]
         return cli.applyS(inner)
+class hist(BaseCli):
+    def __init__(self, bins:int=30):
+        """Bins a long 1d array. Effectively creating a historgram, without
+actually plotting it. Example::
+
+    np.random.randn(1000) | hist(5)
+
+That returns something like::
+
+    (array([-2.31449761, -1.17406889, -0.03364017,  1.10678854,  2.24721726]),
+     array([ 41, 207, 432, 265,  55]),
+     1.1404287156493986)
+
+This format goes with :meth:`~matplotlib.pyplot.bar` directly like this::
+
+    np.random.randn(1000) | hist(10) | ~aS(plt.bar)
+
+If you have tons of data that's handled in multiple processes, but you want to
+get an overall histogram, you can do something like this::
+
+    # bad solution, runs slow, accurate
+    fileNames | applyMp(cat() | toFloat() | aS(list)) | joinStreams() | hist() | ~aS(plt.bar)
+    # good solution, runs fast, slightly inaccurate
+    fileNames | applyMp(cat() | toFloat() | hist(300)) | hist.join() | ~aS(plt.bar)
+
+Let's say in each process, you have 10M records, and that you have 1000 processes in total.
+In the first solution, you transfer all records (10B records total) to a single process,
+then calculate the histogram of them. The transfer overhead is going to be absolutely
+enourmous, as well as the computation. This really defeats the purpose of doing
+multiprocessing.
+
+In the second solution, you "convert" 10M records into 600 numbers for each process,
+which scales up to 600k numbers for all processes. Although big, but certainly
+manageable with current hardware. So the data transfer cost is not a lot at all. The
+histogram merging part also executes relatively fast, as it only creates an internal
+array of 3M length. See over :meth:`hist.join` for param details
+
+:params bins: how many bins should the histogram has?"""
+        self.bins = bins
+    def __ror__(self, it):
+        if not isinstance(it, settings.arrayTypes): it = list(it)
+        y, x = np.histogram(it, bins=self.bins)
+        delta = x[1] - x[0]; x = (x[1:] + x[:-1])/2
+        return x, y, delta
+    @staticmethod
+    def join(scale:float=1e4, bins:int=None, log:bool=True):
+        """Joins multiple histograms together.
+Example::
+
+    a = np.random.randn(1000); b = np.random.randn(1000)+3
+    [a, b] | joinStreams() | hist() | head(2) | ~aS(plt.plot) # ---------------------------------- Ground truth
+    [a, b] | hist(300).all() | hist.join(scale=1e4) | head(2) | ~aS(plt.plot) # ------------------ Log joining
+    [a, b] | hist(300).all() | hist.join(scale=1e4, log=False) | head(2) | ~aS(plt.plot, ".") # -- Linear joining
+    plt.legend(["Ground truth", "Log", "Linear"]); plt.grid(True); plt.ylabel("Frequency"); plt.xlabel("Value");
+
+This results in this:
+
+.. image:: ../images/hist1.png
+
+As you can see, this process is only approximate, but is accurate enough in everyday
+use. If you are a normal user, then this is probably enough. However, if you're a
+mathematician and really care about the accuracy of this, read on.
+
+.. admonition:: Performance vs accuracy
+
+    As mentioned in :class:`hist`, joining histograms from across processes can really speed
+    things up big time. But the joining process is complicated, with multiple parameters
+    and different tradeoffs for each config. In this example, scale = 1e4, bins = 30,
+    OG bins = 300, log = True. "OG bins" is the number of bins coming into :meth:`hist.join`
+
+    To get the best accuracy possible, you should set scale and OG bins high. If better
+    performance is desired, you should first lower scale, then lower OG bins, then finally lower
+    bins.
+
+.. admonition:: Log scale
+
+    Take a look at this piece of code::
+    
+        a, b = np.random.randn(1000)*1, np.random.randn(3000000)*0.3+3
+        [a, b] | joinStreams() | hist() | head(2) | ~aS(plt.plot)
+        [a, b] | hist(300).all() | hist.join(scale=1e4) | head(2) | ~aS(plt.plot)
+        [a, b] | hist(300).all() | hist.join(scale=1e4, log=False) | head(2) | ~aS(plt.plot, ".")
+        plt.yscale("log"); plt.legend(["Ground truth", "Log", "Linear"]); plt.grid(True); plt.ylabel("Frequency"); plt.xlabel("Value");
+
+    This results in:
+
+    .. image:: ../images/hist2.png
+
+    This shows how log mode is generally better than linear mode when the frequencies span
+    across multiple orders of magnitude. So why not delete linear mode directly? Well, I have
+    not formally proved that log scale case fully covers the linear case, although in practice
+    it seems so. So just to be cautious, let's leave it in
+
+.. admonition:: Scale
+
+    The setup is just like in the "Log scale" section, but with scale = 1e3 instead of the default 1e4:
+
+    .. image:: ../images/hist3.png
+    
+    Remember that the higher the scale, the more accurate, but also the longer it runs. If
+    the difference in high and low frequencies are bigger than scale, then the low
+    frequency values are dropped.
+
+:param scale: how big a range of frequencies do we want to capture?
+:param bins: output bins. If not specified automatically defaults to 1/10 the
+    original number of bins
+:param log: whether to transform everything to log scale internally"""
+        def inner(it):
+            it = it | cli.deref()
+            _bins = bins if bins is not None else it | cli.cut(0) | cli.shape(0).all() | cli.toMean() | cli.op()/10 | cli.aS(int)
+            maxY = max(it | cli.cut(1) | cli.toMax().all() | cli.toMax() | cli.op()/scale, 1e-9)
+            if log: it = it | cli.apply(lambda x: np.log(x+1e-9)-math.log(maxY) | cli.aS(np.exp) | cli.aS(np.round) | cli.op().astype(int), 1) | cli.deref()
+            else: it = it | cli.apply(lambda y: (y/maxY).astype(int), 1) | cli.deref()
+            x, y, delta = it | cli.cut(0, 1) | cli.transpose().all() | cli.joinStreams() | ~cli.apply(lambda a,b: [a]*b) | cli.joinStreams() | cli.aS(list) | cli.aS(np.array) | hist(_bins)
+            return x, y*maxY, delta
+        return cli.aS(inner)
 def _permuteGen(row, pers):
     row = list(row); return (row[i] for i in pers)
 class permute(BaseCli):
     def __init__(self, *permutations:List[int]):
         """Permutes the columns. Acts kinda like :meth:`torch.Tensor.permute`.
 Example::
```

## Comparing `k1lib-1.3.5.4.data/data/k1lib/k1ui/256.model.state_dict.pth` & `k1lib-1.3.6.data/data/k1lib/k1ui/256.model.state_dict.pth`

 * *Files identical despite different names*

## Comparing `k1lib-1.3.5.4.data/data/k1lib/k1ui/mouseKey.pth` & `k1lib-1.3.6.data/data/k1lib/k1ui/mouseKey.pth`

 * *Files identical despite different names*

## Comparing `k1lib-1.3.5.4.data/data/k1lib/serve/main.html` & `k1lib-1.3.6.data/data/k1lib/serve/main.html`

 * *Files identical despite different names*

## Comparing `k1lib-1.3.5.4.dist-info/LICENSE` & `k1lib-1.3.6.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `k1lib-1.3.5.4.dist-info/METADATA` & `k1lib-1.3.6.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: k1lib
-Version: 1.3.5.4
+Version: 1.3.6
 Summary: Some nice ML overhaul
 Home-page: https://k1lib.com
 Author: Quang Ho
 Author-email: 157239q@gmail.com
 License: MIT
 Requires-Python: >=3.7
 Description-Content-Type: text/markdown
```

## Comparing `k1lib-1.3.5.4.dist-info/RECORD` & `k1lib-1.3.6.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -45,38 +45,38 @@
 k1lib/callbacks/profilers/io.py,sha256=H8E0YzmLWRD9T2_RyDG2eXvbQQnJgzEnEyx8PqfQ4wY,2319
 k1lib/callbacks/profilers/memory.py,sha256=L0F5pc5LB0dtSnRot8ReR-amZn1uIXv0py0XmGS166U,4419
 k1lib/callbacks/profilers/time.py,sha256=R2-2ZooDwLQIeyonLp2Zz5E_uXzdy6mWUgw6uavQbpE,4215
 k1lib/cli/__init__.py,sha256=hF0ODhL20OSM9o1j68VhcIVflibgSpPuqeyYlsh8oow,925
 k1lib/cli/bio.py,sha256=PhGvy-fDA-wrUzzEDpuRe4x-Kbylx0sNmoXCEZfE_FA,8308
 k1lib/cli/cif.py,sha256=77FX83m1FRYEeZkdXJ8MiVapqCSzZ-1xOQ8ZLeHfhf8,4033
 k1lib/cli/conv.py,sha256=dwsdTpGew3J5OzCVBehATgFmuVdi5vxfRECj6Q-eTDw,18610
-k1lib/cli/filt.py,sha256=NySmpJvbCusI5WOombL17Ro-yGZs6n73XVnaQqXtNLg,24068
+k1lib/cli/filt.py,sha256=uZlB3qbaOSZZhBpfX2Wt0JSDcB72Z98bRlE_eNtb7gc,24096
 k1lib/cli/gb.py,sha256=xxjuNYgWrrElRckon3gP0sj-dShYnKs3jmHAb1U0kVI,6672
 k1lib/cli/grep.py,sha256=Lu4PFOe2pkaqd-UfJe_HhHCUFTUifE6Bh96_k80sQDA,6348
-k1lib/cli/init.py,sha256=bbLyTveUCtvu7zLfrWJxgab70t035Ku0lo1loPBcbLU,17990
+k1lib/cli/init.py,sha256=jtOLSw3PR_0VIepOzK5cDmeAea4WmDNa3jy6WIM6qV4,18312
 k1lib/cli/inp.py,sha256=O2EBUvD9D6y8G0KnFbf9RNGlAw07ajWoUl-7CtJTJFM,20950
 k1lib/cli/kcsv.py,sha256=YGUVVLTZGGujokhxtj5MfjU9t1jRGqp23d58JK8lhq0,623
 k1lib/cli/kxml.py,sha256=YQGutvKNm0_xAi_NhCNtuGey7fx3zZSmSo33kS--54c,4819
 k1lib/cli/mgi.py,sha256=aLke90nG89tgWLPwyKmTj3kM8yJnIBCJSrPS1jT8mUk,1915
-k1lib/cli/modifier.py,sha256=UhB2lTtNV56GVTqly0vTaQ5Pvku0acrwQ3vwFM2ZbWQ,34374
+k1lib/cli/modifier.py,sha256=BYYsg6pBmJ_qDNFaMwQB-ZfIbFfR_JUjFcBS61e_gt4,40213
 k1lib/cli/mol.py,sha256=wNFuCPXtdEcH4DRBbmYaLAWxtDzjN2MOKFX7ynJhaJs,694
 k1lib/cli/nb.py,sha256=SHqhYHJrzV8IzH3wM1Kb0LOVseOa1XXDKUtYE_2KTkQ,3551
 k1lib/cli/optimizations.py,sha256=iZ73DwLqZCxRm0sECVZ7A2nDxf5D4rsoSGzrKTgzGaI,3530
 k1lib/cli/output.py,sha256=HQD61-Epy6WfteMHXW6SV14SiprXF55ELnfer2CWXEA,11559
 k1lib/cli/sam.py,sha256=_ersEPP2ue0Oa3AyftNjQu2PABpH4L7iFBbRJDOkeug,2394
-k1lib/cli/structural.py,sha256=cNxiaIGgNxsqnqDjxMEWUj1WqQWnzdGbHSbkRxYP4h4,41816
+k1lib/cli/structural.py,sha256=HgYG8t8tbj4PN4TNeenhnW0CQQsI0qN1y_uh-avNT-8,49588
 k1lib/cli/trace.py,sha256=nzZgOyXqFJYkQfbpR0lpX0Nnp0bQHXPjk8sDUBIe2hk,10399
 k1lib/cli/typehint.py,sha256=VBYxrOQaSnu5266lNWpgXIhXF7htdT0FT_NEvXjYBVk,23319
 k1lib/cli/utils.py,sha256=gaHYEw2_gjqNjOQFLUfa3JAXXwi6vZPCQqKwDuhrUDg,20345
 k1lib/k1ui/__init__.py,sha256=8D5a8oKgqd6WA1RUkiKCn4l_PVemtyuckxQut0vDHXM,20
 k1lib/k1ui/main.py,sha256=PnmdOhkjYgRSZnDyGYNMYtQ5Nvcb1NhQ9yjfP_3QORI,61803
 k1lib/serve/__init__.py,sha256=8D5a8oKgqd6WA1RUkiKCn4l_PVemtyuckxQut0vDHXM,20
 k1lib/serve/main.py,sha256=SXZADDxXqZkxALeO01xwGKJ7c1sYMn4DjdY3RitMUaI,10093
 k1lib/serve/suffix.py,sha256=UH3ITN6O2vzoha2f6v4bcQG3_Boav7VA7EC8wf8r9f8,642
-k1lib-1.3.5.4.data/data/k1lib/k1ui/256.model.state_dict.pth,sha256=Ga-UXlAJfUPNOZsvP_c1-1cfB2Hp_-oQ4ghdouX1d7g,2453826
-k1lib-1.3.5.4.data/data/k1lib/k1ui/mouseKey.pth,sha256=KULhK_gdK2Ppju9gQnv1zV2kf_A0K-vX2W7trY6DIg8,304735
-k1lib-1.3.5.4.data/data/k1lib/serve/main.html,sha256=gHFNqzE9JKb4eCwCJN-Du45jj75lDRED4Ico91T-b4g,20544
-k1lib-1.3.5.4.dist-info/LICENSE,sha256=psuy2wnTg9zacuCQ0dXfxS44iaa89aTgsNzHDzx4UGM,1049
-k1lib-1.3.5.4.dist-info/METADATA,sha256=dyBGPFqGNjzAJkT8NI3S6cZWLliokXKreT9Xp_TsNJw,2913
-k1lib-1.3.5.4.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-k1lib-1.3.5.4.dist-info/top_level.txt,sha256=xxWmqZzuThnLZn49Mse6A6j41-IVduPVnQW54imcOTA,6
-k1lib-1.3.5.4.dist-info/RECORD,,
+k1lib-1.3.6.data/data/k1lib/k1ui/256.model.state_dict.pth,sha256=Ga-UXlAJfUPNOZsvP_c1-1cfB2Hp_-oQ4ghdouX1d7g,2453826
+k1lib-1.3.6.data/data/k1lib/k1ui/mouseKey.pth,sha256=KULhK_gdK2Ppju9gQnv1zV2kf_A0K-vX2W7trY6DIg8,304735
+k1lib-1.3.6.data/data/k1lib/serve/main.html,sha256=gHFNqzE9JKb4eCwCJN-Du45jj75lDRED4Ico91T-b4g,20544
+k1lib-1.3.6.dist-info/LICENSE,sha256=psuy2wnTg9zacuCQ0dXfxS44iaa89aTgsNzHDzx4UGM,1049
+k1lib-1.3.6.dist-info/METADATA,sha256=IEMwsFAz84_dd_5IbY89ACXLZEAATc5nbCW-_j1XGWo,2911
+k1lib-1.3.6.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+k1lib-1.3.6.dist-info/top_level.txt,sha256=xxWmqZzuThnLZn49Mse6A6j41-IVduPVnQW54imcOTA,6
+k1lib-1.3.6.dist-info/RECORD,,
```

