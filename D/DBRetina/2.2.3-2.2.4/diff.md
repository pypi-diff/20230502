# Comparing `tmp/DBRetina-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.zip` & `tmp/DBRetina-2.2.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.zip`

## zipinfo {}

```diff
@@ -1,31 +1,31 @@
-Zip file size: 1924714 bytes, number of entries: 29
-drwxr-xr-x  2.0 unx        0 b- stor 23-May-01 03:48 DBRetina.libs/
-drwxr-xr-x  2.0 unx        0 b- stor 23-May-01 03:48 kSpider2/
-drwxr-xr-x  2.0 unx        0 b- stor 23-May-01 03:48 DBRetina-2.2.3.dist-info/
-drwxr-xr-x  2.0 unx        0 b- stor 23-May-01 03:48 internal/
--rwxr-xr-x  2.0 unx  7209113 b- defN 23-May-01 03:48 _kSpider_internal.cpython-39-x86_64-linux-gnu.so
--rwxr-xr-x  2.0 unx   168193 b- defN 23-May-01 03:48 DBRetina.libs/libgomp-a34b3233.so.1.0.0
--rwxr-xr-x  2.0 unx    70993 b- defN 23-May-01 03:48 DBRetina.libs/libbz2-a273e504.so.1.0.6
--rw-r--r--  2.0 unx      870 b- defN 23-May-01 03:48 kSpider2/customLogger.py
--rw-r--r--  2.0 unx     4351 b- defN 23-May-01 03:48 kSpider2/ks_pairwise.py
--rw-r--r--  2.0 unx     8439 b- defN 23-May-01 03:48 kSpider2/ks_query_dbretina.py
--rw-r--r--  2.0 unx     5222 b- defN 23-May-01 03:48 kSpider2/ks_index.py
--rw-r--r--  2.0 unx     1837 b- defN 23-May-01 03:48 kSpider2/ks_dataset_indexing.py
--rw-r--r--  2.0 unx      859 b- defN 23-May-01 03:48 kSpider2/kSpider_main.py
--rw-r--r--  2.0 unx     9091 b- defN 23-May-01 03:48 kSpider2/ks_filter.py
--rw-r--r--  2.0 unx       37 b- defN 23-May-01 03:48 kSpider2/__init__.py
--rw-r--r--  2.0 unx     1467 b- defN 23-May-01 03:48 kSpider2/click_context.py
--rw-r--r--  2.0 unx     3316 b- defN 23-May-01 03:48 kSpider2/ks_fastx_to_kfs.py
--rw-r--r--  2.0 unx     5594 b- defN 23-May-01 03:48 kSpider2/ks_export.py
--rw-r--r--  2.0 unx      357 b- defN 23-May-01 03:48 kSpider2/kSpider_version.py
--rw-r--r--  2.0 unx      719 b- defN 23-May-01 03:48 kSpider2/ks_sketch_dbretina.py
--rw-r--r--  2.0 unx     9971 b- defN 23-May-01 03:48 kSpider2/ks_clustering.py
--rw-r--r--  2.0 unx     1054 b- defN 23-May-01 03:48 DBRetina-2.2.3.dist-info/METADATA
--rw-r--r--  2.0 unx       42 b- defN 23-May-01 03:48 DBRetina-2.2.3.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       53 b- defN 23-May-01 03:48 DBRetina-2.2.3.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2114 b- defN 23-May-01 03:48 DBRetina-2.2.3.dist-info/RECORD
--rw-r--r--  2.0 unx      148 b- defN 23-May-01 03:48 DBRetina-2.2.3.dist-info/WHEEL
--rw-r--r--  2.0 unx     1082 b- defN 23-May-01 03:48 DBRetina-2.2.3.dist-info/LICENSE
--rw-r--r--  2.0 unx     2784 b- defN 23-May-01 03:48 internal/kSpider_internal.py
--rw-r--r--  2.0 unx       32 b- defN 23-May-01 03:48 internal/__init__.py
-29 files, 7507738 bytes uncompressed, 1920924 bytes compressed:  74.4%
+Zip file size: 1925656 bytes, number of entries: 29
+drwxr-xr-x  2.0 unx        0 b- stor 23-May-02 02:59 DBRetina.libs/
+drwxr-xr-x  2.0 unx        0 b- stor 23-May-02 02:59 DBRetina-2.2.4.dist-info/
+drwxr-xr-x  2.0 unx        0 b- stor 23-May-02 02:59 kSpider2/
+drwxr-xr-x  2.0 unx        0 b- stor 23-May-02 02:59 internal/
+-rwxr-xr-x  2.0 unx  7209113 b- defN 23-May-02 02:59 _kSpider_internal.cpython-39-x86_64-linux-gnu.so
+-rwxr-xr-x  2.0 unx   168193 b- defN 23-May-02 02:59 DBRetina.libs/libgomp-a34b3233.so.1.0.0
+-rwxr-xr-x  2.0 unx    70993 b- defN 23-May-02 02:59 DBRetina.libs/libbz2-a273e504.so.1.0.6
+-rw-r--r--  2.0 unx     1054 b- defN 23-May-02 02:59 DBRetina-2.2.4.dist-info/METADATA
+-rw-r--r--  2.0 unx       42 b- defN 23-May-02 02:59 DBRetina-2.2.4.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       53 b- defN 23-May-02 02:59 DBRetina-2.2.4.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2115 b- defN 23-May-02 02:59 DBRetina-2.2.4.dist-info/RECORD
+-rw-r--r--  2.0 unx      148 b- defN 23-May-02 02:59 DBRetina-2.2.4.dist-info/WHEEL
+-rw-r--r--  2.0 unx     1082 b- defN 23-May-02 02:59 DBRetina-2.2.4.dist-info/LICENSE
+-rw-r--r--  2.0 unx      870 b- defN 23-May-02 02:59 kSpider2/customLogger.py
+-rw-r--r--  2.0 unx     4351 b- defN 23-May-02 02:59 kSpider2/ks_pairwise.py
+-rw-r--r--  2.0 unx     8436 b- defN 23-May-02 02:59 kSpider2/ks_query_dbretina.py
+-rw-r--r--  2.0 unx     5222 b- defN 23-May-02 02:59 kSpider2/ks_index.py
+-rw-r--r--  2.0 unx     1837 b- defN 23-May-02 02:59 kSpider2/ks_dataset_indexing.py
+-rw-r--r--  2.0 unx      859 b- defN 23-May-02 02:59 kSpider2/kSpider_main.py
+-rw-r--r--  2.0 unx    10672 b- defN 23-May-02 02:59 kSpider2/ks_filter.py
+-rw-r--r--  2.0 unx       37 b- defN 23-May-02 02:59 kSpider2/__init__.py
+-rw-r--r--  2.0 unx     1467 b- defN 23-May-02 02:59 kSpider2/click_context.py
+-rw-r--r--  2.0 unx     3316 b- defN 23-May-02 02:59 kSpider2/ks_fastx_to_kfs.py
+-rw-r--r--  2.0 unx     9330 b- defN 23-May-02 02:59 kSpider2/ks_export.py
+-rw-r--r--  2.0 unx      312 b- defN 23-May-02 02:59 kSpider2/kSpider_version.py
+-rw-r--r--  2.0 unx      719 b- defN 23-May-02 02:59 kSpider2/ks_sketch_dbretina.py
+-rw-r--r--  2.0 unx     8916 b- defN 23-May-02 02:59 kSpider2/ks_clustering.py
+-rw-r--r--  2.0 unx     2784 b- defN 23-May-02 02:59 internal/kSpider_internal.py
+-rw-r--r--  2.0 unx       32 b- defN 23-May-02 02:59 internal/__init__.py
+29 files, 7511953 bytes uncompressed, 1921866 bytes compressed:  74.4%
```

## zipnote {}

```diff
@@ -1,28 +1,46 @@
 Filename: DBRetina.libs/
 Comment: 
 
-Filename: kSpider2/
+Filename: DBRetina-2.2.4.dist-info/
 Comment: 
 
-Filename: DBRetina-2.2.3.dist-info/
+Filename: kSpider2/
 Comment: 
 
 Filename: internal/
 Comment: 
 
 Filename: _kSpider_internal.cpython-39-x86_64-linux-gnu.so
 Comment: 
 
 Filename: DBRetina.libs/libgomp-a34b3233.so.1.0.0
 Comment: 
 
 Filename: DBRetina.libs/libbz2-a273e504.so.1.0.6
 Comment: 
 
+Filename: DBRetina-2.2.4.dist-info/METADATA
+Comment: 
+
+Filename: DBRetina-2.2.4.dist-info/entry_points.txt
+Comment: 
+
+Filename: DBRetina-2.2.4.dist-info/top_level.txt
+Comment: 
+
+Filename: DBRetina-2.2.4.dist-info/RECORD
+Comment: 
+
+Filename: DBRetina-2.2.4.dist-info/WHEEL
+Comment: 
+
+Filename: DBRetina-2.2.4.dist-info/LICENSE
+Comment: 
+
 Filename: kSpider2/customLogger.py
 Comment: 
 
 Filename: kSpider2/ks_pairwise.py
 Comment: 
 
 Filename: kSpider2/ks_query_dbretina.py
@@ -57,32 +75,14 @@
 
 Filename: kSpider2/ks_sketch_dbretina.py
 Comment: 
 
 Filename: kSpider2/ks_clustering.py
 Comment: 
 
-Filename: DBRetina-2.2.3.dist-info/METADATA
-Comment: 
-
-Filename: DBRetina-2.2.3.dist-info/entry_points.txt
-Comment: 
-
-Filename: DBRetina-2.2.3.dist-info/top_level.txt
-Comment: 
-
-Filename: DBRetina-2.2.3.dist-info/RECORD
-Comment: 
-
-Filename: DBRetina-2.2.3.dist-info/WHEEL
-Comment: 
-
-Filename: DBRetina-2.2.3.dist-info/LICENSE
-Comment: 
-
 Filename: internal/kSpider_internal.py
 Comment: 
 
 Filename: internal/__init__.py
 Comment: 
 
 Zip file comment:
```

## kSpider2/ks_query_dbretina.py

```diff
@@ -22,15 +22,15 @@
 def plot_histogram(features_counts, output_file):
     # Set style and context to make a nicer plot
     sns.set_style("whitegrid")
     # sns.set_context("talk")
 
     plt.figure(figsize=(10, 6))  # Set the figure size
     plot = sns.histplot(features_counts, color='skyblue', edgecolor='black',
-                        stat='count', bins=50, discrete=True)  # Generate histogram with KDE
+                        stat='count', bins=10, discrete=False)  # Generate histogram with KDE
 
     plt.title('Histogram of features frequencies')  # Set the title
     plt.xlabel('Feature frequency')  # Set the x-label
     plt.ylabel('Count (log scale)')  # Set the y-label
     plt.yscale('log')
 
 # Add a legend
@@ -100,15 +100,15 @@
     Query a DBRetina index with a set of groups (provided as a single-column file or cluster IDs in a DBRetina cluster file). Output each feature and the associated supergroups.
     
 
 Examples:
 
     1- groups file                    | DBRetina query -i index_prefix -g groups_file -o output_prefix
 
-    
+
     2- clusters file with cluster IDs | DBRetina query -i index_prefix --clusters-file clusters_file --cluster-ids 1,2,3 -o output_prefix
 
     
     """
     
     
     # Inverting the index
```

## kSpider2/ks_filter.py

```diff
@@ -66,44 +66,56 @@
             'Numbers must be a comma-separated list of integers') from e
 
 
 def path_to_absolute_path(ctx, param, value):
     return value if value == "NA" else os.path.abspath(value)
 
 
+
+def get_extended_nodes(nodes, kmer_size):
+    
+    return extended_nodes
+
+
+
 @cli.command(name="filter", help_priority=3)
 @click.option('-p', '--pairwise', 'pairwise_file', callback=path_to_absolute_path, required=True, type=click.Path(exists=True), help="the pairwise TSV file")
 @click.option('-g', '--groups-file', "groups_file", callback=path_to_absolute_path, required=False, default="NA", type=click.Path(exists=False), help="single-column supergroups file")
 @click.option('--clusters-file', "clusters_file", callback=path_to_absolute_path, required=False, default="NA", type=click.Path(exists=False), help="DBRetina clusters file")
 @click.option('--cluster-ids', "cluster_ids", callback=validate_numbers, required=False, default="", help="comma-separated list of cluster IDs")
 @click.option('-d', '--dist-type', "distance_type", required=False, default="NA", show_default=True, type=click.STRING, help="select from ['min_cont', 'avg_cont', 'max_cont', 'ochiai', 'jaccard']")
 @click.option('-c', '--cutoff', required=False, type=click.FloatRange(0, 100, clamp=False), default=0.0, show_default=True, help="filter out distances < cutoff")
+@click.option('--extend', "extend", is_flag=True, default=False, show_default=True, help="include all supergroups that are linked to the given supergroups.")
 @click.option('-o', '--output', "output_file", required=True, type=click.STRING, help="output file prefix")
 @click.pass_context
-def main(ctx, pairwise_file, groups_file, distance_type, cutoff, output_file, clusters_file, cluster_ids):
+def main(ctx, pairwise_file, groups_file, distance_type, cutoff, output_file, clusters_file, cluster_ids, extend):
     """Filter a pairwise file.
 
 
 Detailed description:
 
     Filter a pairwise file by distance cutoff and/or a set of groups (provided as a single-column file or cluster IDs in a DBRetina cluster file).
 
 Examples:
 
-    1- distance cutoff only              | dbretina filter -p pairwise.tsv -d ochiai -c 0.5 -o filtered.tsv
+    1- distance cutoff only              | dbretina filter -p pairwise.tsv -d ochiai -c 60 -o filtered.tsv
 
-    2- distance cutoff and groups file   | dbretina filter -p pairwise.tsv -d min_cont -c 0.5 -g groups.tsv -o filtered.tsv
+    2- distance cutoff and groups file   | dbretina filter -p pairwise.tsv -d min_cont -c 97 -g groups.tsv -o filtered.tsv
 
-    3- distance cutoff and a cluster IDs | dbretina filter -p pairwise.tsv -d max_cont -c 0.5 --clusters-file clusters.tsv --clusters-id 8 -o filtered.tsv
+    3- distance cutoff and a cluster IDs | dbretina filter -p pairwise.tsv -d max_cont -c 77 --clusters-file clusters.tsv --clusters-id 8 -o filtered.tsv
 
     4- groups file only                  | dbretina filter -p pairwise.tsv -g groups.tsv -o filtered.tsv
 
     5- cluster file with cluster IDs     | dbretina filter -p pairwise.tsv --clusters-file clusters.tsv --clusters-id 8 -o filtered.tsv 
     """
     
+    # Extend must be used only when clusters file or groups file is provided
+    if extend and groups_file == "NA" and clusters_file == "NA":
+        ctx.obj.ERROR("DBRetina's filter command requires a groups_file or clusters_file if --extend is provided.")
+        
 
     # check if not any option is provided for filteration
     if distance_type == "NA" and cutoff == 0.0 and groups_file == "NA" and clusters_file == "NA":
         ctx.obj.ERROR(
             "DBRetina's filter command requires at least one option to filter the pairwise file.")
 
     # if clusters_file then must be cluster_id
@@ -138,16 +150,15 @@
         "ochiai": 8,
         "jaccard": 9,
     }
     if distance_type in distance_to_col:
         # +1 because awk is 1-indexed
         awk_column = distance_to_col[distance_type] + 1
     elif distance_type != "NA":
-        ctx.obj.ERROR(
-            f"DBRetina's filter command doesn't support the distance_type {distance_type}.")
+        ctx.obj.ERROR(f"DBRetina's filter command doesn't support the distance_type {distance_type}.")
 
     # check if output_file already exist
     output_file += ".tsv"
     if os.path.exists(output_file):
         ctx.obj.WARNING(f"Output file {output_file} already exists, overwriting ...")
 
     if groups_file != "NA" and not os.path.exists(groups_file):
@@ -170,36 +181,53 @@
 
     _tmp_file = ".DBRetina.tmp.group"
 
     all_ids = set()
     if clusters_file != "NA":
         groups_file = _tmp_file
         with open(clusters_file) as f, open(_tmp_file, 'w') as W:
-            
+
             # skip comments
             while True:
                 pos = f.tell()
                 line = f.readline()
                 if not line.startswith('#'):
                     f.seek(pos)
                     break
-            
+
             next(f)
             for line in f:
                 line = line.strip().split('\t')
                 cluster_id = int(line[0])
                 if cluster_id in cluster_ids:
                     all_ids.add(cluster_id)
                     W.write(line[2].replace('|', '\n') + '\n')
 
     unfound_ids = set(cluster_ids).difference(all_ids)
     if len(unfound_ids):
         ctx.obj.WARNING(
             f"Couldn't find the following cluster IDs: {unfound_ids}")
 
+    
+    extended_ids_list = ".DBRetina_extended_ids_list"
+    
+    with open(extended_ids_list, 'w') as f:
+        f.write("")
+    
+    if extend:
+        # awk_script = f"""grep '^[^#;]' {pairwise_file} | tail -n+2 | LC_ALL=C awk -F'\t' 'BEGIN {{ while ( getline < "{groups_file}" ) {{ gsub(/"/, "", $1); id_map[tolower($1)]=1 }} }} {{ if ( ($3 in id_map) || ($4 in id_map) ) {{ print $3 >> "{extended_ids_list}"; print $4 >> "{extended_ids_list}"}} }}'"""
+        
+        awk_script = f"""grep '^[^#;]' {pairwise_file} | tail -n+2 | LC_ALL=C awk -F'\t' 'BEGIN {{ while ( getline < "{groups_file}" ) {{ gsub(/"/, "", $1); id_map[tolower($1)]=1 }} }} {{ if ( (tolower($3) in id_map) || (tolower($4) in id_map) ) {{ print $0 }} }}' | awk -F'\t' '{{if (${awk_column} >= {cutoff}) {{ print $3 >> "{extended_ids_list}"; print $4 >> "{extended_ids_list}"}}}}'"""
+        
+        result = execute_bash_command(awk_script)
+        bash_script = f"""sort -u {extended_ids_list} -o {extended_ids_list}.uniq"""
+        result = execute_bash_command(bash_script)
+        groups_file = extended_ids_list + '.uniq'
+
+   
     # filter by both cutoff and groups
     if cutoff != 0.0 and groups_file != "NA":
         awk_script = f"""grep '^[^#;]' {pairwise_file} | tail -n+2 | LC_ALL=C awk -F'\t' 'BEGIN {{ while ( getline < "{groups_file}" ) {{ gsub(/"/, "", $1); id_map[tolower($1)]=1 }} }} {{ if ( (tolower($3) in id_map) && (tolower($4) in id_map) ) {{ print $0 }} }}' | awk -F'\t' '{{if (${awk_column} >= {cutoff}) print $0}}' >> {output_file}"""
         result = execute_bash_command(awk_script)
 
     elif cutoff != 0.0:
         ctx.obj.INFO(
@@ -208,12 +236,13 @@
         result = execute_bash_command(command)
 
     elif groups_file != "NA":
         ctx.obj.INFO(f"Filtering by groups file {groups_file}\nPlease wait...")
         awk_script = f"""grep '^[^#;]' {pairwise_file} | tail -n+2 |LC_ALL=C awk -F'\t' 'BEGIN {{ while ( getline < "{groups_file}" ) {{ gsub(/"/, "", $1); id_map[tolower($1)]=1 }} }} {{ if ( (tolower($3) in id_map) && (tolower($4) in id_map) ) {{ print $0 }} }}' >> {output_file}"""
         result = execute_bash_command(awk_script)
 
+
     # if _tmp_file exists, remove it
     if os.path.exists(_tmp_file):
         os.remove(_tmp_file)
 
     ctx.obj.SUCCESS("Done.")
```

## kSpider2/ks_export.py

```diff
@@ -4,15 +4,22 @@
 
 import os
 import click
 import pandas as pd
 from kSpider2.click_context import cli
 from scipy.cluster.hierarchy import linkage, to_tree, ClusterWarning
 from warnings import simplefilter
+import seaborn as sns
+import matplotlib.pyplot as plt
+import numpy as np
+from scipy.cluster.hierarchy import linkage, to_tree
+from ete3 import Tree
+from scipy.spatial.distance import squareform, pdist
 simplefilter("ignore", ClusterWarning)
+import math
 import re
 
 # def newick_str_escape(s):
 #     return s.replace('(', '-').replace(')', '-').replace(',', '-').replace(' ', '-')
 
 def newick_str_escape(name):
     # Remove special characters
@@ -40,22 +47,99 @@
         newick = get_newick(node.get_left(), node.dist,
                             leaf_names, newick=newick)
         newick = get_newick(node.get_right(), node.dist,
                             leaf_names, newick=",%s" % (newick))
         newick = "(%s" % (newick)
         return newick
 
+def generate_heatmap(df):
+    # Ensure DataFrame is numeric
+    # Set up figure and axes
+    fig, ax = plt.subplots(figsize=(10, 8))
+
+    # Generate a mask for the upper triangle
+    mask = np.triu(np.ones_like(df, dtype=bool))
+
+    # Generate a custom diverging colormap
+    cmap = sns.diverging_palette(230, 20, as_cmap=True)
+
+    # Draw the heatmap
+    sns.heatmap(df, mask=mask, cmap=cmap, center=0, square=True, linewidths=.5, cbar_kws={"shrink": .5}, ax=ax, annot=False, fmt=".2f")
+
+    # Set the title
+    ax.set_title('Heatmap')
+
+    # Rotate the x-axis labels
+    # ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')
+    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')
+    
+    # Rotate the y-axis labels
+    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)
+
+    # Show the plot
+    plt.tight_layout()
+    plt.savefig("heatmap.png", dpi=500)
+
+
+# click callback to make sure it's selected from ['ids', 'names']
+def validate_labels(ctx, param, value):
+    if value not in ['ids', 'names']:
+        raise click.BadParameter('labels must be one of ids, names')
+    return value
+
+def dataframe_to_newick(df):
+    np.fill_diagonal(df.values, 0)
+    condensed_matrix = squareform(df)
+    Z = linkage(condensed_matrix, 'single')
+    tree = to_tree(Z, rd=False)
+    return tree_to_newick(tree, list(df.columns))
+
+def tree_to_newick(node, leaf_names):
+    if node.is_leaf():
+        return leaf_names[node.id]
+    left_child = tree_to_newick(node.get_left(), leaf_names)
+    right_child = tree_to_newick(node.get_right(), leaf_names)
+    return f"({left_child}:{node.dist:.2f},{right_child}:{node.dist:.2f})"
+
+
+def similarity_df_to_newick(similarity_df, method='average'):
+    # Convert similarity matrix to dissimilarity matrix
+    dissimilarity_df = 100 - similarity_df
+
+    # Ensure the diagonal is zero
+    np.fill_diagonal(dissimilarity_df.values, 0)
+
+    # Convert the dissimilarity matrix DataFrame to a condensed distance matrix for linkage
+    # condensed_distance_matrix = squareform(dissimilarity_df)
+    condensed_distance_matrix = pdist(dissimilarity_df, 'euclidean')
+
+    # Perform hierarchical/agglomerative clustering
+    Z = linkage(condensed_distance_matrix, method)
+
+    # Convert linkage matrix to a tree
+    tree = to_tree(Z, rd=False)
+
+    return tree_to_newick(tree, list(similarity_df.columns))
+
+def tree_to_newick(node, leaf_names):
+    if node.is_leaf():
+        return leaf_names[node.id]
+    left_child = tree_to_newick(node.get_left(), leaf_names)
+    right_child = tree_to_newick(node.get_right(), leaf_names)
+    return f"({left_child}:{node.dist:.2f},{right_child}:{node.dist:.2f})"
+
 
 @cli.command(name="export", help_priority=5)
 @click.option('-p', '--pairwise', 'pairwise_file', required=True, type=click.Path(exists=True), help="filtered pairwise TSV file")
-@click.option('--newick', "newick", is_flag=True, help="Convert pairwise (containment) matrix to newick format", default=False)
 @click.option('-d', '--dist-type', "distance_type", required=False, default="max_cont", show_default=True, type=click.STRING, help="select from ['min_cont', 'avg_cont', 'max_cont', 'ochiai', 'jaccard']")
-@click.option('-o', "overwritten_output", default="na", required=False, type=click.STRING, help="custom output file name prefix")
+@click.option('--newick', "newick", is_flag=True, help="Convert the dissimilarity matrix to newick tree format", default=False)
+@click.option('-l', '--labels', "labels_selection", callback = validate_labels, required=False, default="ids", show_default=True, type=click.STRING, help="select from ['ids', 'names']")
+@click.option('-o', "output_prefix", required=True, type=click.STRING, help="output prefix")
 @click.pass_context
-def main(ctx, index_prefix, pairwise_file, newick, distance_type, overwritten_output):
+def main(ctx, pairwise_file, newick, distance_type, output_prefix, labels_selection):
     """Export to dissimilarity matrix and newick format.
     
     Export a pairwise TSV file to a dissimilarity matrix and (optionally) a newick-format file.
     
     """
  
     LOGGER = ctx.obj
@@ -74,76 +158,88 @@
     dist_col = distance_to_col[distance_type]    
 
     # Check for existing pairwise file
     for _file in [pairwise_file]:
         if not os.path.exists(_file):
             LOGGER.ERROR(f"File {_file} is not found.")
 
-    """Parse DBRetina's pairwise
-    """
 
-    distances = {}    
-    newick_out = pairwise_file.replace(".tsv", f"_{distance_type}.newick")
-    distmatrix_out = pairwise_file.replace(".tsv", f"_{distance_type}_distmat.tsv")
-
-    if overwritten_output != "na":
-        distmatrix_out = f"{overwritten_output}_{distance_type}_distmat.tsv"
-        newick_out = f"{overwritten_output}_{distance_type}.newick"
-
-    with open(pairwise_file) as PAIRWISE:
-        next(PAIRWISE) # Skip header
-        for line in PAIRWISE:
-            line = (line.strip().split('\t'))
-            # add double quotes to group names
-            grp1 = newick_str_escape(line[2])
-            grp2 = newick_str_escape(line[3])
-            # grp1 = f"\"{line[2]}\"".replace(" ", "_")
-            # grp2 = f"\"{line[3]}\"".replace(" ", "_")
-            dist_metric = float(line[dist_col])
-            # convert xx% to 0.xx for the distance matrix
-            distances[(grp1, grp2)] = dist_metric / 100
-
-
-    elements = set()
-    # for pair in distances.keys():
-    #     elements.update(pair[:2])
-    # index_map = {element: i for i, element in enumerate(sorted(elements))}
-    # n = len(elements)
-    # dist_matrix = np.zeros((n, n))
-    # # Fill in the upper triangle of the distance matrix with the pairwise distances
-    # for (src1, src2), dist in distances.items():
-    #     i = index_map[src1]
-    #     j = index_map[src2]
-    #     dist_matrix[i, j] = dist_matrix[j, i] = dist
-    # src_names = sorted(elements)
-    # dist_df = pd.DataFrame(dist_matrix, index=src_names, columns=src_names)
-    # dist_df.to_csv(distmatrix_out + ".new.tsv", sep='\t')
-
-
-    unique_ids = sorted({x for y in distances for x in y})
-    df = pd.DataFrame(index=unique_ids, columns=unique_ids)
-    for k, v in distances.items():
-        # 1-v for dissimilarity
-        df.loc[k[0], k[1]] = 1-v
-        df.loc[k[1], k[0]] = 1-v
-
-    df = df.fillna(0)
-    LOGGER.INFO(f"Writing distance matrix to {distmatrix_out}")
-    df.to_csv(distmatrix_out, sep='\t')
+    # Parse DBRetina's pairwise
+    
+    if labels_selection == "ids": src1_label_col = 0; src2_label_col = 1
+    else: src1_label_col = 2; src2_label_col = 3
+    
+    df = pd.read_csv(pairwise_file, sep='\t', usecols=[src1_label_col, src2_label_col, dist_col], comment='#')
+    
+    if labels_selection == "ids":    
+        df[df.columns[0]] = df[df.columns[0]].astype(str)
+        df[df.columns[1]] = df[df.columns[1]].astype(str)
+    else: # escape newick_str_escape
+        df[df.columns[0]] = df[df.columns[0]].apply(lambda x: newick_str_escape(x))
+        df[df.columns[1]] = df[df.columns[1]].apply(lambda x: newick_str_escape(x))
+    
+    df[df.columns[2]] = df[df.columns[2]].apply(lambda x: math.log2(x) if x != 0 else 0)
+    
+    similarity_df = df.pivot(index=df.columns[0], columns=df.columns[1], values=df.columns[2])
+
+    similarity_df = similarity_df.combine_first(similarity_df.T).fillna(0)
+    np.fill_diagonal(similarity_df.values, math.log2(100))
+    
+
+    # np.fill_diagonal(matrix_df.values, 0)
+    # dissimilarity_df = 100 - matrix_df
+    # dissimilarity_df = dissimilarity_df.combine_first(dissimilarity_df.T)
+    # dissimilarity_df.fillna(0, inplace=True)
+
+    
+    # Create a custom diverging colormap
+    # cmap = sns.diverging_palette(230, 20, as_cmap=True)
+    # cmap = sns.diverging_palette(250, 15, s=75, l=40, n=1, center="light", as_cmap=True)
+    # cmap = sns.diverging_palette(250, 15, s=75, l=40, n=6, center="light", as_cmap=True, sep=77)
+    # cmap = sns.dark_palette("xkcd:golden", 8)
+    # cmap = sns.diverging_palette(0, 255, sep=77, as_cmap=True)
+    # cmap = sns.light_palette("black", as_cmap=True)
+    # cmap = sns.color_palette("icefire", as_cmap=True)
+    # cmap = sns.color_palette("colorblind", as_cmap=True)
+    cmap = sns.color_palette("Spectral", as_cmap=True)
+    g = sns.clustermap(
+        similarity_df, 
+        cmap=cmap, 
+        center=0, 
+        linewidths=.5, 
+        figsize=(10, 10), 
+        row_cluster=True, 
+        col_cluster=True, 
+        vmin=0, 
+        vmax=math.log2(100),
+        # method = 'single',
+        # metric='braycurtis',
+        )
+    plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, horizontalalignment='right')
+    plt.setp(g.ax_heatmap.get_yticklabels(), rotation=0)
+    g.cax.set_title('Similarity', loc='left', fontsize=12, fontweight='bold')
+    
+    
+    # serialize distance matrix to binary format
+    LOGGER.INFO(f"serializing the distance matrix to {output_prefix}_distmat.pkl")
+    similarity_df.to_pickle(f"{output_prefix}_distmat.pkl")
+    LOGGER.INFO(f"Writing distance matrix to {output_prefix}_distmat.tsv")
+    similarity_df.to_csv(f"{output_prefix}_distmat.tsv", sep='\t')
+    
+
+    newick_out = f"{output_prefix}.newick"
+
+    LOGGER.INFO(f"Writing clustermap plot to {output_prefix}_clustermap.png")
+    plt.savefig(f"{output_prefix}_clustermap.png", dpi=600)
+    
 
     if newick:
-        loaded_df = pd.read_csv(distmatrix_out, sep='\t')
-        LOGGER.INFO(f"Writing newick to {newick_out}.")
-        names = list(loaded_df.columns[1:])
-        dist = loaded_df[loaded_df.columns[1:]].to_numpy()
-        Z = linkage(dist, 'average')
-        tree = to_tree(Z, False)
+        # Call the function with your similarity DataFrame and 'single' linkage method
         try:
-            newick = get_newick(tree, tree.dist, names)
+            newick_string = similarity_df_to_newick(similarity_df, 'average')
             with open(newick_out, 'w') as NW:
-                NW.write(newick)
+                    NW.write(newick_string)
 
         except RecursionError as err:
-            LOGGER.ERROR(f"Couldn't handle the tree depth | {err}")    
-        
+            LOGGER.ERROR(f"Couldn't handle the tree depth | {err}")
 
     LOGGER.SUCCESS("Done.")
```

## kSpider2/kSpider_version.py

```diff
@@ -1,18 +1,15 @@
 import os
-import json
-import urllib.request
-import sys
 
 #TODO there are two files with DBRetina_version, remove one.
 
 # Only update this when releasing stable
 MAJOR = 2
 MINOR = 2
-PATCH = 3
+PATCH = 4
 
 PYPI_PACKAGE = "DBRetina"
 
 def is_github_action():
     return "GITHUB_WORKFLOW" in dict(os.environ)
```

## kSpider2/ks_clustering.py

```diff
@@ -94,67 +94,35 @@
                     self.graph.add_edges_from(edges_tuples)
                     batch_counter = 0
                     edges_tuples.clear()
 
             if len(edges_tuples):
                 self.graph.add_edges_from(edges_tuples)
 
-    def plot_histogram2(self, cluster_sizes):
-        plt.figure(figsize=(10, 6))
-        sns.set_style('whitegrid')
-        sns.histplot(cluster_sizes, kde=True, color='darkblue', bins=math.ceil(max(cluster_sizes)/10))
-        plt.title('Histogram of Cluster Sizes', fontsize=20)
-        plt.xlabel('Cluster Sizes', fontsize=15)
-        plt.ylabel('Count', fontsize=15)
-        plt.yscale('log')
-        plt.savefig(f"{self.output_prefix}_DBRetina_clusters.png", dpi=500)
-    
     def plot_histogram(self, cluster_sizes):
         # Set style and context to make a nicer plot
         sns.set_style("whitegrid")
         # sns.set_context("talk")
 
         plt.figure()  # Set the figure size
-        plot = sns.histplot(cluster_sizes, color='skyblue', edgecolor='black', stat='count', bins=50, discrete=True)  # Generate histogram with KDE
+        plot = sns.histplot(cluster_sizes, color='skyblue', edgecolor='black', stat='count', bins=10, discrete=False)  # Generate histogram with KDE
         # plot = sns.(cluster_sizes, color='skyblue', edgecolor='black', stat='count', bins=50, hue=False)  # Generate histogram with KDE
 
         plt.title('Histogram of Cluster Sizes')  # Set the title
         plt.xlabel('Cluster Sizes')  # Set the x-label
         plt.ylabel('Count (log scale)')  # Set the y-label
         plt.yscale('log')
-        plt.xticks(np.arange(min(cluster_sizes), max(cluster_sizes)+1, 1))
+        # plt.xticks(np.arange(min(cluster_sizes), max(cluster_sizes)+1, 1))
 
         
         # Add a legend
         # plot.legend(labels=['Cluster Sizes'])
         # plt.show()
-        plt.savefig(f"{self.output_prefix}_clusters.png", dpi=500)
-
-    def plot_histogram3(self, data):
-        """
-        This function creates a histogram using seaborn.
-
-        Parameters:
-        data (list): A list of numeric values.
-        """
-        
-        # Setting the style of seaborn to have better visuals
-        sns.set(style="whitegrid")
+        plt.savefig(f"{self.output_prefix}_clusters_histogram.png", dpi=500)
 
-        # Creating the histogram
-        plt.figure(figsize=(10,6))
-        bins = int((len(data)/2))  # square-root choice
-        sns.histplot(data, bins=bins, color='skyblue', kde=False)
-
-        # Setting labels and title
-        plt.xlabel('Values', fontsize=13)
-        plt.ylabel('Frequency', fontsize=13)
-        plt.title('Histogram', fontsize=16)
-        plt.show()
-        plt.savefig(f"{self.output_prefix}_clusters.png", dpi=500)
 
     def plot_bubbles(self, cluster_sizes):
          # Create a new figure
         fig, ax = plt.subplots(figsize=(10, 6))
         
         # Set the style using seaborn
         sns.set_style("whitegrid")
@@ -193,32 +161,34 @@
         self.connected_components = rx.connected_components(self.graph)
         single_components = 0
         retworkx_export = f"{self.output_prefix}_clusters.tsv"
         # and {self.output} ...")
         self.Logger.INFO(f"writing {retworkx_export}")
         # rx.node_link_json(self.graph, path = retworkx_export)
         cluster_id = 1
+        total_clustered_nodes = 0
         with open(retworkx_export, 'w') as CLUSTERS:
             for metadata_line in self.metadata:
                 CLUSTERS.write(metadata_line)
 
             CLUSTERS.write(f"cluster_id\tcluster_size\tcluster_members\n")
             for component in self.connected_components:
                 # uncomment to exclude single genome clusters from exporting
-                if len(component) == 1 and list(component)[0] + 1 not in self.original_nodes:
+                if len(component) == 1: # and list(component)[0] + 1 not in self.original_nodes:
                     continue
-                named_component = [self.original_nodes[node + 1]
-                                   for node in component]
+                
+                named_component = [self.original_nodes[node + 1] for node in component]
                 # CLUSTERS.write(cluster_id + '\t' + len(component) + '\t' + '|'.join(named_component) + '\n')
-                CLUSTERS.write(
-                    f"{cluster_id}\t{len(component)}\t{'|'.join(named_component)}\n")
+                CLUSTERS.write(f"{cluster_id}\t{len(component)}\t{'|'.join(named_component)}\n")
                 cluster_sizes.append(len(component))
+                total_clustered_nodes += len(component)
                 cluster_id += 1
 
         self.Logger.INFO("plotting cluster sizes histogram and bubble plot")
+        self.Logger.INFO(f"Total number of clustered supergroups: {total_clustered_nodes}")
         self.plot_histogram(cluster_sizes)
         self.plot_bubbles(cluster_sizes)
         self.Logger.INFO(f"number of clusters: {cluster_id - 1}")
 
 
 """
 TODO:
```

## Comparing `DBRetina-2.2.3.dist-info/METADATA` & `DBRetina-2.2.4.dist-info/METADATA`

 * *Files 7% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: DBRetina
-Version: 2.2.3
+Version: 2.2.4
 Summary: DBRetina Python Package
 License: BSD 3-Clause
 Project-URL: Bug Reports, https://github.com/DBRetina/DBRetina/issues
 Project-URL: Source, https://github.com/DBRetina/DBRetina/issues
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Development Status :: 3 - Alpha
 Classifier: Operating System :: POSIX :: Linux
```

## Comparing `DBRetina-2.2.3.dist-info/RECORD` & `DBRetina-2.2.4.dist-info/RECORD`

 * *Files 15% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 _kSpider_internal.cpython-39-x86_64-linux-gnu.so,sha256=rNIdDOc1LdFpSWFA47fHAr0sl_T99sjX6eaotv3DE_Y,7209113
 DBRetina.libs/libgomp-a34b3233.so.1.0.0,sha256=On6uznIxkRvi-7Gz58tMtcLg-E4MK7c3OUcrWh_uyME,168193
 DBRetina.libs/libbz2-a273e504.so.1.0.6,sha256=Ks7i35uwgx4aPZalUSQBwyfxeXGQ9BGdNInwVf00yb8,70993
+DBRetina-2.2.4.dist-info/METADATA,sha256=pmyWBvkBmhYEfAB2p895WABFsV0tM6qA0Cr78-iUolI,1054
+DBRetina-2.2.4.dist-info/entry_points.txt,sha256=HuUvdKaCNqW3VFtVnm6P-dCDkkOrVT-niI2-1C7LswI,42
+DBRetina-2.2.4.dist-info/top_level.txt,sha256=mgN01IsYPX0F4K0TlzJVvZm5nddBiNlhZMuGa4sAf8Q,53
+DBRetina-2.2.4.dist-info/RECORD,,
+DBRetina-2.2.4.dist-info/WHEEL,sha256=gREe7-l-MJWbGZG46A7WHnwwUSxA3XJYHQvGGLzmBNU,148
+DBRetina-2.2.4.dist-info/LICENSE,sha256=W1bnRBpBo-y-J4DWTqaty5UL5CzCiFqfgJX9nC87KKo,1082
 kSpider2/customLogger.py,sha256=Xx_sO1daEiRFTndMI2FEDUL4T_DHvKm38sUZ2yNXhh0,870
 kSpider2/ks_pairwise.py,sha256=NxVAYGCqEk6oNxwhWE1JumPQCTBh5j2BWB0FZXm8DvI,4351
-kSpider2/ks_query_dbretina.py,sha256=xqdT19PikASP5zOeeROR8syCo3LUZHJRngjqbjVuwRA,8439
+kSpider2/ks_query_dbretina.py,sha256=CFQAXKiY4cDXfWpfnp8YA__FAZGUbFBv1cJZ6y-eoUs,8436
 kSpider2/ks_index.py,sha256=-eA9pHplGd9_a8soGDoiWrCe_V5-1MU8QSPGknV2D0M,5222
 kSpider2/ks_dataset_indexing.py,sha256=_xzg6Z12R6mabRr9UnzJLx2Ft8xlswncNNN8izL4J4w,1837
 kSpider2/kSpider_main.py,sha256=vUxKV9fiSUpJ95FNHapVG-7hsGpQo1eCVz_Mic4A0D8,859
-kSpider2/ks_filter.py,sha256=TGoKiq7dKtZd2oL_qPYvqIelF9fSf1AbE9xF6Kpm1Uc,9091
+kSpider2/ks_filter.py,sha256=9eyXBmP1pdI6ZY7OLczJyD_U0WZMoxD0xsqpYkE9QN0,10672
 kSpider2/__init__.py,sha256=MlBlDKuZL00E7Rjx_28goPYbJY09SW5CUAu0A4Q2Quo,37
 kSpider2/click_context.py,sha256=Ps9j6PnjvB4zBst2GoRfV3DBP4Pb17GfYKALBAY2I8o,1467
 kSpider2/ks_fastx_to_kfs.py,sha256=r3IUgtoitZL5NwzyEi-uY0tW5Z9_X1nVibxEfD_lHwU,3316
-kSpider2/ks_export.py,sha256=9wFvU5cYkKFpana3eOxFfH9kEiXXcka2RqPTBz--RQM,5594
-kSpider2/kSpider_version.py,sha256=mclGGbm9T5K9i-4SK1CrYiEwm7DyRj4mcwVZgpSZBTQ,357
+kSpider2/ks_export.py,sha256=exMDQljquZWx8jI4ulYkCHrcKUaBLGe678TA3gcRCsA,9330
+kSpider2/kSpider_version.py,sha256=4ovqluExTkfYS1v-OI6Nh2HgYVCn_c67jH_e-KBbsjQ,312
 kSpider2/ks_sketch_dbretina.py,sha256=PZlasGcqRIWH4mmOAtSe8s6zZXEDiYIPYrYNEbc4Bxk,719
-kSpider2/ks_clustering.py,sha256=3lG5w7YY3WuGXbWYxx_42PoQRR-gEpyYKni9G_8rHS0,9971
-DBRetina-2.2.3.dist-info/METADATA,sha256=IJ3GMRp768ISnY8swRcLWqv2xaGhoBDTIIqv6_v8zIE,1054
-DBRetina-2.2.3.dist-info/entry_points.txt,sha256=HuUvdKaCNqW3VFtVnm6P-dCDkkOrVT-niI2-1C7LswI,42
-DBRetina-2.2.3.dist-info/top_level.txt,sha256=mgN01IsYPX0F4K0TlzJVvZm5nddBiNlhZMuGa4sAf8Q,53
-DBRetina-2.2.3.dist-info/RECORD,,
-DBRetina-2.2.3.dist-info/WHEEL,sha256=gREe7-l-MJWbGZG46A7WHnwwUSxA3XJYHQvGGLzmBNU,148
-DBRetina-2.2.3.dist-info/LICENSE,sha256=W1bnRBpBo-y-J4DWTqaty5UL5CzCiFqfgJX9nC87KKo,1082
+kSpider2/ks_clustering.py,sha256=2PW_YtFOuRO8nS-3ujTNDqmHIyMosQkKKl_R9DHwq3w,8916
 internal/kSpider_internal.py,sha256=I8yVW1soDuOBFpWt47gOjBIiwF-EkbjACQhi0BqJj9o,2784
 internal/__init__.py,sha256=3S25GDI0myAK8OZ5Vg9kj3Y7cir1VKYlpAI8keTHWd0,32
```

## Comparing `DBRetina-2.2.3.dist-info/LICENSE` & `DBRetina-2.2.4.dist-info/LICENSE`

 * *Files identical despite different names*

