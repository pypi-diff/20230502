# Comparing `tmp/cubepy-1.0.2-py3-none-any.whl.zip` & `tmp/cubepy-1.9.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,17 +1,18 @@
-Zip file size: 17009 bytes, number of entries: 15
--rw-r--r--  2.0 unx      256 b- defN 22-Jan-03 12:49 cubepy/__init__.py
--rw-r--r--  2.0 unx      142 b- defN 22-Jan-03 12:49 cubepy/_version.py
--rw-r--r--  2.0 unx     2076 b- defN 22-Jan-03 12:49 cubepy/converged.py
--rw-r--r--  2.0 unx     4101 b- defN 22-Jan-03 12:49 cubepy/gauss_kronrod.py
--rw-r--r--  2.0 unx     5321 b- defN 22-Jan-03 12:49 cubepy/genz_malik.py
--rw-r--r--  2.0 unx    10207 b- defN 22-Jan-03 12:49 cubepy/integration.py
--rw-r--r--  2.0 unx     5355 b- defN 22-Jan-03 12:49 cubepy/points.py
--rw-r--r--  2.0 unx     3453 b- defN 22-Jan-03 12:49 cubepy/region.py
--rw-r--r--  2.0 unx      199 b- defN 22-Jan-03 12:49 cubepy/type_aliases.py
--rw-r--r--  2.0 unx     1520 b- defN 22-Jan-03 12:49 cubepy-1.0.2.dist-info/LICENSE
--rw-r--r--  2.0 unx     1939 b- defN 22-Jan-03 12:49 cubepy-1.0.2.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 22-Jan-03 12:49 cubepy-1.0.2.dist-info/WHEEL
--rw-r--r--  2.0 unx        7 b- defN 22-Jan-03 12:49 cubepy-1.0.2.dist-info/top_level.txt
--rw-r--r--  2.0 unx        1 b- defN 22-Jan-03 12:49 cubepy-1.0.2.dist-info/zip-safe
-?rw-rw-r--  2.0 unx     1149 b- defN 22-Jan-03 12:49 cubepy-1.0.2.dist-info/RECORD
-15 files, 35818 bytes uncompressed, 15131 bytes compressed:  57.8%
+Zip file size: 14771 bytes, number of entries: 16
+-rw-r--r--  2.0 unx      309 b- defN 23-May-02 14:44 cubepy/__init__.py
+-rw-r--r--  2.0 unx      160 b- defN 23-May-02 14:44 cubepy/_version.py
+-rw-r--r--  2.0 unx      781 b- defN 23-May-02 14:44 cubepy/converged.py
+-rw-r--r--  2.0 unx     2889 b- defN 23-May-02 14:44 cubepy/gauss_kronrod.py
+-rw-r--r--  2.0 unx     5591 b- defN 23-May-02 14:44 cubepy/genz_malik.py
+-rw-r--r--  2.0 unx     2849 b- defN 23-May-02 14:44 cubepy/input.py
+-rw-r--r--  2.0 unx     6263 b- defN 23-May-02 14:44 cubepy/integration.py
+-rw-r--r--  2.0 unx     5637 b- defN 23-May-02 14:44 cubepy/points.py
+-rw-r--r--  2.0 unx     1783 b- defN 23-May-02 14:44 cubepy/region.py
+-rw-r--r--  2.0 unx      556 b- defN 23-May-02 14:44 cubepy/type_aliases.py
+-rw-r--r--  2.0 unx     1074 b- defN 23-May-02 14:44 cubepy-1.9.1.dist-info/LICENSE
+-rw-r--r--  2.0 unx     4364 b- defN 23-May-02 14:44 cubepy-1.9.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-02 14:44 cubepy-1.9.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx        7 b- defN 23-May-02 14:44 cubepy-1.9.1.dist-info/top_level.txt
+-rw-r--r--  2.0 unx        1 b- defN 23-May-02 14:44 cubepy-1.9.1.dist-info/zip-safe
+-rw-rw-r--  2.0 unx     1219 b- defN 23-May-02 14:44 cubepy-1.9.1.dist-info/RECORD
+16 files, 33575 bytes uncompressed, 12787 bytes compressed:  61.9%
```

## zipnote {}

```diff
@@ -9,38 +9,41 @@
 
 Filename: cubepy/gauss_kronrod.py
 Comment: 
 
 Filename: cubepy/genz_malik.py
 Comment: 
 
+Filename: cubepy/input.py
+Comment: 
+
 Filename: cubepy/integration.py
 Comment: 
 
 Filename: cubepy/points.py
 Comment: 
 
 Filename: cubepy/region.py
 Comment: 
 
 Filename: cubepy/type_aliases.py
 Comment: 
 
-Filename: cubepy-1.0.2.dist-info/LICENSE
+Filename: cubepy-1.9.1.dist-info/LICENSE
 Comment: 
 
-Filename: cubepy-1.0.2.dist-info/METADATA
+Filename: cubepy-1.9.1.dist-info/METADATA
 Comment: 
 
-Filename: cubepy-1.0.2.dist-info/WHEEL
+Filename: cubepy-1.9.1.dist-info/WHEEL
 Comment: 
 
-Filename: cubepy-1.0.2.dist-info/top_level.txt
+Filename: cubepy-1.9.1.dist-info/top_level.txt
 Comment: 
 
-Filename: cubepy-1.0.2.dist-info/zip-safe
+Filename: cubepy-1.9.1.dist-info/zip-safe
 Comment: 
 
-Filename: cubepy-1.0.2.dist-info/RECORD
+Filename: cubepy-1.9.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## cubepy/__init__.py

```diff
@@ -1,12 +1,21 @@
 __all__ = [
     "integrate",
+    "input",
     "integration",
     "points",
     "genz_malik",
     "gauss_kronrod",
     "region",
     "type_aliases",
 ]
 
-from . import gauss_kronrod, genz_malik, integration, points, region, type_aliases
+from . import (
+    gauss_kronrod,
+    genz_malik,
+    input,
+    integration,
+    points,
+    region,
+    type_aliases,
+)
 from .integration import integrate
```

## cubepy/_version.py

```diff
@@ -1,5 +1,4 @@
-# coding: utf-8
 # file generated by setuptools_scm
 # don't change, don't track in version control
-version = '1.0.2'
-version_tuple = (1, 0, 2)
+__version__ = version = '1.9.1'
+__version_tuple__ = version_tuple = (1, 9, 1)
```

## cubepy/converged.py

```diff
@@ -1,46 +1,25 @@
-# BSD 3-Clause License
-#
-# Copyright (c) 2021, Alex Reustle
-# All rights reserved.
-#
-# Redistribution and use in source and binary forms, with or without
-# modification, are permitted provided that the following conditions are met:
-#
-# 1. Redistributions of source code must retain the above copyright notice, this
-#    list of conditions and the following disclaimer.
-#
-# 2. Redistributions in binary form must reproduce the above copyright notice,
-#    this list of conditions and the following disclaimer in the documentation
-#    and/or other materials provided with the distribution.
-#
-# 3. Neither the name of the copyright holder nor the names of its
-#    contributors may be used to endorse or promote products derived from
-#    this software without specific prior written permission.
-#
-# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
-# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
-# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
-# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
-# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
-# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
-# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
 from __future__ import annotations
 
 import numpy as np
 
-from .type_aliases import NPB, NPF
+from .type_aliases import NPB, NPF, NPT
 
 
-def converged(result: NPF, error: NPF, abstol: float, reltol: float) -> NPB:
+def converged(
+    result: NPF, local_error: NPF, parent_result: NPT, rtol: float, atol: float
+) -> NPB:
     """Determine wether error values are below threshod for convergence."""
 
-    # {val, err}    [ range_dim, events_regions ]
-    val = np.linalg.norm(result, ord=np.inf, axis=0)
-    err = np.linalg.norm(error, ord=np.inf, axis=0)
+    r = result.shape[0] // 2
+    E = local_error
+    if r >= 1:
+        E2 = np.abs(parent_result - (result[:r] + result[r:]))  # [ r/2, events ]
+        ES = E[:r] + E[r:]
+        inv_error = np.reciprocal(
+            np.where(ES <= 2.0 * np.finfo(ES.dtype).eps, 1.0, ES)
+        )  # [ r/2, events ]
+        E[:r] += E2 * (0.25 + 0.5 * inv_error * E[:r])
+        E[r:] += E2 * (0.25 + 0.5 * inv_error * E[r:])
 
-    # {cmask}       [ events_regions ]
-    return (err <= abstol) | (err <= (reltol * np.abs(val)))
+    # {cmask}       [ regions, events ]
+    return E <= (atol + rtol * np.abs(result))
```

## cubepy/gauss_kronrod.py

```diff
@@ -1,51 +1,22 @@
-# BSD 3-Clause License
-#
-# Copyright (c) 2021, Alex Reustle
-# All rights reserved.
-#
-# Redistribution and use in source and binary forms, with or without
-# modification, are permitted provided that the following conditions are met:
-#
-# 1. Redistributions of source code must retain the above copyright notice, this
-#    list of conditions and the following disclaimer.
-#
-# 2. Redistributions in binary form must reproduce the above copyright notice,
-#    this list of conditions and the following disclaimer in the documentation
-#    and/or other materials provided with the distribution.
-#
-# 3. Neither the name of the copyright holder nor the names of its
-#    contributors may be used to endorse or promote products derived from
-#    this software without specific prior written permission.
-#
-# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
-# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
-# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
-# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
-# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
-# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
-# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
 from __future__ import annotations
 
 from typing import Callable
 
 import numpy as np
 
-from . import points
 from .type_aliases import NPF, NPI
 
 
 def gauss_kronrod(
-    f: Callable, centers: NPF, halfwidths: NPF, v: NPF
-) -> tuple[NPF, NPF, NPI]:
-
+    f: Callable,
+    pts: NPF,
+    halfwidths: NPF,
+    *_,
+):
     # GK [7, 15] weights from
     # https://www.advanpix.com/2011/11/07/gauss-kronrod-quadrature-nodes-weights/
     gk_weights = np.array(
         [
             0.022935322010529224963732008058970,  # 0
             0.063092092629978553290700663189204,  # 1
             0.104790010322250183839876322541518,  # 2
@@ -72,32 +43,41 @@
             0.417959183673469387755102040816327,  # 3
             0.381830050505118944950369775488975,  # 2
             0.279705391489276667901467771423780,  # 1
             0.129484966168869693270611432679082,  # 0
         ]
     )
 
-    # p.shape [ 15(points), ... ]
-    p = points.gk_pts(centers, halfwidths)
-
-    # vals.shape [ range_dim, points, ... ]
-    vals = f(p)
+    # centers, halfwidths  =  1 * [ regions, { 1 | nevts } ]
+    # p.shape 1 * [ 15(points), regions, { 1 | nevts } ]
+    # pts = points.gk_pts(center[0], halfwidths[0])
+    nreg = pts[0].shape[1]
+    nevt = pts[0].shape[2]
+    pts = pts.reshape(1, 15 * nreg, nevt)
+    # vals.shape [ points, regions, events ]
+    vals = f(pts).reshape(15, nreg, nevt)
+
+    # Reshape shapes to conform to matmul shape requirements.
+    # s0 = (15, nreg, nevt)
+    # s1 = (15, nreg * nevt)
+    # s2 = (2, nreg, nevt)
+
+    # r_ [ regions, events ] = [M] . [ M, regions, events ]
+    rg = np.tensordot(gl_weights, vals[1::2], (0, 0))
+    rk = np.tensordot(gk_weights, vals, (0, 0))
 
-    # r_.shape [ range_dim, ... ]
-    rg: NPF = np.tensordot(gl_weights, vals[:, 1::2, ...], (0, 1))
-    rk: NPF = np.tensordot(gk_weights, vals, (0, 1))
+    # error [ regions, events ]
+    err = halfwidths[0] * np.abs(rk - rg)
 
-    # error
-    err = halfwidths * np.abs(rk - rg)
     mean = 0.5 * rk
-    I_tilde = halfwidths * np.tensordot(gk_weights, np.abs(vals - mean), (0, 1))
+    I_tilde = halfwidths[0] * np.tensordot(gk_weights, np.abs(vals - mean), (0, 0))
 
     mask = np.abs(I_tilde) > 1.0e-15
     scale = (200.0 * err[mask] / I_tilde[mask]) ** 1.5
     scale[scale > 1.0] = 1.0
     err[mask] = I_tilde[mask] * scale
 
     min_err = 50.0 * np.finfo(rk.dtype).eps
-    rabs = halfwidths * np.tensordot(gk_weights, np.abs(vals), (0, 1))
+    rabs = halfwidths[0] * np.tensordot(gk_weights, np.abs(vals), (0, 0))
     err[(rabs > (np.finfo(rk.dtype).tiny / min_err)) & (min_err > err)] = min_err
 
-    return (rk * halfwidths), err, np.zeros(err.shape[-1], dtype=int)
+    return (rk * halfwidths[0]), err, np.zeros(err.shape[0], dtype=int)
```

## cubepy/genz_malik.py

```diff
@@ -1,132 +1,175 @@
-# BSD 3-Clause License
-#
-# Copyright (c) 2021, Alex Reustle
-# All rights reserved.
-#
-# Redistribution and use in source and binary forms, with or without
-# modification, are permitted provided that the following conditions are met:
-#
-# 1. Redistributions of source code must retain the above copyright notice, this
-#    list of conditions and the following disclaimer.
-#
-# 2. Redistributions in binary form must reproduce the above copyright notice,
-#    this list of conditions and the following disclaimer in the documentation
-#    and/or other materials provided with the distribution.
-#
-# 3. Neither the name of the copyright holder nor the names of its
-#    contributors may be used to endorse or promote products derived from
-#    this software without specific prior written permission.
-#
-# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
-# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
-# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
-# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
-# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
-# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
-# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 from __future__ import annotations
 
+from functools import cache
 from typing import Callable
 
 import numpy as np
 
 from . import points
-from .type_aliases import *
+from .type_aliases import NPF, NPI
 
 
-def genz_malik_weights(dim: int) -> NPF:
+# def genz_malik_weights(dim: int) -> NPF:
+@cache
+def rule_weights(dim: int) -> NPF:
     return np.array(
         [
-            (12824.0 - 9120.0 * dim + 400.0 * dim ** 2) / 19683.0,
+            (12824.0 - 9120.0 * dim + 400.0 * dim**2) / 19683.0,
             0.149367474470355128791342783112330437433318091754305746075293,  # 980/6561
             (1820.0 - 400.0 * dim) / 19683.0,
             0.010161052685058172026621958034852410709749530051313316059543,  # 200/19683
-            (6859.0 / 19683.0) / 2 ** dim,
+            (6859.0 / 19683.0) / 2**dim,
         ]
     )
 
 
-def genz_malik_err_weights(dim: int) -> NPF:
+# def genz_malik_err_weights(dim: int) -> NPF:
+@cache
+def error_weights(dim: int) -> NPF:
     return np.array(
         [
-            (729.0 - 950.0 * dim + 50.0 * dim ** 2) / 729.0,
+            (729.0 - 950.0 * dim + 50.0 * dim**2) / 729.0,
             0.50411522633744855967078189300411522633744855967078189300411522,  # 245/486
             (265.0 - 100.0 * dim) / 1458.0,
             0.034293552812071330589849108367626886145404663923182441700960219,  # 25/729
         ]
     )
 
 
-def genz_malik(
-    f: Callable, centers: NPF, halfwidths: NPF, volumes: NPF
-) -> tuple[NPF, NPF, NPI]:
-
-    ### [7, 5] FS rule weights from Genz, Malik: "An adaptive algorithm for numerical
-    ### integration Over an N-dimensional rectangular region", updated by Bernstein,
-    ### Espelid, Genz in "An Adaptive Algorithm for the Approximate Calculation of
-    ### Multiple Integrals"
-    alpha2 = 0.35856858280031809199064515390793749545406372969943071  # √(9/70)
-    alpha4 = 0.94868329805051379959966806332981556011586654179756505  # √(9/10)
-    alpha5 = 0.68824720161168529772162873429362352512689535661564885  # √(9/19)
+@cache
+def div_diff_weights(dim: int) -> NPF:
     ratio = 0.14285714285714285714285714285714285714285714285714281  # ⍺₂² / ⍺₄²
+    a = np.zeros((dim, points.num_k0k1(dim)), dtype=float)
+    a[:, 0] = -2 + 2 * ratio
+    k1T0 = np.tile(np.arange(dim)[:, None], (1, 4))
+    k1T1 = np.arange(1, points.num_k0k1(dim)).reshape((dim, 4))
+    a[k1T0, k1T1] = [1.0, 1.0, -ratio, -ratio]
+
+    return a
+
+
+def rule_split_dim(vals, err, halfwidth, volume):
+    # :::::::::::::: Shapes ::::::::::::::::
+    # vals [ points, regions, events ]
+    # err [ regions, events ]
+    # halfwidth domain_dim * [ regions, { 1 | nevts } ]
+    # volume [ events ]
 
-    # p shape [ domain_dim, points, ... ]
-    p = points.fullsym(
-        centers, halfwidths * alpha2, halfwidths * alpha4, halfwidths * alpha5
-    )
-    dim = p.shape[0]
+    dim = len(halfwidth)
+    npts, nreg, nevt = vals.shape
     d1 = points.num_k0k1(dim)
-    d2 = points.num_k2(dim)
-    d3 = d1 + d2
-
-    # vals shape [ range_dim, points, ... ]
-    vals = f(p)
-
-    if vals.ndim <= 2:
-        vals = np.expand_dims(vals, 0)
-
-    vc = vals[:, 0:1, ...]  # center integrand value. shape = [ rdim, 1, ... ]
 
-    # [ range_dim, domain_dim, ... ]
-    v01 = vals[:, 1:d1:4, ...] + vals[:, 2:d1:4, ...]
-    v23 = vals[:, 3:d1:4, ...] + vals[:, 4:d1:4, ...]
-
-    # Compute the 4th divided difference to determine dimension on which to split.
-    fdiff = np.abs(v01 - 2 * vc - ratio * (v23 - 2 * vc))
-    diff = np.sum(fdiff, axis=0)  # [ domain_dim, ... ]
-
-    vc = np.squeeze(vc, 1)
-    s2 = np.sum(v01, axis=1)  # [ range_dim, ... ]
-    s3 = np.sum(v23, axis=1)  # [ range_dim, ... ]
-    s4 = np.sum(vals[:, d1:d3, ...], axis=1)  # [ range_dim, ... ]
-    s5 = np.sum(vals[:, d3:, ...], axis=1)  # [ range_dim, ... ]
-
-    w = genz_malik_weights(dim)  # [5]
-    wE = genz_malik_err_weights(dim)  # [4]
+    # Compute the 4th divided difference to determine the dimension on which to split.
+    s1 = (npts, nreg * nevt)
+    s3 = (dim, nreg, nevt)
+
+    # [ domain_dim, regions, events ] = [ domain_dim, d1 ] @ [ d1, regions, events ]
+    # fdiff = div_diff_weights(dim) @ vals.reshape(s1)[:d1, ...]
+    # [ domain_dim, regions ]
+    diff = np.linalg.norm(
+        (div_diff_weights(dim) @ vals.reshape(s1)[:d1, ...]).reshape(s3), ord=1, axis=-1
+    )
 
-    # [5] . [5,range_dim, ... ] = [range_dim, ... ]
-    result = volumes * np.tensordot(w, (vc, s2, s3, s4, s5), (0, 0))
+    # [ regions ]
+    split_dim = np.argmax(diff, axis=0)
+    widest_dim = np.argmax(np.asarray([np.amax(h, axis=1) for h in halfwidth]), axis=0)
+
+    # [ domain_dim, regions ]
+    delta = np.abs(diff[split_dim, np.arange(nreg)] - diff[widest_dim, np.arange(nreg)])
+    df = np.sum(err * (volume[None, :] * 10 ** (-dim)), axis=1)  # [ regions ]
 
-    # [4] . [4,range_dim, ... ] = [range_dim, ... ]
-    res5th = volumes * np.tensordot(wE, (vc, s2, s3, s4), (0, 0))
+    too_close = delta <= df
+    split_dim[too_close] = widest_dim[too_close]
+    return split_dim
 
-    err = np.abs(res5th - result)  # [range_dim, ... ]
 
-    # determine split dimension
-    split_dim = np.argmax(diff, axis=0)  # [ ... ]
-    split_i = np.zeros_like(diff, dtype=np.bool_)
-    np.put_along_axis(split_i, np.expand_dims(split_dim, 0), True, axis=0)
+@cache
+def error_weights_vec(dim: int) -> NPF:
+    d1 = points.num_k0k1(dim)
+    d2 = points.num_k2(dim)
+    d3 = d1 + d2
+    wE = error_weights(dim)
+    a = np.zeros(d3)
+    a[0] = wE[0]
+    a[1:d1:4] = wE[1]
+    a[2:d1:4] = wE[1]
+    a[3:d1:4] = wE[2]
+    a[4:d1:4] = wE[2]
+    a[d1:d3] = wE[3]
+    return a
 
-    widest_dim = np.argmax(halfwidths, axis=0)
-    widest_i = np.zeros_like(halfwidths, dtype=np.bool_)
-    np.put_along_axis(widest_i, np.expand_dims(widest_dim, 0), True, axis=0)
 
-    delta = np.reshape(diff[split_i] - diff[widest_i], diff.shape[1:])  # [ ... ]
-    df = np.sum(err, axis=0) / (volumes * 10 ** dim)  # [ ... ]
-    too_close = delta <= df
-    split_dim[too_close] = widest_dim[too_close]
+@cache
+def rule_weights_vec(dim: int) -> NPF:
+    d1 = points.num_k0k1(dim)
+    d2 = points.num_k2(dim)
+    d3 = d1 + d2
+    w = rule_weights(dim)
+    a = np.zeros(points.num_points(dim))
+    a[0] = w[0]
+    a[1:d1:4] = w[1]
+    a[2:d1:4] = w[1]
+    a[3:d1:4] = w[2]
+    a[4:d1:4] = w[2]
+    a[d1:d3] = w[3]
+    a[d3:] = w[4]
+    return a
+
+
+@cache
+def rule_error_weights(dim: int) -> NPF:
+    """
+    The necessary weights for computing the 7th and 5th order genz malik rule values
+    laid out in matrix form.
+    """
+    d1 = points.num_k0k1(dim)
+    d2 = points.num_k2(dim)
+    d3 = d1 + d2
+    a = np.zeros((2, points.num_points(dim)))
+    w = rule_weights(dim)
+    wE = error_weights(dim)
+    a[:, 0:1] = np.array([w[0], wE[0]])[:, None]
+    a[:, 1:d1:4] = np.array([w[1], wE[1]])[:, None]
+    a[:, 2:d1:4] = np.array([w[1], wE[1]])[:, None]
+    a[:, 3:d1:4] = np.array([w[2], wE[2]])[:, None]
+    a[:, 4:d1:4] = np.array([w[2], wE[2]])[:, None]
+    a[:, d1:d3] = np.array([w[3], wE[3]])[:, None]
+    a[:, d3:] = np.array([w[4], 0])[:, None]
+    return a
+
+
+def genz_malik(f: Callable, pts, halfwidth, volume) -> tuple[NPF, NPF, NPI]:
+    # [7, 5] FS rule weights from Genz, Malik: "An adaptive algorithm for numerical
+    # integration Over an N-dimensional rectangular region", updated by Bernstein,
+    # Espelid, Genz in "An Adaptive Algorithm for the Approximate Calculation of
+    # Multiple Integrals"
+
+    # p shape domain_dim * [ points, regions, { 1 | nevts } ]
+    dim = len(pts)
+    npts = points.num_points(dim)
+    nreg = halfwidth[0].shape[0]
+
+    # Save shape then reshape to [domain_dim, (points*regions), 1] before passing to f
+    pts = [np.reshape(p, (npts * nreg, p.shape[-1])) for p in pts]
+    # vals shape [ points * regions, events  ] ==> [ points, regions, events ]
+    vals = f(pts)
+    # any eventwise operations in the integrand will automatically be (N, 1) * (M)
+    # or (N, M) * (M) operations, so should return events in the trailing dimension.
+    nevt = vals.size // (nreg * npts)
+
+    # Reshape shapes to conform to matmul shape requirements.
+    s0 = (npts, nreg, nevt)
+    s1 = (npts, nreg * nevt)
+    s2 = (2, nreg, nevt)
+
+    vals = np.reshape(vals, s0)
+    # vals = np.reshape(vals, s1)
+    w = rule_error_weights(dim)
+
+    rpack = (w @ vals.reshape(s1)).reshape(s2) * volume
+    rpack[1] = np.abs(np.diff(rpack, axis=0))  # [ regions, events ]
+    result, err = rpack
+    split_dim = rule_split_dim(vals.reshape(s0), err, halfwidth, volume)  # [ regions ]
 
+    # [regions, events] [ regions, events ] [ regions ]
     return result, err, split_dim
```

## cubepy/integration.py

```diff
@@ -1,274 +1,168 @@
-# BSD 3-Clause License
-#
-# Copyright (c) 2021, Alex Reustle
-# All rights reserved.
-#
-# Redistribution and use in source and binary forms, with or without
-# modification, are permitted provided that the following conditions are met:
-#
-# 1. Redistributions of source code must retain the above copyright notice, this
-#    list of conditions and the following disclaimer.
-#
-# 2. Redistributions in binary form must reproduce the above copyright notice,
-#    this list of conditions and the following disclaimer in the documentation
-#    and/or other materials provided with the distribution.
-#
-# 3. Neither the name of the copyright holder nor the names of its
-#    contributors may be used to endorse or promote products derived from
-#    this software without specific prior written permission.
-#
-# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
-# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
-# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
-# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
-# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
-# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
-# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
 from __future__ import annotations
 
-from concurrent.futures import ThreadPoolExecutor
-from typing import Any, Callable
+from functools import reduce
+from operator import mul
+from typing import Any, Callable, Sequence
 
 import numpy as np
 
-from . import converged, points, region
+from . import converged, input, region
 from .gauss_kronrod import gauss_kronrod
 from .genz_malik import genz_malik
+from .points import gk_pts, gm_pts
 from .type_aliases import NPF
 
-# import multiprocessing as mp
-
 __all__ = ["integrate"]
 
 
 def integrate(
     f: Callable,
     low,
     high,
-    args: tuple[Any, ...] = tuple([]),
-    abstol: float = 1e-6,
-    reltol: float = 1e-6,
-    is_1d: bool = False,
-    evt_idx_arg: bool = False,
-    itermax: int | float = 1000,
-    tile_byte_limit: int | float = 2 ** 30,
-    range_dim: int = 0,
-    parallel: bool = False,
+    args: Sequence[Any] = tuple([]),
+    *,  # kwonly arguments
+    domain_dim: None | int = None,
+    rtol: float = 1e-5,
+    atol: float = 1e-8,
+    itermax: int | float = 16,
 ) -> tuple[NPF, NPF]:
     """Numerical Cubature in multiple dimensions.
 
     Functions with 1D domain use an adaptive Gauss Kronrod Quadrature scheme.
     Functions with 2+D domain use an adaptive Genz Malik Cubature scheme.
 
     The adaptive regional subdivision is performed independently for un-converged
     regions.
 
-    Local convergence is obtained when the global tolerance values exceed a local
-    region's error estimate.
+    Local convergence is obtained when the tolerance values exceed a local
+    region's error estimate by Bernsten's error estimation formula.
 
     Global convergence is obtained when all regions are locally converged.
 
     Parameters
     ==========
         f: Callable
             Integrand function: expected function signature is
             `f(x: NDArray, *args) -> NDArray`
             where `x` is the expected vector input, with domain in the leading dimension
             (`x.shape[0]`)
-        low: float or NDArray
+        low: Scalar, Iterable, or NDArray
             The finite integral lower bound. If a 1D vector the default behavior is to
             treat the length (`shape[0]`) as the domain of integration of 1 event.
             If a 2D ndarray, the default behavior is to treat the leading dimension
             (`shape[0]`) as the domain of integration, and the trailing dimension as the
             set of independent events over which to integrate. This default behavior
             is controlled by the `event_axis` parameter.
-        high: float or NDArray
+        high: Scalar, Iterable, or NDArray
             The finite integral high bound. Behavior is identical to `low` parameter.
         args: tuple, Optional
             The function arguments to pass into `f`.
-        abstol: float, Optional
-            Absolute local error tolerance. Default 1e-6
-        reltol: float, Optional
-            Relative local error tolerance. Default 1e-6
+        rtol: float, Optional
+            Relative local error tolerance. Default 1e-5
+        atol: float, Optional
+            Absolute local error tolerance. Default 1e-8
         itermax: int or float, Optional
             Maximum number of subdivision iterations to perform on the integrand.
             Default is 100
     """
 
-    ### Prepare parameters
-    low = np.asarray(low)
-    high = np.asarray(high)
-
-    if low.shape == ():
-        low = np.expand_dims(low, 0)
-    if high.shape == ():
-        high = np.expand_dims(high, 0)
-
-    if low.shape != high.shape:
-        raise RuntimeError(
-            "Limits of integration must be the same shape", low.shape, high.shape
-        )
-
-    input_shape = low.shape
-
-    ## Reshape the limits of integration if necessary. Domain_dim must be along axis 0
-    ## and the final shape for low and high must both be 2D. Ravel trailing dimensions
-    ## and reshape results once complete.
-    if low.ndim == 1:
-        low = np.expand_dims(low, 0 if is_1d else -1)
-        high = np.expand_dims(high, 0 if is_1d else -1)
-        event_shape = low.shape[1:]
-    elif low.ndim > 1:
-        if is_1d:
-            event_shape = input_shape
-            low = np.ravel(low).reshape(1, np.prod(input_shape))
-            high = np.ravel(high).reshape(1, np.prod(input_shape))
-        else:
-            event_shape = low.shape[1:]
-            low = np.ravel(low).reshape(input_shape[0], np.prod(event_shape))
-            high = np.ravel(high).reshape(input_shape[0], np.prod(event_shape))
-    else:
-        raise RuntimeError("Unsupported shape for limits of integration", low.shape)
-
-    num_evts = low.shape[-1]
-    evtidx = np.arange(num_evts)
-
     # :::::::::::::::: Shapes ::::::::::::::::::
-    # {low, high}       [ domain_dim, events ]
-    # {center, hwidth}  [ domain_dim, regions_events ]
-    # {volume}          [ regions_events ]
+    # {low, high}       [ domain_dim, {events} ]
+    # {center, hwidth}  [ domain_dim, regions, {events} ]
+    # {volume}          [ regions ]
 
     # ---------------- Results -----------------
-    # {value}       [ range_dim, regions_events ]
-    # {error}       [ range_dim, regions_events ]
-    # {split_dim}   [ regions_events ]
+    # {value}       [ events ]
+    # {error}       [ events ]
+    # {split_dim}   [ events ]
 
     # ------------ Working vectors -------------
-    # {cmask}   [ regions_events ]
+    # {cmask}   [ regions, events ]
+
+    low, high, event_shape = input.parse_input(f, low, high, args, domain_dim)
+    domain_dim = len(low)
+    nevts = reduce(mul, event_shape, 1)
+    active_evt_idx = np.arange(nevts)  # [ kept_evts ]
+    aemsk = input.get_arg_evt_mask(args, event_shape)
+    error = np.array([])
+
+    # [ events ]
+    result_value = np.zeros(nevts)
+    result_error = np.zeros(nevts)
+    # [ regions, events ]
+    parent_value = np.zeros((1, nevts))
+
+    # Prepare the integrand including applying the event mask to the maskable elements
+    # in the args array.
+    def _f(ev):
+        return lambda x: f(*x, *(a[ev] if b else a for a, b in zip(args, aemsk)))
 
     # Create initial region
     center, halfwidth, vol = region.region(low, high)
 
-    domain_dim = center.shape[0]
-    pts = points.num_points(domain_dim) if domain_dim > 1 else 15
-    event_size = center.itemsize * domain_dim * pts
-    max_tile_len = tile_byte_limit / event_size
-    max_tile_len = np.maximum(max_tile_len, 1)
-
-    # prepare the integrand
-    def _f(evi):
-        return (lambda x: f(x, evi, *args)) if evt_idx_arg else lambda x: f(x, *args)
-
     # prepare the integral rule
-    rule = gauss_kronrod if center.shape[0] == 1 else genz_malik
+    rule_ = gauss_kronrod if len(center) == 1 else genz_malik
+    pts_ = gk_pts if len(center) == 1 else gm_pts
 
-    if range_dim == 0:
-        value, error, _ = rule(
-            _f(evtidx[0:1]), center[:, 0:1], halfwidth[:, 0:1], vol[0:1]
-        )
+    def rule(p, h, v, e):
+        return rule_(_f(e), p, h, v)
 
-        # prepare results
-        if value.shape != error.shape:
-            # expect [range_dim, regions_events]
-            raise RuntimeError("Value/Error shape mismatch after rule application")
-        range_dim = value.shape[0]
-
-    tiled_rule = tiled_rule_generator(max_tile_len, parallel, range_dim, rule, _f)
-
-    # perform initial rule application
-    value, error, split_dim = tiled_rule(center, halfwidth, vol, evtidx)
-
-    # prepare results
-    if value.shape != error.shape:
-        # expect [range_dim, regions_events]
-        raise RuntimeError("Value/Error shape mismatch after rule application")
-
-    if range_dim != value.shape[0]:
-        raise RuntimeError("Function return value does not match input range_dim.")
-
-    # [range_dim, events]
-    result_value = np.zeros((range_dim, num_evts))
-    result_error = np.zeros((range_dim, num_evts))
+    pts = pts_(center, halfwidth)
 
-    iter = 1
+    iter: int = 1
     while iter < int(itermax):
+        # Perform rule application on unconverged regions. [regions, events]
+        value, error, split_dim = rule(pts, halfwidth, vol, active_evt_idx)
 
-        # cmask.shape [ regions_events ]
-        # Determine which regions are converged
-        cmask = converged.converged(value, error, abstol, reltol)
-
-        # Accumulate converged region results into correct event
-        for i in range(range_dim):
-            result_value[i, :] += np.bincount(evtidx[cmask], value[i, cmask], num_evts)
-            result_error[i, :] += np.bincount(evtidx[cmask], error[i, cmask], num_evts)
+        iter += 1
 
-        if np.all(cmask):
-            break
+        # Determine which regions are converged [ regions, active_events ]
+        converge_mask = converged.converged(value, error, parent_value, rtol, atol)
 
-        # nmask.shape [ regions_events ]
-        nmask = ~cmask
-        # subdivide the un-converged regions
-        center, halfwidth, vol = region.split(
-            center[:, nmask], halfwidth[:, nmask], vol[nmask], split_dim[nmask]
-        )
-        evtidx = np.tile(evtidx[nmask], 2)
+        # Event indices of locally converged regions, events [ regions, events ]
+        evtidx = np.broadcast_to(active_evt_idx, converge_mask.shape)[converge_mask]
 
-        value, error, split_dim = tiled_rule(center, halfwidth, vol, evtidx)
+        # Accumulate converged region results into correct events. bincount is most
+        # efficient accumulator when multiple regions in the same event converge.
+        result_value += np.bincount(evtidx, value[converge_mask], nevts)
+        result_error += np.bincount(evtidx, error[converge_mask], nevts)
 
-        iter += 1
+        if np.all(converge_mask):
+            break
+
+        # Locally unconverged regions. [ region, events ]
+        unconverged_mask = ~converge_mask
+        region_mask = np.any(unconverged_mask, axis=1)  # [ regions ]
+        event_mask = np.any(unconverged_mask, axis=0)  # [ events ]
+        active_mask = np.ix_(region_mask, event_mask)
+
+        # Indices of unconverged events
+        active_evt_idx = active_evt_idx[event_mask]  # [kept_evts]
+
+        # update parent_values with active values
+        parent_value = value[active_mask]  # [ kept_regions, kept_events ]
+
+        # mask out the converged events from regions
+        center = [c[region_mask] if c.shape[1] == 1 else c[active_mask] for c in center]
+        halfwidth = [
+            h[region_mask] if h.shape[1] == 1 else h[active_mask] for h in halfwidth
+        ]
+        vol = vol[event_mask]
+        split_dim = split_dim[region_mask]
+
+        # subdivide the un-converged regions [ kept_regions, kept_events ]
+        center, halfwidth, vol = region.split(center, halfwidth, vol, split_dim)
+        pts = pts_(center, halfwidth, pts=pts)
 
     if iter == int(itermax):
-        raise RuntimeError(
+        raise RuntimeWarning(
             "Failed to converge within the iteration limit: ",
             itermax,
             "Maximum un-converged error estimate: ",
             np.amax(error),
         )
 
-    result_value = np.reshape(result_value, (range_dim, *event_shape))
-    result_error = np.reshape(result_error, (range_dim, *event_shape))
-
-    # return np.sum(result_value, axis=0), np.sum(result_error, axis=0)
-    return result_value, result_error
-
-
-# prepare tiled iteration of the rule.
-def tiled_rule_generator(max_tile_len, parallel, range_dim, rule, _f):
-    def tiled_rule(center, halfwidth, vol, evtidx):
-
-        revt_len = evtidx.shape[0]
-        numtiles = int(np.ceil(revt_len / max_tile_len))
-
-        value = np.empty((range_dim, revt_len), dtype=center.dtype)
-        error = np.empty((range_dim, revt_len), dtype=center.dtype)
-        split_dim = np.empty((revt_len), dtype=np.intp)
-
-        c_sp = np.array_split(center, numtiles, -1)
-        h_sp = np.array_split(halfwidth, numtiles, -1)
-        v_sp = np.array_split(vol, numtiles, -1)
-        e_sp = np.array_split(evtidx, numtiles, -1)
-
-        lens = np.roll(np.cumsum(np.array(list(map(lambda x: x.shape[1], c_sp))), 0), 1)
-        lens[0] = 0
-
-        def rule_worker(iter, c, h, v, e):
-            end = iter + c.shape[1]
-            val, err, sub = rule(_f(e), c, h, v)
-            value[:, iter:end] = val
-            error[:, iter:end] = err
-            split_dim[iter:end] = sub
-
-        if isinstance(parallel, bool):
-            max_workers = None if parallel else 1
-        else:
-            max_workers = parallel
-        with ThreadPoolExecutor(max_workers=max_workers) as exec:
-            exec.map(rule_worker, lens, c_sp, h_sp, v_sp, e_sp)
-
-        return value, error, split_dim
+    result_value = np.reshape(result_value, event_shape)
+    result_error = np.reshape(result_error, event_shape)
 
-    return tiled_rule
+    return np.squeeze(result_value), np.squeeze(result_error)
```

## cubepy/points.py

```diff
@@ -1,45 +1,16 @@
-# BSD 3-Clause License
-#
-# Copyright (c) 2021, Alex Reustle
-# All rights reserved.
-#
-# Redistribution and use in source and binary forms, with or without
-# modification, are permitted provided that the following conditions are met:
-#
-# 1. Redistributions of source code must retain the above copyright notice, this
-#    list of conditions and the following disclaimer.
-#
-# 2. Redistributions in binary form must reproduce the above copyright notice,
-#    this list of conditions and the following disclaimer in the documentation
-#    and/or other materials provided with the distribution.
-#
-# 3. Neither the name of the copyright holder nor the names of its
-#    contributors may be used to endorse or promote products derived from
-#    this software without specific prior written permission.
-#
-# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
-# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
-# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
-# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
-# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
-# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
-# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
 from __future__ import annotations
 
-from itertools import product
-from typing import Callable
+from functools import cache
+from itertools import combinations, product
+from typing import List, Tuple
 
 import numpy as np
 
-from .type_aliases import NPF
+from .type_aliases import NPF, NPI, NPT
 
 
 def num_k0k1(dim: int) -> int:
     return 1 + 4 * dim
 
 
 def num_k2(dim: int) -> int:
@@ -51,96 +22,118 @@
 
 
 def num_points(dim: int) -> int:
     return num_k0k1(dim) + num_k2(dim) + num_k6(dim)
 
 
 def num_points_full(dim: int) -> tuple[int, ...]:
-    return tuple(
-        [
-            num_k0k1(dim) + num_k2(dim) + num_k6(dim),
-            num_k0k1(dim),
-            num_k0k1(dim) + num_k2(dim),
-        ]
+    return (
+        num_k0k1(dim) + num_k2(dim) + num_k6(dim),
+        num_k0k1(dim),
+        num_k0k1(dim) + num_k2(dim),
     )
 
 
-# p shape [ domain_dim, points, ...]
-def full_kn(c: NPF, numf: Callable) -> NPF:
-    dim = c.shape[0]
-    s = [dim, numf(c.shape[0]), *c.shape[1:]]
-    _shape: tuple = tuple(filter(None, s))
-    return np.full(_shape, c[:, None, ...])
-
-
-# Center points in full sym(lambda2, 0, ... ,0) & full sym(lambda3=lambda4, 0, ..., 0)
-def pts_k0k1(c: NPF, r1: NPF, r2: NPF, p: NPF | None = None) -> NPF:
-
-    p = full_kn(c, num_k0k1) if p is None else p
-
-    for i in range(p.shape[0]):
-        j = 4 * i
-        p[i, j + 1] -= r1[i]
-        p[i, j + 2] += r1[i]
-        p[i, j + 3] -= r2[i]
-        p[i, j + 4] += r2[i]
-
-    return p
-
-
-# Center points for full sym(lambda4, lambda4, 0, ...,0)
-def pts_k2(c: NPF, r: NPF, p: NPF | None = None) -> NPF:
-
-    p = full_kn(c, num_k2) if p is None else p
-    dim = p.shape[0]
-    k = 0
-
-    for i in range(dim - 1):
-        for j in range(i + 1, dim):
-            p[i, k] -= r[i]
-            p[j, k] -= r[j]
-            k += 1
-            p[i, k] += r[i]
-            p[j, k] -= r[j]
-            k += 1
-            p[i, k] -= r[i]
-            p[j, k] += r[j]
-            k += 1
-            p[i, k] += r[i]
-            p[j, k] += r[j]
-            k += 1
-
-    return p
-
-
-# Center points for full sym(lambda5, ...,  lambda5)
-def pts_k6(c: NPF, r: NPF, p: NPF | None = None) -> NPF:
-
-    p = full_kn(c, num_k6) if p is None else p
-    t = np.array(list(product([-1, 1], repeat=p.shape[0]))).T
-    # # p += r[:, None, ...] * t[..., None, None]
-    for i in range(p.shape[0]):
-        p[i] += np.multiply.outer(t[i], r[i])
-    return p
-
+@cache
+def k2indexes(ndim: int) -> Tuple[List[NPI], List[NPI]]:
+    # fmt: off
+    offset = num_k0k1(ndim)
+    A: List[List[int]] = [[] for _ in range(ndim)]
+    B: List[List[int]] = [[] for _ in range(ndim)]
+    # fmt: on
+    for i, (a, b) in enumerate(combinations(range(ndim), 2)):
+        A[a].append(i)
+        B[b].append(i)
+
+    return (
+        [4 * np.array(x, dtype=int)[:, None] + np.arange(4) + offset for x in A],
+        [4 * np.array(x, dtype=int)[:, None] + np.arange(4) + offset for x in B],
+    )
 
-def fullsym(c: NPF, l2: NPF, l4: NPF, l5: NPF) -> NPF:
 
-    p: NPF = full_kn(c, num_points)
-    _, d1, d2 = num_points_full(p.shape[0])
+@cache
+def gm_weights(
+    dim,
+    alpha2: float = 0.35856858280031809199064515390793749545406372969943071,
+    alpha4: float = 0.94868329805051379959966806332981556011586654179756505,
+    alpha5: float = 0.68824720161168529772162873429362352512689535661564885,
+    dtype=np.float64,
+):
+    # [7, 5] FS rule weights from Genz, Malik: "An adaptive algorithm for numerical
+    # integration Over an N-dimensional rectangular region", updated by Bernstein,
+    # Espelid, Genz in "An Adaptive Algorithm for the Approximate Calculation of
+    # Multiple Integrals"
+    # alpha2 = 0.35856858280031809199064515390793749545406372969943071  # √(9/70)
+    # alpha4 = 0.94868329805051379959966806332981556011586654179756505  # √(9/10)
+    # alpha5 = 0.68824720161168529772162873429362352512689535661564885  # √(9/19)
+    npts = num_points(dim)
+
+    M = [np.zeros(npts) for _ in range(dim)]
+    M1 = np.array([-alpha2, alpha2, -alpha4, alpha4], dtype=dtype)
+    M2a = np.array([-alpha4, alpha4, -alpha4, alpha4], dtype=dtype)
+    M2b = np.array([-alpha4, -alpha4, alpha4, alpha4], dtype=dtype)
+    M6 = np.array([*product([-alpha5, alpha5], repeat=dim)], dtype=dtype).T
+    k2A, k2B = k2indexes(dim)
+    off6 = num_k0k1(dim) + num_k2(dim)
+    for d in range(dim):
+        # k1: Center points in fullsym(lambda2, 0, ... ,0) & fullsym(a4, 0, ..., 0)
+        j = 4 * d
+        M[d][1 + j : 5 + j] = M1
+        # k2: Center points in full sym(lambda4, lambda4, ... ,0)
+        M[d][k2A[d]] = M2a
+        M[d][k2B[d]] = M2b
+        # k6: Center points in full sym(lambda5, lambda5, ... ,lambda5)
+        M[d][off6:] = M6[d]
+
+    return M
+
+
+def gm_pts(
+    center,
+    halfwidth,
+    alpha2: float = 0.35856858280031809199064515390793749545406372969943071,
+    alpha4: float = 0.94868329805051379959966806332981556011586654179756505,
+    alpha5: float = 0.68824720161168529772162873429362352512689535661564885,
+    pts=None,
+):
+    # [7, 5] FS rule weights from Genz, Malik: "An adaptive algorithm for numerical
+    # integration Over an N-dimensional rectangular region", updated by Bernstein,
+    # Espelid, Genz in "An Adaptive Algorithm for the Approximate Calculation of
+    # Multiple Integrals"
+    # alpha2 = 0.35856858280031809199064515390793749545406372969943071  # √(9/70)
+    # alpha4 = 0.94868329805051379959966806332981556011586654179756505  # √(9/10)
+    # alpha5 = 0.68824720161168529772162873429362352512689535661564885  # √(9/19)
+    #
+    # {center, halfwidth}  domain_dim * [ regions, { 1 | nevts } ]
+
+    dim = len(center)
+    nreg = center[0].shape[0]
+    npts = num_points(dim)
+    dtype = center[0].dtype
+
+    # p: domain_dim * [ points, regions, { 1 | nevts } ]
+    if not pts:
+        pts = [
+            np.empty((npts, nreg * center[d].shape[1]), dtype=dtype) for d in range(dim)
+        ]
 
-    pts_k0k1(c, l2, l4, p=p[:, 0:d1, ...])
-    pts_k2(c, l4, p=p[:, d1:d2, ...])
-    pts_k6(c, l5, p=p[:, d2:, ...])
+    M = gm_weights(dim, alpha2, alpha4, alpha5)
 
-    return p
+    for d in range(dim):
+        pts[d] = np.empty((npts, nreg * center[d].shape[1]), dtype=dtype)
+        np.multiply.outer(
+            M[d], halfwidth[d].reshape((nreg * halfwidth[d].shape[1])), out=pts[d]
+        )
+        np.add(pts[d], center[d].reshape((1, nreg * center[d].shape[1])), out=pts[d])
+        pts[d] = np.reshape(pts[d], (npts, nreg, center[d].shape[1]))
 
+    return pts
 
-def gk_pts(c: NPF, h: NPF, p: NPF | None = None) -> NPF:
 
+def gk_pts(center, halfwidth, pts=None):
     # GK [7, 15] node points from
     # https://www.advanpix.com/2011/11/07/gauss-kronrod-quadrature-nodes-weights/
     nodes = np.array(
         [
             -0.991455371120812639206854697526329,  # 0
             -0.949107912342758524526189684047851,  # 1
             -0.864864423359769072789712788640926,  # 2
@@ -155,20 +148,13 @@
             0.741531185599394439863864773280788,  # 11
             0.864864423359769072789712788640926,  # 12
             0.949107912342758524526189684047851,  # 13
             0.991455371120812639206854697526329,  # 14
         ]
     )
 
-    # {c, h}  [ regions, events ]
-    c = np.squeeze(c, 0)
-    h = np.squeeze(h, 0)
-
     # {p}  [ points, regions, events ]
-    p = c + np.multiply.outer(nodes, h)
+    p = center[0] + np.multiply.outer(nodes, halfwidth[0])
 
     # {p}  [ 1(domain_dim), points, regions, events ]
-    return np.expand_dims(p, 0)
-
-
-def gm_pts(ndim):
-    pass
+    # return [p]
+    return p[None, ...]
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## cubepy/region.py

```diff
@@ -1,99 +1,59 @@
-# BSD 3-Clause License
-#
-# Copyright (c) 2021, Alex Reustle
-# All rights reserved.
-#
-# Redistribution and use in source and binary forms, with or without
-# modification, are permitted provided that the following conditions are met:
-#
-# 1. Redistributions of source code must retain the above copyright notice, this
-#    list of conditions and the following disclaimer.
-#
-# 2. Redistributions in binary form must reproduce the above copyright notice,
-#    this list of conditions and the following disclaimer in the documentation
-#    and/or other materials provided with the distribution.
-#
-# 3. Neither the name of the copyright holder nor the names of its
-#    contributors may be used to endorse or promote products derived from
-#    this software without specific prior written permission.
-#
-# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
-# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
-# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
-# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
-# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
-# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
-# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
 from __future__ import annotations
 
+from functools import reduce
+from operator import mul
+
 import numpy as np
 
-from .type_aliases import NPF, NPI
+# from .type_aliases import NPT  # , NPF, NPI
+
+# from typing import
 
 __all__ = ["region", "split"]
 
 
-def region(low: NPF, high: NPF) -> tuple[NPF, ...]:
+def region(low, high):
     """Compute the hyper-rectangular region parameters from given limits of integration."""
 
     # :::::::::::::::: Shapes ::::::::::::::::::
-    # {low, high}.shape [ domain_dim, events ]
-    # centers.shape     [ domain_dim, regions_events ]
-    # halfwidth.shape   [ domain_dim, regions_events ]
-    # vol.shape         [ regions_events ]
-
-    if low.shape != high.shape:
-        raise RuntimeError(
-            "Vector limits of integration must be equivalent.", low.shape, high.shape
-        )
-
-    if low.ndim == 1:
-        low = np.expand_dims(low, 0)
-        high = np.expand_dims(high, 0)
-
-    if low.ndim != 2:
-        raise RuntimeError("Input limits shape not supported.")
-
-    centers = (high + low) * 0.5
-    halfwidth = (high - low) * 0.5
-    vol = np.prod(2 * halfwidth, axis=0)
-
-    return centers, halfwidth, vol
-
-
-def split(centers: NPF, halfwidth: NPF, volumes: NPF, split_dim: NPI):
-
-    # centers.shape   [ domain_dim, regions_events ]
-    # split_dim.shape [ 1, regions_events ]
-
-    if np.amin(split_dim) < 0 or np.amax(split_dim) >= (centers.shape[0]):
+    # {low, high} domain_dim * [ { 1 | nevts } ]
+    # center      domain_dim * [ regions, { 1 | nevts } ]
+    # halfwidth   domain_dim * [ regions, { 1 | nevts } ]
+    # vol.shape         [ nevts ]
+
+    center = [np.expand_dims(0.5 * (hi + lo), 0) for lo, hi in zip(low, high)]
+    halfwidth = [np.expand_dims(0.5 * (hi - lo), 0) for lo, hi in zip(low, high)]
+    vol = reduce(mul, [2.0 * h for h in halfwidth]).ravel()
+    return center, halfwidth, vol
+
+
+def split(center, halfwidth, vol, split_dim):
+    """
+    Split the input arrays along the specified dimension according to split_dim
+    unless every event in which that region is active is converged. In that case, drop
+    the region.
+    """
+    if np.amin(split_dim) < 0 or np.amax(split_dim) >= len(center):
         raise IndexError("split dimension invalid")
 
-    if split_dim.ndim < centers.ndim:
-        split_dim = np.expand_dims(split_dim, 0)
-
-    ## {center, hwidth}  [ domain_dim, (regions, events) ]
-
-    mask = np.zeros_like(centers, dtype=np.bool_)
-    np.put_along_axis(mask, split_dim, True, 0)
+    # {center, halfwidth}  [ regions, { 1 | nevts } ]
 
-    h = np.copy(halfwidth)
-    h[mask] *= 0.5
+    dim = len(center)
+    nreg = center[0].shape[0]
 
-    v = np.copy(volumes)
-    v *= 0.5
+    # split_dim [ regions ]
+    split_mask = split_dim == np.arange(dim)[:, None]
 
-    c1 = np.copy(centers)
-    c2 = np.copy(centers)
-    c1[mask] -= h[mask]
-    c2[mask] += h[mask]
+    for d in range(dim):
+        halfwidth[d][split_mask[d]] *= 0.5
+        center[d] = np.tile(center[d], (2, 1))
+        m1 = split_mask[d]
+        m2 = split_mask[d]
+        center[d][:nreg][m1] -= halfwidth[d][m1]
+        center[d][nreg:][m2] += halfwidth[d][m2]
+        halfwidth[d] = np.tile(halfwidth[d], (2, 1))
 
-    c = np.concatenate((c1, c2), axis=1)
-    h = np.concatenate((h, h), axis=1)
-    v = np.concatenate((v, v), axis=0)
+    # vol [ events ]
+    vol *= 0.5
 
-    return c, h, v
+    return center, halfwidth, vol
```

## cubepy/type_aliases.py

```diff
@@ -1,10 +1,21 @@
 from __future__ import annotations
 
+import typing
+
 import numpy as np
 from numpy.typing import NDArray
 
-__all__ = ["NPF", "NPI", "NPB"]
+__all__ = ["NPF", "NPI", "NPB", "InputBoundsT", "ValidBoundsT"]
 
+NPT = NDArray[typing.Union[np.floating, np.integer]]
 NPF = NDArray[np.floating]
 NPI = NDArray[np.integer]
 NPB = NDArray[np.bool_]
+
+# ValidBoundsT = typing.Tuple[typing.Union[int, float, NPT], ...]
+ValidBoundsT = typing.Tuple[NPT, ...]
+
+InputBoundsT = typing.Union[
+    int, float, NPT, typing.Sequence[typing.Union[int, float, NPT]], ValidBoundsT
+]
+# InputBoundsT = typing.Sequence[NPF]
```

## Comparing `cubepy-1.0.2.dist-info/RECORD` & `cubepy-1.9.1.dist-info/RECORD`

 * *Files 27% similar despite different names*

```diff
@@ -1,15 +1,16 @@
-cubepy/__init__.py,sha256=z52dUt3WPqaEFu5b2tq6a1eqJBSyLQW-m0rmB4Sw6PE,256
-cubepy/_version.py,sha256=MauXrpYR0xP8vYLv3Kc7OgBI6t17F4_5t3c9S3T7sbQ,142
-cubepy/converged.py,sha256=zeXoTCNn2IL9VJU3k2vcLZQHxLd98uvEHs7vz4pZS_M,2076
-cubepy/gauss_kronrod.py,sha256=_OGu0AYcuNZUeCjHoWMcfbPEFbQDXUYeJnaVj2QVYdA,4101
-cubepy/genz_malik.py,sha256=6mAxgxSZFGiQcpoNUksrFCJvEqVy1f3T5BS566NQ-NA,5321
-cubepy/integration.py,sha256=Ch65rWcPXLL1WW6Quw7VtwoSjBIzudhHsfajtNjPuZg,10207
-cubepy/points.py,sha256=oSbMGct4CVtB0ib0DeELR-KhwEz2pQkKQDvOkymZWAo,5355
-cubepy/region.py,sha256=Yq-2CLRgzdM7SHoDitSpmbwjYPTHGb_E27_DJ7pREqs,3453
-cubepy/type_aliases.py,sha256=7eCfkHPCMu9jrMSUp8qp26FnJGZqPcdyPEvk4_gOmlk,199
-cubepy-1.0.2.dist-info/LICENSE,sha256=YVNx7e0aujKu97BFoh5b_IrcSekE7rbwCZc5mSY3gfs,1520
-cubepy-1.0.2.dist-info/METADATA,sha256=AWFXxdkcFYsMRbEPYYPm5oGqZBN_EkntBgWnYqIQYds,1939
-cubepy-1.0.2.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-cubepy-1.0.2.dist-info/top_level.txt,sha256=MAChqjkJmhWk1w0Jk6qDnas_jvaciaIXnbEvld8iL48,7
-cubepy-1.0.2.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
-cubepy-1.0.2.dist-info/RECORD,,
+cubepy/__init__.py,sha256=qhY4FF6NQCM9S_l63DHlbyF0B6K7nOC_CjuhElxCimg,309
+cubepy/_version.py,sha256=X614IvhNX7SUr4_ZcCCYzqYK9w1_uXJCpZgOR5iZQug,160
+cubepy/converged.py,sha256=D2w-p1wiMBpF8sQPWPPcD6wB8wc-vCaTO8QDQcvkqQs,781
+cubepy/gauss_kronrod.py,sha256=87pUQ7yXOk-zLwDZlOKoZkOSPjMptGVzMhe91VDtgSw,2889
+cubepy/genz_malik.py,sha256=MHm_-PCyb5bzCbWPpXJF8J2USMnAecg7d-lwmpiotD8,5591
+cubepy/input.py,sha256=JxsuX8KAAqddunMrC__9pzxkBGsFWrFoQH1cQa1VApY,2849
+cubepy/integration.py,sha256=aZ5jpAiL4uygul6pB_xs3R5XdCpXicE3Wb5rlrv8zrM,6263
+cubepy/points.py,sha256=mgMtp_qlgeirHCRy6iz_syzf7st8z2JO2HvtsUsCMiI,5637
+cubepy/region.py,sha256=zpyVKTKVeXj-yJ4ZeC_D5-DV4i3hlJIOExJ8wgAvkpU,1783
+cubepy/type_aliases.py,sha256=zcYet0zJmxDqWI3uuGw66D1pOU9wV8EJNUV2Rz2bqN8,556
+cubepy-1.9.1.dist-info/LICENSE,sha256=QdYgZP5-s62y8W_mIdxCXO8UCTjO3923iO9xBjUbzmM,1074
+cubepy-1.9.1.dist-info/METADATA,sha256=BVBW-vbBoZ468FS5deojiE_KtSCB2yTyQRAVHWU1sfo,4364
+cubepy-1.9.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+cubepy-1.9.1.dist-info/top_level.txt,sha256=MAChqjkJmhWk1w0Jk6qDnas_jvaciaIXnbEvld8iL48,7
+cubepy-1.9.1.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+cubepy-1.9.1.dist-info/RECORD,,
```

