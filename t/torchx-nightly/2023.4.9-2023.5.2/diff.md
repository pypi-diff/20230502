# Comparing `tmp/torchx_nightly-2023.4.9-py3-none-any.whl.zip` & `tmp/torchx_nightly-2023.5.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,119 +1,120 @@
-Zip file size: 240760 bytes, number of entries: 117
--rw-r--r--  2.0 unx      340 b- defN 23-Apr-09 11:17 torchx/__init__.py
--rw-r--r--  2.0 unx      993 b- defN 23-Apr-09 11:17 torchx/notebook.py
--rw-r--r--  2.0 unx      936 b- defN 23-Apr-09 11:17 torchx/version.py
--rw-r--r--  2.0 unx      231 b- defN 23-Apr-09 11:17 torchx/apps/__init__.py
--rw-r--r--  2.0 unx      208 b- defN 23-Apr-09 11:17 torchx/apps/serve/__init__.py
--rw-r--r--  2.0 unx     4371 b- defN 23-Apr-09 11:17 torchx/apps/serve/serve.py
--rw-r--r--  2.0 unx      208 b- defN 23-Apr-09 11:17 torchx/apps/utils/__init__.py
--rw-r--r--  2.0 unx     1412 b- defN 23-Apr-09 11:17 torchx/apps/utils/booth_main.py
--rw-r--r--  2.0 unx     1823 b- defN 23-Apr-09 11:17 torchx/apps/utils/copy_main.py
--rw-r--r--  2.0 unx     3437 b- defN 23-Apr-09 11:17 torchx/apps/utils/process_monitor.py
--rw-r--r--  2.0 unx    10336 b- defN 23-Apr-09 11:17 torchx/cli/__init__.py
--rw-r--r--  2.0 unx     2836 b- defN 23-Apr-09 11:17 torchx/cli/argparse_util.py
--rw-r--r--  2.0 unx      775 b- defN 23-Apr-09 11:17 torchx/cli/cmd_base.py
--rw-r--r--  2.0 unx      820 b- defN 23-Apr-09 11:17 torchx/cli/cmd_cancel.py
--rw-r--r--  2.0 unx     1707 b- defN 23-Apr-09 11:17 torchx/cli/cmd_configure.py
--rw-r--r--  2.0 unx     1268 b- defN 23-Apr-09 11:17 torchx/cli/cmd_describe.py
--rw-r--r--  2.0 unx     1414 b- defN 23-Apr-09 11:17 torchx/cli/cmd_list.py
--rw-r--r--  2.0 unx     6003 b- defN 23-Apr-09 11:17 torchx/cli/cmd_log.py
--rw-r--r--  2.0 unx    10417 b- defN 23-Apr-09 11:17 torchx/cli/cmd_run.py
--rw-r--r--  2.0 unx     1287 b- defN 23-Apr-09 11:17 torchx/cli/cmd_runopts.py
--rw-r--r--  2.0 unx     1821 b- defN 23-Apr-09 11:17 torchx/cli/cmd_status.py
--rw-r--r--  2.0 unx     5203 b- defN 23-Apr-09 11:17 torchx/cli/cmd_tracker.py
--rw-r--r--  2.0 unx      553 b- defN 23-Apr-09 11:17 torchx/cli/colors.py
--rw-r--r--  2.0 unx     3469 b- defN 23-Apr-09 11:17 torchx/cli/main.py
--rw-r--r--  2.0 unx    12106 b- defN 23-Apr-09 11:17 torchx/components/__init__.py
--rw-r--r--  2.0 unx     4135 b- defN 23-Apr-09 11:17 torchx/components/component_test_base.py
--rw-r--r--  2.0 unx    14075 b- defN 23-Apr-09 11:17 torchx/components/dist.py
--rw-r--r--  2.0 unx      697 b- defN 23-Apr-09 11:17 torchx/components/interpret.py
--rw-r--r--  2.0 unx     2814 b- defN 23-Apr-09 11:17 torchx/components/metrics.py
--rw-r--r--  2.0 unx     2141 b- defN 23-Apr-09 11:17 torchx/components/serve.py
--rw-r--r--  2.0 unx     9542 b- defN 23-Apr-09 11:17 torchx/components/structured_arg.py
--rw-r--r--  2.0 unx     1259 b- defN 23-Apr-09 11:17 torchx/components/train.py
--rw-r--r--  2.0 unx     9025 b- defN 23-Apr-09 11:17 torchx/components/utils.py
--rw-r--r--  2.0 unx      208 b- defN 23-Apr-09 11:17 torchx/components/integration_tests/__init__.py
--rw-r--r--  2.0 unx     3980 b- defN 23-Apr-09 11:17 torchx/components/integration_tests/component_provider.py
--rw-r--r--  2.0 unx     5150 b- defN 23-Apr-09 11:17 torchx/components/integration_tests/integ_tests.py
--rw-r--r--  2.0 unx     8786 b- defN 23-Apr-09 11:17 torchx/distributed/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-09 11:17 torchx/examples/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-09 11:17 torchx/examples/apps/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-09 11:17 torchx/examples/apps/datapreproc/__init__.py
--rw-r--r--  2.0 unx     4302 b- defN 23-Apr-09 11:17 torchx/examples/apps/datapreproc/datapreproc.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-09 11:17 torchx/examples/apps/lightning/__init__.py
--rw-r--r--  2.0 unx     6583 b- defN 23-Apr-09 11:17 torchx/examples/apps/lightning/data.py
--rw-r--r--  2.0 unx     5256 b- defN 23-Apr-09 11:17 torchx/examples/apps/lightning/interpret.py
--rw-r--r--  2.0 unx     3932 b- defN 23-Apr-09 11:17 torchx/examples/apps/lightning/model.py
--rw-r--r--  2.0 unx     1926 b- defN 23-Apr-09 11:17 torchx/examples/apps/lightning/profiler.py
--rw-r--r--  2.0 unx     6084 b- defN 23-Apr-09 11:17 torchx/examples/apps/lightning/train.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-09 11:17 torchx/examples/pipelines/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-09 11:17 torchx/examples/pipelines/kfp/__init__.py
--rw-r--r--  2.0 unx     8416 b- defN 23-Apr-09 11:17 torchx/examples/pipelines/kfp/advanced_pipeline.py
--rw-r--r--  2.0 unx     2178 b- defN 23-Apr-09 11:17 torchx/examples/pipelines/kfp/dist_pipeline.py
--rw-r--r--  2.0 unx     2751 b- defN 23-Apr-09 11:17 torchx/examples/pipelines/kfp/intro_pipeline.py
--rw-r--r--  2.0 unx      606 b- defN 23-Apr-09 11:17 torchx/pipelines/__init__.py
--rw-r--r--  2.0 unx      721 b- defN 23-Apr-09 11:17 torchx/pipelines/kfp/__init__.py
--rw-r--r--  2.0 unx     8952 b- defN 23-Apr-09 11:17 torchx/pipelines/kfp/adapter.py
--rw-r--r--  2.0 unx      524 b- defN 23-Apr-09 11:17 torchx/pipelines/kfp/version.py
--rw-r--r--  2.0 unx      300 b- defN 23-Apr-09 11:17 torchx/runner/__init__.py
--rw-r--r--  2.0 unx    26817 b- defN 23-Apr-09 11:17 torchx/runner/api.py
--rw-r--r--  2.0 unx    17171 b- defN 23-Apr-09 11:17 torchx/runner/config.py
--rw-r--r--  2.0 unx     3592 b- defN 23-Apr-09 11:17 torchx/runner/events/__init__.py
--rw-r--r--  2.0 unx     1957 b- defN 23-Apr-09 11:17 torchx/runner/events/api.py
--rw-r--r--  2.0 unx      507 b- defN 23-Apr-09 11:17 torchx/runner/events/handlers.py
--rw-r--r--  2.0 unx      593 b- defN 23-Apr-09 11:17 torchx/runtime/__init__.py
--rw-r--r--  2.0 unx     3040 b- defN 23-Apr-09 11:17 torchx/runtime/tracking/__init__.py
--rw-r--r--  2.0 unx     5457 b- defN 23-Apr-09 11:17 torchx/runtime/tracking/api.py
--rw-r--r--  2.0 unx     2157 b- defN 23-Apr-09 11:17 torchx/schedulers/__init__.py
--rw-r--r--  2.0 unx    13941 b- defN 23-Apr-09 11:17 torchx/schedulers/api.py
--rw-r--r--  2.0 unx    26063 b- defN 23-Apr-09 11:17 torchx/schedulers/aws_batch_scheduler.py
--rw-r--r--  2.0 unx     1352 b- defN 23-Apr-09 11:17 torchx/schedulers/devices.py
--rw-r--r--  2.0 unx    15370 b- defN 23-Apr-09 11:17 torchx/schedulers/docker_scheduler.py
--rw-r--r--  2.0 unx    15993 b- defN 23-Apr-09 11:17 torchx/schedulers/gcp_batch_scheduler.py
--rw-r--r--  2.0 unx     1783 b- defN 23-Apr-09 11:17 torchx/schedulers/ids.py
--rw-r--r--  2.0 unx    41100 b- defN 23-Apr-09 11:17 torchx/schedulers/kubernetes_mcad_scheduler.py
--rw-r--r--  2.0 unx    26830 b- defN 23-Apr-09 11:17 torchx/schedulers/kubernetes_scheduler.py
--rw-r--r--  2.0 unx    37591 b- defN 23-Apr-09 11:17 torchx/schedulers/local_scheduler.py
--rw-r--r--  2.0 unx    17552 b- defN 23-Apr-09 11:17 torchx/schedulers/lsf_scheduler.py
--rw-r--r--  2.0 unx    16190 b- defN 23-Apr-09 11:17 torchx/schedulers/ray_scheduler.py
--rw-r--r--  2.0 unx    19269 b- defN 23-Apr-09 11:17 torchx/schedulers/slurm_scheduler.py
--rw-r--r--  2.0 unx     1992 b- defN 23-Apr-09 11:17 torchx/schedulers/streams.py
--rw-r--r--  2.0 unx      231 b- defN 23-Apr-09 11:17 torchx/schedulers/ray/__init__.py
--rw-r--r--  2.0 unx      610 b- defN 23-Apr-09 11:17 torchx/schedulers/ray/ray_common.py
--rw-r--r--  2.0 unx    12282 b- defN 23-Apr-09 11:17 torchx/schedulers/ray/ray_driver.py
--rw-r--r--  2.0 unx     5462 b- defN 23-Apr-09 11:17 torchx/specs/__init__.py
--rw-r--r--  2.0 unx    33798 b- defN 23-Apr-09 11:17 torchx/specs/api.py
--rw-r--r--  2.0 unx     8512 b- defN 23-Apr-09 11:17 torchx/specs/builders.py
--rw-r--r--  2.0 unx    11714 b- defN 23-Apr-09 11:17 torchx/specs/file_linter.py
--rw-r--r--  2.0 unx    16234 b- defN 23-Apr-09 11:17 torchx/specs/finder.py
--rw-r--r--  2.0 unx     6361 b- defN 23-Apr-09 11:17 torchx/specs/named_resources_aws.py
--rw-r--r--  2.0 unx     2631 b- defN 23-Apr-09 11:17 torchx/specs/named_resources_generic.py
--rw-r--r--  2.0 unx      208 b- defN 23-Apr-09 11:17 torchx/specs/test/components/__init__.py
--rw-r--r--  2.0 unx      546 b- defN 23-Apr-09 11:17 torchx/specs/test/components/a/__init__.py
--rw-r--r--  2.0 unx      208 b- defN 23-Apr-09 11:17 torchx/specs/test/components/a/b/__init__.py
--rw-r--r--  2.0 unx      539 b- defN 23-Apr-09 11:17 torchx/specs/test/components/a/b/c.py
--rw-r--r--  2.0 unx      231 b- defN 23-Apr-09 11:17 torchx/specs/test/components/c/__init__.py
--rw-r--r--  2.0 unx      531 b- defN 23-Apr-09 11:17 torchx/specs/test/components/c/d.py
--rw-r--r--  2.0 unx     4206 b- defN 23-Apr-09 11:17 torchx/tracker/__init__.py
--rw-r--r--  2.0 unx    11263 b- defN 23-Apr-09 11:17 torchx/tracker/api.py
--rw-r--r--  2.0 unx    13221 b- defN 23-Apr-09 11:17 torchx/tracker/mlflow.py
--rw-r--r--  2.0 unx      231 b- defN 23-Apr-09 11:17 torchx/tracker/backend/__init__.py
--rw-r--r--  2.0 unx    10425 b- defN 23-Apr-09 11:17 torchx/tracker/backend/fsspec.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-09 11:17 torchx/util/__init__.py
--rw-r--r--  2.0 unx      390 b- defN 23-Apr-09 11:17 torchx/util/datetime.py
--rw-r--r--  2.0 unx     2710 b- defN 23-Apr-09 11:17 torchx/util/entrypoints.py
--rw-r--r--  2.0 unx     1792 b- defN 23-Apr-09 11:17 torchx/util/io.py
--rw-r--r--  2.0 unx      448 b- defN 23-Apr-09 11:17 torchx/util/shlex.py
--rw-r--r--  2.0 unx      663 b- defN 23-Apr-09 11:17 torchx/util/strings.py
--rw-r--r--  2.0 unx     7016 b- defN 23-Apr-09 11:17 torchx/util/types.py
--rw-r--r--  2.0 unx      783 b- defN 23-Apr-09 11:17 torchx/workspace/__init__.py
--rw-r--r--  2.0 unx     5464 b- defN 23-Apr-09 11:17 torchx/workspace/api.py
--rw-r--r--  2.0 unx     2253 b- defN 23-Apr-09 11:17 torchx/workspace/dir_workspace.py
--rw-r--r--  2.0 unx     9208 b- defN 23-Apr-09 11:17 torchx/workspace/docker_workspace.py
--rw-r--r--  2.0 unx     1721 b- defN 23-Apr-09 11:38 torchx_nightly-2023.4.9.dist-info/LICENSE
--rw-r--r--  2.0 unx     5513 b- defN 23-Apr-09 11:38 torchx_nightly-2023.4.9.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-09 11:38 torchx_nightly-2023.4.9.dist-info/WHEEL
--rw-r--r--  2.0 unx      170 b- defN 23-Apr-09 11:38 torchx_nightly-2023.4.9.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        7 b- defN 23-Apr-09 11:38 torchx_nightly-2023.4.9.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    10274 b- defN 23-Apr-09 11:38 torchx_nightly-2023.4.9.dist-info/RECORD
-117 files, 672582 bytes uncompressed, 224460 bytes compressed:  66.6%
+Zip file size: 243407 bytes, number of entries: 118
+-rw-r--r--  2.0 unx      340 b- defN 23-May-02 11:18 torchx/__init__.py
+-rw-r--r--  2.0 unx      993 b- defN 23-May-02 11:18 torchx/notebook.py
+-rw-r--r--  2.0 unx      936 b- defN 23-May-02 11:18 torchx/version.py
+-rw-r--r--  2.0 unx      231 b- defN 23-May-02 11:18 torchx/apps/__init__.py
+-rw-r--r--  2.0 unx      208 b- defN 23-May-02 11:18 torchx/apps/serve/__init__.py
+-rw-r--r--  2.0 unx     4371 b- defN 23-May-02 11:18 torchx/apps/serve/serve.py
+-rw-r--r--  2.0 unx      208 b- defN 23-May-02 11:18 torchx/apps/utils/__init__.py
+-rw-r--r--  2.0 unx     1412 b- defN 23-May-02 11:18 torchx/apps/utils/booth_main.py
+-rw-r--r--  2.0 unx     1823 b- defN 23-May-02 11:18 torchx/apps/utils/copy_main.py
+-rw-r--r--  2.0 unx     3437 b- defN 23-May-02 11:18 torchx/apps/utils/process_monitor.py
+-rw-r--r--  2.0 unx    10336 b- defN 23-May-02 11:18 torchx/cli/__init__.py
+-rw-r--r--  2.0 unx     2836 b- defN 23-May-02 11:18 torchx/cli/argparse_util.py
+-rw-r--r--  2.0 unx      775 b- defN 23-May-02 11:18 torchx/cli/cmd_base.py
+-rw-r--r--  2.0 unx      820 b- defN 23-May-02 11:18 torchx/cli/cmd_cancel.py
+-rw-r--r--  2.0 unx     1707 b- defN 23-May-02 11:18 torchx/cli/cmd_configure.py
+-rw-r--r--  2.0 unx     1268 b- defN 23-May-02 11:18 torchx/cli/cmd_describe.py
+-rw-r--r--  2.0 unx     1414 b- defN 23-May-02 11:18 torchx/cli/cmd_list.py
+-rw-r--r--  2.0 unx     6003 b- defN 23-May-02 11:18 torchx/cli/cmd_log.py
+-rw-r--r--  2.0 unx    10417 b- defN 23-May-02 11:18 torchx/cli/cmd_run.py
+-rw-r--r--  2.0 unx     1287 b- defN 23-May-02 11:18 torchx/cli/cmd_runopts.py
+-rw-r--r--  2.0 unx     1821 b- defN 23-May-02 11:18 torchx/cli/cmd_status.py
+-rw-r--r--  2.0 unx     5203 b- defN 23-May-02 11:18 torchx/cli/cmd_tracker.py
+-rw-r--r--  2.0 unx      553 b- defN 23-May-02 11:18 torchx/cli/colors.py
+-rw-r--r--  2.0 unx     3469 b- defN 23-May-02 11:18 torchx/cli/main.py
+-rw-r--r--  2.0 unx    12106 b- defN 23-May-02 11:18 torchx/components/__init__.py
+-rw-r--r--  2.0 unx     4135 b- defN 23-May-02 11:18 torchx/components/component_test_base.py
+-rw-r--r--  2.0 unx    14079 b- defN 23-May-02 11:18 torchx/components/dist.py
+-rw-r--r--  2.0 unx      697 b- defN 23-May-02 11:18 torchx/components/interpret.py
+-rw-r--r--  2.0 unx     2814 b- defN 23-May-02 11:18 torchx/components/metrics.py
+-rw-r--r--  2.0 unx     2141 b- defN 23-May-02 11:18 torchx/components/serve.py
+-rw-r--r--  2.0 unx     9542 b- defN 23-May-02 11:18 torchx/components/structured_arg.py
+-rw-r--r--  2.0 unx     1259 b- defN 23-May-02 11:18 torchx/components/train.py
+-rw-r--r--  2.0 unx     9025 b- defN 23-May-02 11:18 torchx/components/utils.py
+-rw-r--r--  2.0 unx      208 b- defN 23-May-02 11:18 torchx/components/integration_tests/__init__.py
+-rw-r--r--  2.0 unx     3980 b- defN 23-May-02 11:18 torchx/components/integration_tests/component_provider.py
+-rw-r--r--  2.0 unx     5150 b- defN 23-May-02 11:18 torchx/components/integration_tests/integ_tests.py
+-rw-r--r--  2.0 unx    10280 b- defN 23-May-02 11:18 torchx/distributed/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-02 11:18 torchx/examples/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-02 11:18 torchx/examples/apps/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-02 11:18 torchx/examples/apps/datapreproc/__init__.py
+-rw-r--r--  2.0 unx     4302 b- defN 23-May-02 11:18 torchx/examples/apps/datapreproc/datapreproc.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-02 11:18 torchx/examples/apps/lightning/__init__.py
+-rw-r--r--  2.0 unx     6583 b- defN 23-May-02 11:18 torchx/examples/apps/lightning/data.py
+-rw-r--r--  2.0 unx     5256 b- defN 23-May-02 11:18 torchx/examples/apps/lightning/interpret.py
+-rw-r--r--  2.0 unx     3932 b- defN 23-May-02 11:18 torchx/examples/apps/lightning/model.py
+-rw-r--r--  2.0 unx     1926 b- defN 23-May-02 11:18 torchx/examples/apps/lightning/profiler.py
+-rw-r--r--  2.0 unx     6084 b- defN 23-May-02 11:18 torchx/examples/apps/lightning/train.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-02 11:18 torchx/examples/pipelines/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-02 11:18 torchx/examples/pipelines/kfp/__init__.py
+-rw-r--r--  2.0 unx     8416 b- defN 23-May-02 11:18 torchx/examples/pipelines/kfp/advanced_pipeline.py
+-rw-r--r--  2.0 unx     2178 b- defN 23-May-02 11:18 torchx/examples/pipelines/kfp/dist_pipeline.py
+-rw-r--r--  2.0 unx     2751 b- defN 23-May-02 11:18 torchx/examples/pipelines/kfp/intro_pipeline.py
+-rw-r--r--  2.0 unx      606 b- defN 23-May-02 11:18 torchx/pipelines/__init__.py
+-rw-r--r--  2.0 unx      721 b- defN 23-May-02 11:18 torchx/pipelines/kfp/__init__.py
+-rw-r--r--  2.0 unx     8952 b- defN 23-May-02 11:18 torchx/pipelines/kfp/adapter.py
+-rw-r--r--  2.0 unx      524 b- defN 23-May-02 11:18 torchx/pipelines/kfp/version.py
+-rw-r--r--  2.0 unx      300 b- defN 23-May-02 11:18 torchx/runner/__init__.py
+-rw-r--r--  2.0 unx    26817 b- defN 23-May-02 11:18 torchx/runner/api.py
+-rw-r--r--  2.0 unx    17171 b- defN 23-May-02 11:18 torchx/runner/config.py
+-rw-r--r--  2.0 unx     3592 b- defN 23-May-02 11:18 torchx/runner/events/__init__.py
+-rw-r--r--  2.0 unx     1957 b- defN 23-May-02 11:18 torchx/runner/events/api.py
+-rw-r--r--  2.0 unx      507 b- defN 23-May-02 11:18 torchx/runner/events/handlers.py
+-rw-r--r--  2.0 unx      593 b- defN 23-May-02 11:18 torchx/runtime/__init__.py
+-rw-r--r--  2.0 unx     3040 b- defN 23-May-02 11:18 torchx/runtime/tracking/__init__.py
+-rw-r--r--  2.0 unx     5457 b- defN 23-May-02 11:18 torchx/runtime/tracking/api.py
+-rw-r--r--  2.0 unx     2157 b- defN 23-May-02 11:18 torchx/schedulers/__init__.py
+-rw-r--r--  2.0 unx    13941 b- defN 23-May-02 11:18 torchx/schedulers/api.py
+-rw-r--r--  2.0 unx    26405 b- defN 23-May-02 11:18 torchx/schedulers/aws_batch_scheduler.py
+-rw-r--r--  2.0 unx     1352 b- defN 23-May-02 11:18 torchx/schedulers/devices.py
+-rw-r--r--  2.0 unx    15370 b- defN 23-May-02 11:18 torchx/schedulers/docker_scheduler.py
+-rw-r--r--  2.0 unx    15993 b- defN 23-May-02 11:18 torchx/schedulers/gcp_batch_scheduler.py
+-rw-r--r--  2.0 unx     1783 b- defN 23-May-02 11:18 torchx/schedulers/ids.py
+-rw-r--r--  2.0 unx    42500 b- defN 23-May-02 11:18 torchx/schedulers/kubernetes_mcad_scheduler.py
+-rw-r--r--  2.0 unx    26830 b- defN 23-May-02 11:18 torchx/schedulers/kubernetes_scheduler.py
+-rw-r--r--  2.0 unx    39945 b- defN 23-May-02 11:18 torchx/schedulers/local_scheduler.py
+-rw-r--r--  2.0 unx    17552 b- defN 23-May-02 11:18 torchx/schedulers/lsf_scheduler.py
+-rw-r--r--  2.0 unx    16190 b- defN 23-May-02 11:18 torchx/schedulers/ray_scheduler.py
+-rw-r--r--  2.0 unx    19269 b- defN 23-May-02 11:18 torchx/schedulers/slurm_scheduler.py
+-rw-r--r--  2.0 unx     1992 b- defN 23-May-02 11:18 torchx/schedulers/streams.py
+-rw-r--r--  2.0 unx      231 b- defN 23-May-02 11:18 torchx/schedulers/ray/__init__.py
+-rw-r--r--  2.0 unx      610 b- defN 23-May-02 11:18 torchx/schedulers/ray/ray_common.py
+-rw-r--r--  2.0 unx    12282 b- defN 23-May-02 11:18 torchx/schedulers/ray/ray_driver.py
+-rw-r--r--  2.0 unx     5462 b- defN 23-May-02 11:18 torchx/specs/__init__.py
+-rw-r--r--  2.0 unx    33798 b- defN 23-May-02 11:18 torchx/specs/api.py
+-rw-r--r--  2.0 unx     8512 b- defN 23-May-02 11:18 torchx/specs/builders.py
+-rw-r--r--  2.0 unx    11714 b- defN 23-May-02 11:18 torchx/specs/file_linter.py
+-rw-r--r--  2.0 unx    16234 b- defN 23-May-02 11:18 torchx/specs/finder.py
+-rw-r--r--  2.0 unx     6361 b- defN 23-May-02 11:18 torchx/specs/named_resources_aws.py
+-rw-r--r--  2.0 unx     2631 b- defN 23-May-02 11:18 torchx/specs/named_resources_generic.py
+-rw-r--r--  2.0 unx      208 b- defN 23-May-02 11:18 torchx/specs/test/components/__init__.py
+-rw-r--r--  2.0 unx      546 b- defN 23-May-02 11:18 torchx/specs/test/components/a/__init__.py
+-rw-r--r--  2.0 unx      208 b- defN 23-May-02 11:18 torchx/specs/test/components/a/b/__init__.py
+-rw-r--r--  2.0 unx      539 b- defN 23-May-02 11:18 torchx/specs/test/components/a/b/c.py
+-rw-r--r--  2.0 unx      231 b- defN 23-May-02 11:18 torchx/specs/test/components/c/__init__.py
+-rw-r--r--  2.0 unx      531 b- defN 23-May-02 11:18 torchx/specs/test/components/c/d.py
+-rw-r--r--  2.0 unx     4206 b- defN 23-May-02 11:18 torchx/tracker/__init__.py
+-rw-r--r--  2.0 unx    11263 b- defN 23-May-02 11:18 torchx/tracker/api.py
+-rw-r--r--  2.0 unx    14487 b- defN 23-May-02 11:18 torchx/tracker/mlflow.py
+-rw-r--r--  2.0 unx      231 b- defN 23-May-02 11:18 torchx/tracker/backend/__init__.py
+-rw-r--r--  2.0 unx    10425 b- defN 23-May-02 11:18 torchx/tracker/backend/fsspec.py
+-rw-r--r--  2.0 unx        0 b- defN 23-May-02 11:18 torchx/util/__init__.py
+-rw-r--r--  2.0 unx     1084 b- defN 23-May-02 11:18 torchx/util/cuda.py
+-rw-r--r--  2.0 unx      390 b- defN 23-May-02 11:18 torchx/util/datetime.py
+-rw-r--r--  2.0 unx     2710 b- defN 23-May-02 11:18 torchx/util/entrypoints.py
+-rw-r--r--  2.0 unx     1792 b- defN 23-May-02 11:18 torchx/util/io.py
+-rw-r--r--  2.0 unx      448 b- defN 23-May-02 11:18 torchx/util/shlex.py
+-rw-r--r--  2.0 unx      663 b- defN 23-May-02 11:18 torchx/util/strings.py
+-rw-r--r--  2.0 unx     7016 b- defN 23-May-02 11:18 torchx/util/types.py
+-rw-r--r--  2.0 unx      783 b- defN 23-May-02 11:18 torchx/workspace/__init__.py
+-rw-r--r--  2.0 unx     5464 b- defN 23-May-02 11:18 torchx/workspace/api.py
+-rw-r--r--  2.0 unx     2253 b- defN 23-May-02 11:18 torchx/workspace/dir_workspace.py
+-rw-r--r--  2.0 unx     9208 b- defN 23-May-02 11:18 torchx/workspace/docker_workspace.py
+-rw-r--r--  2.0 unx     1721 b- defN 23-May-02 11:27 torchx_nightly-2023.5.2.dist-info/LICENSE
+-rw-r--r--  2.0 unx     5513 b- defN 23-May-02 11:27 torchx_nightly-2023.5.2.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-02 11:27 torchx_nightly-2023.5.2.dist-info/WHEEL
+-rw-r--r--  2.0 unx      170 b- defN 23-May-02 11:27 torchx_nightly-2023.5.2.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        7 b- defN 23-May-02 11:27 torchx_nightly-2023.5.2.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    10351 b- defN 23-May-02 11:27 torchx_nightly-2023.5.2.dist-info/RECORD
+118 files, 680603 bytes uncompressed, 226993 bytes compressed:  66.6%
```

## zipnote {}

```diff
@@ -297,14 +297,17 @@
 
 Filename: torchx/tracker/backend/fsspec.py
 Comment: 
 
 Filename: torchx/util/__init__.py
 Comment: 
 
+Filename: torchx/util/cuda.py
+Comment: 
+
 Filename: torchx/util/datetime.py
 Comment: 
 
 Filename: torchx/util/entrypoints.py
 Comment: 
 
 Filename: torchx/util/io.py
@@ -327,26 +330,26 @@
 
 Filename: torchx/workspace/dir_workspace.py
 Comment: 
 
 Filename: torchx/workspace/docker_workspace.py
 Comment: 
 
-Filename: torchx_nightly-2023.4.9.dist-info/LICENSE
+Filename: torchx_nightly-2023.5.2.dist-info/LICENSE
 Comment: 
 
-Filename: torchx_nightly-2023.4.9.dist-info/METADATA
+Filename: torchx_nightly-2023.5.2.dist-info/METADATA
 Comment: 
 
-Filename: torchx_nightly-2023.4.9.dist-info/WHEEL
+Filename: torchx_nightly-2023.5.2.dist-info/WHEEL
 Comment: 
 
-Filename: torchx_nightly-2023.4.9.dist-info/entry_points.txt
+Filename: torchx_nightly-2023.5.2.dist-info/entry_points.txt
 Comment: 
 
-Filename: torchx_nightly-2023.4.9.dist-info/top_level.txt
+Filename: torchx_nightly-2023.5.2.dist-info/top_level.txt
 Comment: 
 
-Filename: torchx_nightly-2023.4.9.dist-info/RECORD
+Filename: torchx_nightly-2023.5.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## torchx/components/dist.py

```diff
@@ -279,15 +279,15 @@
                 min_replicas=min_nnodes,
                 entrypoint="bash",
                 num_replicas=int(max_nnodes),
                 resource=specs.resource(cpu=cpu, gpu=gpu, memMB=memMB, h=h),
                 args=["-c", _args_join(cmd)],
                 env=env,
                 port_map={
-                    "c10d": 29500,
+                    "c10d": rdzv_port,
                 },
                 max_retries=max_retries,
                 mounts=specs.parse_mounts(mounts) if mounts else [],
             )
         ],
     )
```

## torchx/distributed/__init__.py

```diff
@@ -12,88 +12,124 @@
 import os
 import warnings
 from contextlib import contextmanager
 from typing import Any, Iterator
 
 import torch
 import torch.distributed as dist
+from torch.distributed.distributed_c10d import _get_default_group
+
+from torchx.util.cuda import has_cuda_devices
 from typing_extensions import Literal
 
 log: logging.Logger = logging.getLogger(__name__)
 
 
 def local_rank() -> int:
     """
     Returns the local rank (aka rank within the node) of this process.
-    Typically the local rank is used to set the CUDA device on the node.
+    Typically, the local rank is used to set the CUDA device on the node.
 
     .. warning::
         This function only works correctly if the invoker of the program sets ``LOCAL_RANK`` env var
         or invokes the program with ``torchrun`` (aka ``torch.distributed.run``) or ``torchx``.
         If ``LOCAL_RANK`` is not set or the process group is not initialized
         then this function assumes that the process is not distributed and trivially returns 0.
 
     """
 
-    if not dist.is_initialized():
-        return 0
-
-    if "LOCAL_RANK" not in os.environ:
-        warnings.warn(
-            "\n"
-            "==============================================================================================\n"
-            "`LOCAL_RANK` environment variable is not set. Will trivially return 0 for local_rank.\n"
-            " It is recommended to use torchrun/torchx to run your script or set the `LOCAL_RANK` manually.\n"
-            " For additional details see:\n"
-            "  1) https://pytorch.org/torchx/latest/components/distributed.html\n"
-            "  2) https://pytorch.org/docs/stable/elastic/run.html\n"
-            "=============================================================================================="
-        )
-        return 0
-    else:
+    if "LOCAL_RANK" in os.environ:
         return int(os.environ["LOCAL_RANK"])
+    else:  # "LOCAL_RANK" not in os.environ
+        if dist.is_initialized():
+            warnings.warn(
+                "\n"
+                "==============================================================================================\n"
+                " The default torch.distributed process group is initialized\n"
+                " but the `LOCAL_RANK` environment variable is not set. Will trivially return 0 for local_rank.\n"
+                " It is recommended to use torchrun/torchx to run your script or set the `LOCAL_RANK` manually.\n"
+                " For additional details see:\n"
+                "  1) https://pytorch.org/torchx/latest/components/distributed.html\n"
+                "  2) https://pytorch.org/docs/stable/elastic/run.html\n"
+                "=============================================================================================="
+            )
+        return 0
 
 
 def local_cuda_device() -> torch.device:
     """
     Returns the CUDA device (as a ``torch.device``) based on the local rank.
 
-    See Also: :py:func:`get_local_rank`.
+    .. note::
+        For hardware agnostic code, prefer to use :py:func:`local_device`, which will
+        return the correct device based on the backend the process group has been initialized with
+
+    See Also: :py:func:`local_rank`.
     """
     return torch.device(f"cuda:{local_rank()}")
 
 
+def local_device() -> torch.device:
+    """
+    Returns the device that the current process should be using for models and tensors
+    based on the default process group.
+
+    .. note:: If the process group has not been initialized
+        then this method returns ``cuda`` if GPU is available on the machine, and ``cpu`` otherwise.
+
+    Returns ``cuda:$LOCAL_RANK`` if the default process group's backend is ``nccl`` otherwise ``cpu``
+
+    """
+
+    if dist.is_initialized():
+        default_pg = _get_default_group()
+        return (
+            local_cuda_device()
+            if default_pg.options.backend == "nccl"
+            else torch.device("cpu")
+        )
+    else:
+        return torch.device("cuda") if has_cuda_devices() else torch.device("cpu")
+
+
 def rank() -> int:
     """
     A non-distributed-safe get_rank call. Unlike ``torch.distributed.get_rank()``
     this method will not fail if being invoked from a non-distributed (e.g. process group not initialized)
     context. Therefore, this method is safe to use in internal methods that may be used
     in non-distributed contexts as well.
 
     Returns:
         If a process group has been initialized returns the value returned by ``torch.distributed.get_rank()``.
-        Otherwise, returns 0 (trivial rank)
+        Otherwise, returns the rank specified by the env var ``RANK`` or 0 (trivial rank) if no such env var exists.
 
     """
-    return dist.get_rank() if dist.is_initialized() else 0
+    if dist.is_initialized():
+        return dist.get_rank()
+    else:
+        return int(os.getenv("RANK", "0"))
 
 
 def world_size() -> int:
     """
     A non-distributed-safe get_world_size call. Unlike ``torch.distributed.get_world_size()``,
     this method will not fail if being invoked from a non-distributed (e.g. process group not initialized)
-    context. Threefore, this method is safe to use in internal mthods that may be used
+    context. Therefore, this method is safe to use in internal mthods that may be used
     in non-distributed contexts as well.
 
     Returns:
         If a process group has been initialized returns the value returns by ``torch.distributed.get_world_size()``.
-        Otherwise, returns 1 (trivial world_size)
+        Otherwise, returns the world size specified by the env var ``WORLD_SIZE`` or 1 (trivial world_size)
+        if no such env var exists.
 
     """
-    return dist.get_world_size() if dist.is_initialized() else 1
+    if dist.is_initialized():
+        return dist.get_world_size()
+    else:
+        return int(os.getenv("WORLD_SIZE", "1"))
 
 
 def is_rank0() -> bool:
     """
     Returns ``True`` if the caller is rank 0 (in a distributed setting).
     If no process group has been initialized, then this method assumes
     that the caller is a single-process (aka not-distributed) and trivially returns ``True``.
```

## torchx/schedulers/aws_batch_scheduler.py

```diff
@@ -14,15 +14,15 @@
 
 Prerequisites
 ==============
 
 You'll need to create an AWS Batch queue configured for multi-node parallel jobs.
 
 See
-https://docs.aws.amazon.com/batch/latest/userguide/Batch_GetStarted.html#first-run-step-2
+https://docs.aws.amazon.com/batch/latest/userguide/Batch_GetStarted.html
 for how to setup a job queue and compute environment. It needs to be backed by
 EC2 for multi-node parallel jobs.
 
 See
 https://docs.aws.amazon.com/batch/latest/userguide/multi-node-parallel-jobs.html
 for more information on distributed jobs.
 
@@ -647,30 +647,38 @@
 
         job = self._get_job(app_id)
         if job is None:
             return []
         node_properties = job["nodeProperties"]
         nodes = node_properties["nodeRangeProperties"]
 
-        i = 0
+        global_idx = -1
         # finds the global idx of the node that matches the role's k'th replica
         for i, node in enumerate(nodes):
             container = node["container"]
             env = {opt["name"]: opt["value"] for opt in container["environment"]}
             node_role = env.get(ENV_TORCHX_ROLE_NAME, DEFAULT_ROLE_NAME)
             start_idx, _ = _parse_start_and_end_idx(
                 node["targetNodes"],
                 node_properties["numNodes"],
             )
-            replica_id = start_idx + k
 
-            if role_name == node_role and k == replica_id:
+            # k with the replica idx within the role
+            # so add k to the start index of the node group to get the global idx
+            global_idx = start_idx + k
+
+            if role_name == node_role:
                 break
 
-        job = self._get_job(app_id, rank=i)
+        assert global_idx != -1, (
+            f"Role `{role_name}`'s replica `{k}` not found in job `{job['jobName']}.\n"
+            f"Inspect the job by running `aws batch describe-jobs --jobs {job['jobId']}`"
+        )
+
+        job = self._get_job(app_id, rank=global_idx)
         if not job:
             return []
 
         if "status" in job and job["status"] == "RUNNING":
             stream_name = job["container"]["logStreamName"]
         else:
             attempts = job["attempts"]
```

## torchx/schedulers/kubernetes_mcad_scheduler.py

```diff
@@ -360,17 +360,17 @@
             priority_class_name=priority_class_name,
         ),
         metadata=metadata,
     )
 
 
 def create_pod_group(
-    app: AppDef, role: Role, namespace: str, app_id: str
+    app: AppDef, role: Role, role_idx: int, namespace: str, app_id: str
 ) -> "Dict[str, Any]":
-    pod_group_name = app_id + "-" + cleanup_str(role.name) + "-pg"
+    pod_group_name = app_id + "-pg" + str(role_idx)
 
     labels = object_labels(app, app_id)
     labels.update({"appwrapper.mcad.ibm.com": app_id})
 
     pod_group: Dict[str, Any] = {
         "apiVersion": "scheduling.sigs.k8s.io/v1alpha1",
         "kind": "PodGroup",
@@ -453,14 +453,43 @@
     """
     if data.startswith("-"):
         data = data[1:]
     pattern = r"[a-z0-9\-]"
     return "".join(re.findall(pattern, data.lower())).lstrip("0123456789")
 
 
+def get_unique_truncated_appid(app: AppDef) -> str:
+    """
+    Some Kubernetes objects need to have names that are
+    63 characters or less. When creating the unique app_id,
+    this function calculates the max size to pass to
+    make_unique. The PodGroup name includes 3 characters plus
+    the role_id characters. The minimum number of characters
+    for the unique identifier is 4.  These amounts are taken into account.
+    """
+    default_size = 14
+    uid_chars = 4
+    pg_chars = 3 + len(app.roles)
+    size = 63 - (len(app.name) + uid_chars + pg_chars)
+
+    unique_id_size = default_size if size > default_size else size
+
+    if unique_id_size <= 3:
+        msg = "Name size has too many characters for some Kubernetes objects. Truncating \
+application name."
+        warnings.warn(msg)
+        end = 63 - uid_chars - pg_chars
+        substring = app.name[0:end]
+        app.name = substring
+        unique_id_size = 3
+
+    unique_app_id = cleanup_str(make_unique(app.name, unique_id_size))
+    return unique_app_id
+
+
 def get_port_for_service(app: AppDef) -> str:
     # Initialize port to default
     port = "29500"
 
     for role_idx, role in enumerate(app.roles):
         if role.port_map is None:
             continue
@@ -471,14 +500,27 @@
         msg = """Warning: port_map set to invalid port number. Value must be between 1-65535, with torchx default = 29500. Setting port to default = 29500"""
         port = "29500"
         warnings.warn(msg)
 
     return port
 
 
+def enable_retry(
+    job_spec: Dict[str, Any], appwrapper_retries: int, total_pods: int
+) -> None:
+    requeue_dict = {
+        "timeInSeconds": 300,
+        "maxTimeInSeconds": 0,
+        "growthType": "exponential",
+        "maxNumRequeuings": appwrapper_retries,
+    }
+    nested_specs = {"minAvailable": total_pods, "requeuing": requeue_dict}
+    job_spec["schedulingSpec"] = nested_specs
+
+
 def app_to_resource(
     app: AppDef,
     namespace: str,
     service_account: Optional[str],
     image_secret: Optional[str],
     coscheduler_name: Optional[str],
     priority_class_name: Optional[str],
@@ -486,24 +528,27 @@
     priority: Optional[int] = None,
 ) -> Dict[str, Any]:
     """
     app_to_resource creates a AppWrapper/MCAD Kubernetes resource definition from
     the provided AppDef. The resource definition can be used to launch the
     app on Kubernetes.
 
+    MCAD supports retries at the APPLICATION level. In the case of multiple TorchX Roles,
+    the AppWrapper maximum number of retries
+    count is set to the minimum of the max_retries of the roles.
     """
 
     genericitems = []
 
-    unique_app_id = cleanup_str(make_unique(app.name))
+    unique_app_id = get_unique_truncated_appid(app)
 
     if coscheduler_name is not None:
         for role_idx, role in enumerate(app.roles):
             genericitem_pod_group = create_pod_group(
-                app, role, namespace, unique_app_id
+                app, role, role_idx, namespace, unique_app_id
             )
             genericitems.append(genericitem_pod_group)
 
     for role_idx, role in enumerate(app.roles):
         for replica_id in range(role.num_replicas):
             values = macros.Values(
                 img_root="",
@@ -543,23 +588,14 @@
                 )
             )
 
             genericitem: Dict[str, Any] = {
                 "replicas": 1,
                 "generictemplate": pod,
             }
-            # TODO: retry support here. For more information, see MCAD GitHub issue #207
-            if role.max_retries > 0:
-                genericitem["maxRetry"] = role.max_retries
-                genericitem["policies"] = RETRY_POLICIES[role.retry_policy]
-                msg = f"""
-MCAD currently does not support retries. Role {role.name} configured with restarts: {role.max_retries}.
-                """
-                warnings.warn(msg)
-
             genericitems.append(genericitem)
 
     """
     Create Service:
     The selector will have the key 'appwrapper.mcad.ibm.com', and the value will be 
     the appwrapper name
     """
@@ -581,20 +617,26 @@
             "GenericItems": genericitems,
         },
     }
 
     if priority is not None:
         job_spec["priority"] = priority
 
+    appwrapper_retries = min(role.max_retries for role in app.roles)
+    if appwrapper_retries > 0:
+        total_pods = sum(role.num_replicas for role in app.roles)
+        enable_retry(job_spec, appwrapper_retries, total_pods)
+
     resource: Dict[str, object] = {
         "apiVersion": "mcad.ibm.com/v1beta1",
         "kind": "AppWrapper",
         "metadata": {"name": unique_app_id, "namespace": namespace},
         "spec": job_spec,
     }
+
     return resource
 
 
 # Helper function for MCAD generic items information -> TorchX Role
 def get_role_information(generic_items: Iterable[Dict[str, Any]]) -> Dict[str, Any]:
     # Store unique role information
     roles = {}
@@ -1218,12 +1260,12 @@
         LABEL_VERSION: torchx.__version__,
         LABEL_APP_NAME: app.name,
         LABEL_ROLE_INDEX: str(role_idx),
         LABEL_ROLE_NAME: role.name,
         LABEL_REPLICA_ID: str(replica_id),
     }
     if coscheduler_name is not None:
-        pod_group = app_id + "-" + cleanup_str(role.name) + "-pg"
+        pod_group = app_id + "-pg" + str(role_idx)
         pod_labels.update({"pod-group.scheduling.sigs.k8s.io": pod_group})
 
     labels.update(pod_labels)
     return labels
```

## torchx/schedulers/local_scheduler.py

```diff
@@ -41,24 +41,24 @@
 from torchx.schedulers.ids import make_unique
 from torchx.schedulers.streams import Tee
 from torchx.specs.api import AppDef, AppState, is_terminal, macros, NONE, Role, runopts
 
 from torchx.util.types import none_throws
 from typing_extensions import TypedDict
 
-
 log: logging.Logger = logging.getLogger(__name__)
 
 STDOUT_LOG = "stdout.log"
 STDERR_LOG = "stderr.log"
 COMBINED_LOG = "combined.log"
 
-
 NA: str = "<N/A>"
 
+ENV_CUDA_VISIBLE_DEVICES = "CUDA_VISIBLE_DEVICES"
+
 
 class SignalException(Exception):
     """
     Exception is raised during the runtime when the torchx local scheduler process
     got termination signal.
     """
 
@@ -759,73 +759,123 @@
         self, app: AppDef, cfg: LocalOpts
     ) -> AppDryRunInfo[PopenRequest]:
         request = self._to_popen_request(app, cfg)
         return AppDryRunInfo(
             request, lambda p: pprint.pformat(asdict(p), indent=2, width=80)
         )
 
-    def _get_gpu_device_count(self) -> int:
+    def _cuda_device_count(self) -> int:
+        # this method deliberately does not use ``torch.cuda.device_count()``
+        # to avoid taking a dependency on pytorch
+        # this make sit possible to avoid a BUCK dependency (internally at Meta)
+        # on //caffe2:torch which slows down builds of //torchx:* rules
         gpu_cmd = "nvidia-smi -L"
         try:
             log.debug(f"Running {gpu_cmd}")
             result = subprocess.run(
                 gpu_cmd.split(), capture_output=True, text=True, check=True
             )
             log.debug(f"Cmd {gpu_cmd} returned: {result}")
             gpus_info = [gpu_info for gpu_info in result.stdout.split("\n") if gpu_info]
             return len(gpus_info)
         except subprocess.CalledProcessError as e:
             log.exception(f"Got exception while listing GPUs: {e.stderr}")
             return 0
 
-    def _set_cuda_visible_devices_for_role_replica(
-        self,
-        replica: ReplicaParam,
-        replica_id: int,
-        requested_gpus: int,
-        role_gpu_start_idx: int,
-    ) -> None:
-        if requested_gpus <= 0:
-            return
-        start_device = role_gpu_start_idx + requested_gpus * replica_id
-        end_device = role_gpu_start_idx + requested_gpus * (replica_id + 1)
-        devices = list(range(start_device, end_device))
-        visible_devices = ",".join([str(device) for device in devices])
-        replica.env["CUDA_VISIBLE_DEVICES"] = visible_devices
-
-    def _update_env_cuda_visible_devices(
+    def auto_set_CUDA_VISIBLE_DEVICES(
         self,
         role_params: Dict[str, List[ReplicaParam]],
         app: AppDef,
         cfg: LocalOpts,
     ) -> None:
-        autoset = cfg.get("auto_set_cuda_visible_devices")
-        if not autoset:
-            return
+        """
+        If the run option ``auto_set_cuda_visible_devices = True``, then
+        sets the ``CUDA_VISIBLE_DEVICES`` env var to each replica's (node) env var
+        according to the number of gpus specified in each role's resource specifications,
+        overwriting any existing ``CUDA_VISIBLE_DEVICES`` in the role's ``env`` field.
+        To manually set ``CUDA_VISIBLE_DEVICES``, run with ``auto_set_cuda_visible_devices = False``
+        in the scheduler runcfg.
 
-        requested_gpus_total = sum(
-            [role.resource.gpu * role.num_replicas for role in app.roles]
-        )
-        if requested_gpus_total <= 0:
+        .. note::
+            If the host's device count is less than the total number of requested GPUs,
+            then ``CUDA_VISIBLE_DEVICES`` is NOT set (even if ``auto_set_cuda_visible_devices=True``).
+
+        .. note::
+            This method either sets ``CUDA_VISIBLE_DEVICES`` on all gpu roles or doesn't
+
+
+        Examples (all examples assume running on a host with 8 GPUs):
+
+        #. ``Role(num_replicas=2, resource=Resource(gpus=2))``
+              #. replica_0's ``CUDA_VISIBLE_DEVICES=0,1``
+              #. replica_1's ``CUDA_VISIBLE_DEVICES=2,3``
+
+        #. ``Role(num_replicas=3, resource=Resource(gpus=4))``
+              #. Error - `` 3 * 4 = 12 >= 8``
+
+        #. ``[Role(num_replicas=1, resource=Resource(gpus=2)), Role(num_replicas=3, resource=Resource(gpus=1))]``
+              #. role_0, replica_0's ``CUDA_VISIBLE_DEVICES=0,1``
+              #. role_1, replica_0's ``CUDA_VISIBLE_DEVICES=2``
+              #. role_1, replica_1's ``CUDA_VISIBLE_DEVICES=3``
+              #. role_1, replica_2's ``CUDA_VISIBLE_DEVICES=4``
+
+        """
+
+        total_requested_gpus = 0  # total number of gpus for the app
+
+        for role in app.roles:
+            gpus = role.num_replicas * role.resource.gpu
+            total_requested_gpus += gpus
+
+        if not cfg.get("auto_set_cuda_visible_devices") or total_requested_gpus <= 0:
+            if total_requested_gpus > 0:
+                log.warning(
+                    """\n
+======================================================================
+Running multiple role replicas that require GPUs without
+setting `CUDA_VISIBLE_DEVICES` may result in multiple 
+processes using the same GPU device with undesired consequences
+such as CUDA OutOfMemory errors.
+
+To have TorchX set `CUDA_VISIBLE_DEVICES` to divide the
+available GPUs on this host equally among the role replicas
+set the `auto_set_cuda_visible_devices = True` scheduler runopt
+======================================================================
+                            """
+                )
             return
 
-        device_count = self._get_gpu_device_count()
-        if requested_gpus_total > device_count:
+        device_count = self._cuda_device_count()
+        if total_requested_gpus > device_count:
             log.warning(
-                "Cannot set `CUDA_VISIBLE_DEVICES` due to "
-                f"Available GPUs {device_count} less than requested {requested_gpus_total}"
+                f"""\n
+======================================================================
+Cannot auto-set `CUDA_VISIBLE_DEVICES`
+Available GPUs: {device_count} is less than the
+number of requested GPUs: {total_requested_gpus}."
+
+Reduce requested GPU resources or use a host with more GPUs
+======================================================================
+                """
             )
-        role_gpu_start_idx = 0
+            return
+
+        start_idx = 0
         for role in app.roles:
+            # skip roles that have not requested gpus
+            if role.resource.gpu <= 0:
+                continue
+
             role_replicas = role_params[role.name]
             for replica_id, replica in enumerate(role_replicas):
-                self._set_cuda_visible_devices_for_role_replica(
-                    replica, replica_id, role.resource.gpu, role_gpu_start_idx
+                end_idx = start_idx + role.resource.gpu
+                replica.env[ENV_CUDA_VISIBLE_DEVICES] = ",".join(
+                    list(str(idx) for idx in range(start_idx, end_idx))
                 )
-            role_gpu_start_idx += role.resource.gpu * role.num_replicas
+                start_idx = end_idx
 
     def _to_popen_request(
         self,
         app: AppDef,
         cfg: LocalOpts,
     ) -> PopenRequest:
         """
@@ -893,15 +943,15 @@
 
                 replica_params.append(
                     image_provider.get_replica_param(
                         img_root, replica_role, stdout, stderr, combined
                     )
                 )
                 replica_log_dirs.append(replica_log_dir)
-        self._update_env_cuda_visible_devices(role_params, app, cfg)
+        self.auto_set_CUDA_VISIBLE_DEVICES(role_params, app, cfg)
         return PopenRequest(app_id, app_log_dir, role_params, role_log_dirs)
 
     def describe(self, app_id: str) -> Optional[DescribeAppResponse]:
         if app_id not in self._apps:
             return None
 
         local_app = self._apps[app_id]
```

## torchx/tracker/mlflow.py

```diff
@@ -15,15 +15,21 @@
 
 import mlflow
 from mlflow import MlflowClient
 from mlflow.entities import Experiment, Run
 
 from torchx.distributed import on_rank0_first
 from torchx.runner.config import get_configs
-from torchx.tracker.api import Lineage, TrackerArtifact, TrackerBase, TrackerSource
+from torchx.tracker.api import (
+    ENV_TORCHX_JOB_ID,
+    Lineage,
+    TrackerArtifact,
+    TrackerBase,
+    TrackerSource,
+)
 
 log: Logger = getLogger(__name__)
 TAG_ARTIFACT_MD_PREFIX = "torchx.artifact.metadata"
 
 
 class MLflowTracker(TrackerBase):
     """
@@ -59,14 +65,22 @@
             experiment_name = self.default_experiment_name()
 
         self.tracking_uri = tracking_uri
         mlflow.set_tracking_uri(tracking_uri)
         log.info(
             f"MLflow tracking_uri={tracking_uri}, artifact_location={artifact_location}"
         )
+
+        # mlflow uses ids (experiment_id and run_id) rather than names
+        # to uniquely identify experiment runs. But in torchx tracker
+        # we use the job name (TORCHX_JOB_ID which is unique in torchx)
+        # to uniquely identify experiment runs. So always look up experiments and runs
+        # by their names, then use the mlflow returned ids.
+        # Since this tracker may be used in a distributed setting (SPMD),
+        # guard against races when querying mlflow by running on rank 0 first
         with on_rank0_first():
             existing_experiment = mlflow.get_experiment_by_name(experiment_name)
             if existing_experiment:
                 self.experiment: Experiment = existing_experiment
                 log.info(
                     f"Found existing experiment `{experiment_name}` (id={self.experiment_id})"
                 )
@@ -76,14 +90,23 @@
                     artifact_location=artifact_location,
                 )
                 self.experiment = mlflow.get_experiment(experiment_id)
                 log.info(
                     f"Created new experiment `{experiment_name}` (id={experiment_id})"
                 )
 
+            # torchx gets the run name from TORCHX_JOB_ID env var
+            # so this env var will exist if the job is launched with torchx
+            # if so, then prime the run here so that rank0 creates the run first
+            # and the rest of the ranks can point to the existing run
+            run_name = os.getenv(ENV_TORCHX_JOB_ID)
+            if run_name:
+                run = self.get_run(run_name)
+                log.info(f"Primed run `{run.info.run_name}` ({run.info.run_id})")
+
     @staticmethod
     def default_experiment_name() -> str:
         return f"default-experiment/{getuser()}/{socket.getfqdn()}"
 
     @property
     def experiment_id(self) -> str:
         return self.experiment.experiment_id
@@ -125,18 +148,22 @@
             search_result = mlflow.search_runs(
                 experiment_ids=[self.experiment_id],
                 output_format="list",
                 filter_string=f"tags.`mlflow.runName` = '{run_name}'",
             )
             if not search_result:
                 return mlflow.start_run(
-                    experiment_id=self.experiment_id, run_name=run_name
+                    experiment_id=self.experiment_id,
+                    run_name=run_name,
                 )
             elif len(search_result) == 1:
-                return search_result[0]
+                return mlflow.start_run(
+                    experiment_id=self.experiment_id,
+                    run_id=search_result[0].info.run_id,
+                )
             else:  # len(search_result) > 1
                 raise RuntimeError(
                     f"More than 1 run found for run_name `{run_name}` in experiment `{self.experiment_name}`."
                     f" Did you manually create runs with the same name under this experiment?"
                     f" Remove duplicate run names and try again"
                 )
         else:
@@ -159,14 +186,15 @@
         run_id: str,
         name: str,
         path: str,
         metadata: Optional[Mapping[str, object]] = None,
     ) -> None:
         self.get_run(run_id)
         # stores the artifact in {artifact_location}/{name} (e.g. s3://bucket/prefix/{name})
+        log.info(f"Writing artifact: {name}, path: {path}")
         mlflow.log_artifact(local_path=path, artifact_path=name)
 
         # add artifact metadata with torchx.artifact_metadata.{name}.* tag prefix
         if metadata:
             mlflow.set_tags(
                 tags={
                     f"{TAG_ARTIFACT_MD_PREFIX}.{name}.{k}": v
```

## Comparing `torchx_nightly-2023.4.9.dist-info/LICENSE` & `torchx_nightly-2023.5.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `torchx_nightly-2023.4.9.dist-info/METADATA` & `torchx_nightly-2023.5.2.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: torchx-nightly
-Version: 2023.4.9
+Version: 2023.5.2
 Summary: TorchX SDK and Components
 Home-page: https://github.com/pytorch/torchx
 Author: TorchX Devs
 Author-email: torchx@fb.com
 License: BSD-3
 Keywords: pytorch,machine learning
 Platform: UNKNOWN
```

## Comparing `torchx_nightly-2023.4.9.dist-info/RECORD` & `torchx_nightly-2023.5.2.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -20,25 +20,25 @@
 torchx/cli/cmd_runopts.py,sha256=smQEJChk678o9n1y-crsVFiTMICp1C0PXcwoC3nRCtU,1287
 torchx/cli/cmd_status.py,sha256=BG-ScFn1wpLnf_VWphFvv-OI24JRQIbpCQ3_vPVVtG4,1821
 torchx/cli/cmd_tracker.py,sha256=S4GOTtBWoR3sbAJxRzjrF_I5uPvUjjoX-S4YEgGBLI0,5203
 torchx/cli/colors.py,sha256=bVN_jEDwLgvypnDMeCHKn0q0ZDDhQjBJnyVfZHAE6nc,553
 torchx/cli/main.py,sha256=DJYikTWacADa4VoscqZGjZmMKWWK29tBl6-pGtnzsRE,3469
 torchx/components/__init__.py,sha256=6-TQ4SY-Tn56os_1lOs_HMabOoE7gkkud_8e1BgvfJw,12106
 torchx/components/component_test_base.py,sha256=eKOwBp5cRgiA4FgZd_FCvyJ-ppv2v3JN9AGXnaSK_Cw,4135
-torchx/components/dist.py,sha256=FA1Wxxdo4qZ1_zd2Y20JpHog2ZjEGCkjN0k7dz5ZLvE,14075
+torchx/components/dist.py,sha256=gAtv11JnuicDQVBhOIAWyz5xQgHtJVFnaBICEEpHAY4,14079
 torchx/components/interpret.py,sha256=g8gkKdDJvsBfX1ZrpVT7n2bMEtmwRV_1AqDyAnnQ_aA,697
 torchx/components/metrics.py,sha256=1gbp8BfzZWGa7PD1db5vRADlONzmae4qSBUUdCWayr0,2814
 torchx/components/serve.py,sha256=9RlpwlU2KOC7sMOZBeYwUpJIKDCXrU8xNo1SH-AT3fc,2141
 torchx/components/structured_arg.py,sha256=uavcUeFDRnMP7cWAqcxR3ujJYi6JEsClz0_Rd4Dgxj4,9542
 torchx/components/train.py,sha256=vtrQXRcD7bIcbb3lSeyD9BBlIe1mv1WNW6rnLK9R0Mw,1259
 torchx/components/utils.py,sha256=m7mFe6du2AMHpViwcW9dF8rr_twQB6KHQuEzJyHwBXw,9025
 torchx/components/integration_tests/__init__.py,sha256=Md3cCHD7Ano9kV15PqGbicgUO-RMdh4aVy1yKiDt_xE,208
 torchx/components/integration_tests/component_provider.py,sha256=FTwzCrr3p4SWYbxcjN4E6i7qjklyrWgDWL3UGkhoDaA,3980
 torchx/components/integration_tests/integ_tests.py,sha256=OVgRvGrLWhDUNlqbbYj90ukGmkAwka2KubCWUR8pC7Y,5150
-torchx/distributed/__init__.py,sha256=OAO1CIwVBOaclzbp2NjH_SMBq2WlK7aE9NVlNmDtVlQ,8786
+torchx/distributed/__init__.py,sha256=pkB_V4eX0DnupRsmOGnINL2XGDM1oRLG0-fH7-feeNI,10280
 torchx/examples/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 torchx/examples/apps/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 torchx/examples/apps/datapreproc/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 torchx/examples/apps/datapreproc/datapreproc.py,sha256=7GV37WS3JLueID8vGFvqO93ua0PSSx__hz2MYNto53Q,4302
 torchx/examples/apps/lightning/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 torchx/examples/apps/lightning/data.py,sha256=uTZM_G8Wd-UjzlmeDIsl645qZl9qD7d-cesRFt0nnm4,6583
 torchx/examples/apps/lightning/interpret.py,sha256=Hd3kE5a6FyhxCmJBfTzb4Tlj518zhX8V0XvZfzu4nqE,5256
@@ -61,22 +61,22 @@
 torchx/runner/events/api.py,sha256=Amj9aamjh3AUo4iGzcRO-bxfmtsWL1fdwj2M77PHhIE,1957
 torchx/runner/events/handlers.py,sha256=esLkzce9fvwgjqu1IrO_furmhECUqwUeL7wy5zbqtUo,507
 torchx/runtime/__init__.py,sha256=Wxje2BryzeQneFu5r6P9JJiEKG-_C9W1CcZ_JNrKT6g,593
 torchx/runtime/tracking/__init__.py,sha256=uHbJ1NqsxFWGYz2aV0_p4OCMhW467zDJu_86B0C1Mn8,3040
 torchx/runtime/tracking/api.py,sha256=9mlsCnnKP8hfvypNcEX2_57OYMW4AuTMM-nvsIgOzK4,5457
 torchx/schedulers/__init__.py,sha256=cCansxGU45SV_lxhgzyw2on7AJyIvhprAFo6Di1x9xQ,2157
 torchx/schedulers/api.py,sha256=BtDK4P20q38aHoMboNfqY4MnvMSonUz25mYt9Y8Bu74,13941
-torchx/schedulers/aws_batch_scheduler.py,sha256=_jetOwBgxBr4F0jpaUanhHClRamT0uEctXqVnc_W4W4,26063
+torchx/schedulers/aws_batch_scheduler.py,sha256=Fmg1RyWRh0NPw2p8REdRS1mj4oErWmZJuTUBFBuOGeI,26405
 torchx/schedulers/devices.py,sha256=PNbcpf8fEM18Ag1RgK9Q30zPBalEcPdsFWctdbLxuv8,1352
 torchx/schedulers/docker_scheduler.py,sha256=DU5YdLrVCjyoVxqpqeUM4ssTISuMEQaDGOBHU-cqcms,15370
 torchx/schedulers/gcp_batch_scheduler.py,sha256=MNlZGjNZVd-E7m7sR5DN0BidRJOU0w8TZDpovdU3d9o,15993
 torchx/schedulers/ids.py,sha256=IGsJEbCYTdfKdU3MhKLQU6b7sWCJy5dlRV6JIL_9BlE,1783
-torchx/schedulers/kubernetes_mcad_scheduler.py,sha256=Q4RWGplSvZHvK4i-BOlxfOVke0bTOTmddl4DomqmnS0,41100
+torchx/schedulers/kubernetes_mcad_scheduler.py,sha256=NoJSgnofM7rQPA5Pc4ArFx_XsTHp69oj7elfo0ktq60,42500
 torchx/schedulers/kubernetes_scheduler.py,sha256=bkfrR6arwgsLHoZaGkGu--f3WtnbaTOfnd7Fa0j_pVo,26830
-torchx/schedulers/local_scheduler.py,sha256=V-Qox7jIbrr-vGaWrOeU6NYds47mDlA1EQcMj4ehbK4,37591
+torchx/schedulers/local_scheduler.py,sha256=f_b_50XGBZkPdJSwdkmsRm9qoNQJLoI8pBOWTeX1oZI,39945
 torchx/schedulers/lsf_scheduler.py,sha256=3lRSY9yiM83YFDHR73KVqgaQDMJ3Hsi2wRUl-Ak3u80,17552
 torchx/schedulers/ray_scheduler.py,sha256=UWN4jCdG_0x6Kd04FcayhLxc3BZGw3UMH21DH1m1tlQ,16190
 torchx/schedulers/slurm_scheduler.py,sha256=32lW_lld1-U6tp8UBoscEHtf-ooplSzuZ-GkrufP1Xg,19269
 torchx/schedulers/streams.py,sha256=ObaKwEEcnsjrPyc6VZOp8cgZ_f2RFextAxeISxZUWeQ,1992
 torchx/schedulers/ray/__init__.py,sha256=fE0IHi1JJpxsNVBNzWNee2thrNXFFRhY94c80RxNSIE,231
 torchx/schedulers/ray/ray_common.py,sha256=pyNYFvTKVwdjDAeCBNbPwAWwVNmlLOJWExfn90XY8u8,610
 torchx/schedulers/ray/ray_driver.py,sha256=0DL8Ad_hire-WgH8ZEYx1Q-mI2SUfZDk-6_6PICk8OQ,12282
@@ -91,27 +91,28 @@
 torchx/specs/test/components/a/__init__.py,sha256=T7exlQ47Fak5ajCEGPg6_yOfChJCWpIMhWBmSVUnlrQ,546
 torchx/specs/test/components/a/b/__init__.py,sha256=Md3cCHD7Ano9kV15PqGbicgUO-RMdh4aVy1yKiDt_xE,208
 torchx/specs/test/components/a/b/c.py,sha256=QyTZfsCaSZscmk3DeNOkAyMoz6GCcayrWtOKbNFIZ1M,539
 torchx/specs/test/components/c/__init__.py,sha256=fE0IHi1JJpxsNVBNzWNee2thrNXFFRhY94c80RxNSIE,231
 torchx/specs/test/components/c/d.py,sha256=RH07jjo6uvFbzIaNFnAwmD_h24cEsT8kyZDTN-ezFio,531
 torchx/tracker/__init__.py,sha256=bnqiFZmrQoioeDlUkrzxFYzfbuf6OQvrlZmhtNekw8U,4206
 torchx/tracker/api.py,sha256=WRS3As_8YkxaL_enMz60wKba9cC_ynGIp8IQwNBbTTM,11263
-torchx/tracker/mlflow.py,sha256=P_mj7Yi-bZc7QOZ-6PJW4FHeWWGX0rjauNK0zXC25ig,13221
+torchx/tracker/mlflow.py,sha256=poeoIXVPzr2sxgi515fMGRH83KAFNL6XFILMh0EQ2Dw,14487
 torchx/tracker/backend/__init__.py,sha256=fE0IHi1JJpxsNVBNzWNee2thrNXFFRhY94c80RxNSIE,231
 torchx/tracker/backend/fsspec.py,sha256=JpSioMgn54mrxqqpY0kw5Gudqx9hhxkgDLaOFSEP2Ko,10425
 torchx/util/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+torchx/util/cuda.py,sha256=GiAtP9-T4zJxwHl7r5qGQRuINb59Mzwz8tnzB1MVY74,1084
 torchx/util/datetime.py,sha256=e-sO5Wjx1Utpln14C3qfJHl4v3KM-SMnn11hSyvkqFY,390
 torchx/util/entrypoints.py,sha256=C4A7cF1tPLlfyYWyZ7uZEtsKeuoOoLbMv0sOSxLhXs4,2710
 torchx/util/io.py,sha256=sxb6KI42Lq6n5z6_-YKW_mAhgPdC6CxzexlMyGheWSc,1792
 torchx/util/shlex.py,sha256=KzyWektMeU3oXS3Z5mFkNSPLItBTszVcvQ3EYfOMUYA,448
 torchx/util/strings.py,sha256=7CZe5WKHa7IQ6DuJCYeJ5FapUC4Fd1OGeq1yZAmjluw,663
 torchx/util/types.py,sha256=6ASuDKGO91UU3DCSuWhPX_C03341tApLCQEByUz8xpY,7016
 torchx/workspace/__init__.py,sha256=KbGEzJqqXaIxALm_EQO64aw-fE7MeDMFXcpU1mY650I,783
 torchx/workspace/api.py,sha256=Ej6DR__mNWaVyZgoVNAAOloDy1kTD5X1jz7pRtoVf80,5464
 torchx/workspace/dir_workspace.py,sha256=Fz-hKIx0KN8iJf2BsthNj0NvTkWlxP6WFsElPs_BaT0,2253
 torchx/workspace/docker_workspace.py,sha256=Yd8ut26bNfjyJQnmH8ANOrflfr-4VKcnOrIjbi_XIUY,9208
-torchx_nightly-2023.4.9.dist-info/LICENSE,sha256=WVHfXhFC0Ia8LTKt_nJVYobdqTJVg_4J3Crrfm2A8KQ,1721
-torchx_nightly-2023.4.9.dist-info/METADATA,sha256=1byW-PWlmFwTF7zhpY2blV8m_ZnuWwa8j3z67UrdMHY,5513
-torchx_nightly-2023.4.9.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-torchx_nightly-2023.4.9.dist-info/entry_points.txt,sha256=3JYZFlX9aWzR-Gs_qsx1zq7mlqbFz6Mi9rQUULW8caI,170
-torchx_nightly-2023.4.9.dist-info/top_level.txt,sha256=pxew3bc2gsiViS0zADs0jb6kC5v8o_Yy_85fhHj_J1A,7
-torchx_nightly-2023.4.9.dist-info/RECORD,,
+torchx_nightly-2023.5.2.dist-info/LICENSE,sha256=WVHfXhFC0Ia8LTKt_nJVYobdqTJVg_4J3Crrfm2A8KQ,1721
+torchx_nightly-2023.5.2.dist-info/METADATA,sha256=iQbep2wZvIGyPWNwrZWWJdF5UXKx8U9VLAJmVzo1aXc,5513
+torchx_nightly-2023.5.2.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+torchx_nightly-2023.5.2.dist-info/entry_points.txt,sha256=3JYZFlX9aWzR-Gs_qsx1zq7mlqbFz6Mi9rQUULW8caI,170
+torchx_nightly-2023.5.2.dist-info/top_level.txt,sha256=pxew3bc2gsiViS0zADs0jb6kC5v8o_Yy_85fhHj_J1A,7
+torchx_nightly-2023.5.2.dist-info/RECORD,,
```

